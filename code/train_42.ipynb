{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12d68fc3",
   "metadata": {},
   "source": [
    "## LZV modeļa apmācība"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d97ea1fd",
   "metadata": {},
   "source": [
    "Šī Jupyter grāmatiņa trenē LZV modeli, izmantojot pārneses mācīšanās stratēģiju no ASL modeļa, kas trenēts uz 42 orientieriem.\n",
    "\n",
    "Lai palaistu šo grāmatiņu, ir nepieciešams:\n",
    "\n",
    "* GitHub repo sagatavotais:\n",
    "    * char_map.json\n",
    "    * dataset_info.json\n",
    "    * cslr_model_best_42.keras\n",
    "\n",
    "* Jūsu pašu sagatavots:\n",
    "    * training.tfrecord\n",
    "    * validation.tfrecord\n",
    "\n",
    "Galā tiks iegūts .keras training un prediction modelis, kā arī metadatu fails. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e884f5",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc00bfb1",
   "metadata": {},
   "source": [
    "### 1. Konfigurācija\n",
    "\n",
    "Šobrīd ir noklusējuma opcijas. Spoguļattēla augmentācija mēdz pasliktināt, tādēļ USE_FLIP_AUGMENTATION = False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1db8d47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 254\n",
      "Number of validation samples: 64\n",
      "Number of classes: 45\n",
      "Number of classes with blank: 46\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "import time\n",
    "from datetime import datetime, timezone\n",
    "from pathlib import Path\n",
    "import jiwer\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "try:\n",
    "    # Mapītes\n",
    "    BASE_DIR = os.path.abspath(os.path.join(os.getcwd(), \"../\"))\n",
    "    DATA_DIR = \"..\\data\\processed_landmarks\"\n",
    "\n",
    "    TFRECORD_FILE = os.path.join(DATA_DIR, \"training.tfrecord\")\n",
    "    TFRECORD_FILE_VAL = os.path.join(DATA_DIR, \"validation.tfrecord\")\n",
    "    DATASET_INFO_FILE = os.path.join(DATA_DIR, \"dataset_info.json\")\n",
    "\n",
    "    CHAR_MAP_FILE = os.path.join(DATA_DIR, \"char_map.json\")\n",
    "\n",
    "    MODELS_BASE_DIR = os.path.join(BASE_DIR, \"models\")\n",
    "    ASL_MODEL_PATH = os.path.join(MODELS_BASE_DIR, \"asl\\\\42\\\\cslr_model_best_42.keras\")\n",
    "    OUTPUT_DIR = os.path.join(MODELS_BASE_DIR, \"lzv\")\n",
    "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "    # Parametri\n",
    "    EPOCHS = 300\n",
    "    BATCH_SIZE = 4\n",
    "    LEARNING_RATE = 1e-6\n",
    "    FINE_TUNE_AT  = 20\n",
    "\n",
    "    EPOCHS_PHASE_1 = 50\n",
    "    EPOCHS_PHASE_2 = 200\n",
    "    EPOCHS_PHASE_3 = 100\n",
    "\n",
    "    LR_PHASE_1 = 1e-3\n",
    "    LR_PHASE_2 = 5e-5\n",
    "    LR_PHASE_3 = 1e-6\n",
    "\n",
    "    NUM_LSTM_UNITS = 64\n",
    "    NUM_CONV_FILTERS = 128\n",
    "    CONV_KERNEL_SIZE = 5\n",
    "    CONV_STRIDES = 1\n",
    "    shuffle_buffer = 1000\n",
    "\n",
    "    ASL_NUM_CLASSES_WITH_BLANK = 60\n",
    "    NUM_CLASSES_WITH_BLANK = 46\n",
    "\n",
    "    USE_AUGMENTATION = True\n",
    "    USE_FLIP_AUGMENTATION = False # Spoguļattēla augmentācija\n",
    "\n",
    "    # Simbolu vārdnīca\n",
    "    with open(CHAR_MAP_FILE, 'r', encoding='utf-8') as f:\n",
    "        char_map = json.load(f)\n",
    "        id_to_char = {int(v): k for k, v in char_map.items()}\n",
    "\n",
    "    inverse_char_map = {}\n",
    "    try:\n",
    "        inverse_char_map = {v: k for k, v in char_map.items()}\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "\n",
    "    # Metadatu fails\n",
    "    with open(DATASET_INFO_FILE, 'r') as f:\n",
    "        dataset_info = json.load(f)\n",
    "\n",
    "    # Vērtību iegūšana no metadatu faila\n",
    "    NUM_TRAIN_SAMPLES_LZV = dataset_info[\"dataset_stats\"][\"train_samples\"]\n",
    "    NUM_VAL_SAMPLES_LZV = dataset_info[\"dataset_stats\"][\"val_samples\"]\n",
    "    NUM_CLASSES_WITH_BLANK = dataset_info[\"num_classes_with_blank\"]\n",
    "    NUM_CLASSES = dataset_info[\"num_classes\"]\n",
    "    VOCAB_SIZE = NUM_CLASSES\n",
    "\n",
    "    NUM_TRAIN_SAMPLES_AFTER_FILTER = NUM_TRAIN_SAMPLES_LZV\n",
    "    NUM_VAL_SAMPLES_AFTER_FILTER = NUM_VAL_SAMPLES_LZV\n",
    "\n",
    "    print(f\"Number of training samples: {NUM_TRAIN_SAMPLES_LZV}\")\n",
    "    print(f\"Number of validation samples: {NUM_VAL_SAMPLES_LZV}\")\n",
    "    print(f\"Number of classes: {NUM_CLASSES}\")\n",
    "    print(f\"Number of classes with blank: {NUM_CLASSES_WITH_BLANK}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57040a89",
   "metadata": {},
   "source": [
    "### 2. Orientieri\n",
    "\n",
    "Šie indeksi atbilst 543 punktu orientieriem, kas ir pieejami MediaPipe modeļos.\n",
    "\n",
    "Šajā grāmatiņā tiek izmantots 42 roku orientieri, tomēr orientieru iedalījums 75 orientieru konfigurācijai un ķermeņa daļām arī ir atstāts.\n",
    "\n",
    "Orientieru globālā indeksācija ir šāda:\n",
    "* 33 pozas (0-32)\n",
    "* 468 sejas (33-500)\n",
    "* 21 kreisās rokas (501-521)\n",
    "* 21 labās rokas (522-542)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67527583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training landmark count: 42\n",
      "Training landmark indices: [501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542]\n"
     ]
    }
   ],
   "source": [
    "ORIGINAL_NUM_LANDMARKS = 543\n",
    "LANDMARK_DIMS = 3\n",
    "\n",
    "ALL_IDXS = list(range(1, 544))\n",
    "\n",
    "POSE_SYMMETRY = [\n",
    "    (11, 12), # Pleci\n",
    "    (13, 14), # Elkoņi\n",
    "    (15, 16), # Plecu locītavas\n",
    "    (23, 24), # Gurni\n",
    "]\n",
    "\n",
    "FACE_SYMMETRY = [\n",
    "    (33, 263),   # Ārējie acu stūri\n",
    "    (133, 362),  # Iekšējie acu stūri\n",
    "]\n",
    "\n",
    "LIP_IDXS = [\n",
    "    61, 146, 91, 181, 84, 17, 314, 405, 321, 375, 291,\n",
    "    78, 191, 80, 81, 82, 312, 311, 310, 415, 308\n",
    "]\n",
    "\n",
    "LPOSE_IDXS_REL = [p[0] for p in POSE_SYMMETRY]\n",
    "RPOSE_IDXS_REL = [p[1] for p in POSE_SYMMETRY]\n",
    "LFACE_IDXS_REL = [p[0] for p in FACE_SYMMETRY]\n",
    "RFACE_IDXS_REL = [p[1] for p in FACE_SYMMETRY]\n",
    "\n",
    "LHAND_IDXS_ALL = list(range(501, 522))\n",
    "RHAND_IDXS_ALL = list(range(522, 543))\n",
    "\n",
    "training_indices_list = sorted(list(set(\n",
    "    LHAND_IDXS_ALL + RHAND_IDXS_ALL\n",
    ")))\n",
    "\n",
    "TRAINING_IDXS = tf.constant(training_indices_list, dtype=tf.int32)\n",
    "NEW_NUM_LANDMARKS = len(training_indices_list)\n",
    "NUM_LANDMARKS = NEW_NUM_LANDMARKS\n",
    "\n",
    "trim_idxs = tf.constant(training_indices_list, dtype=tf.int32)\n",
    "TRIMMED_NUM_LANDMARKS = len(training_indices_list)\n",
    "ASL_USED_LANDMARKS_COUNT = TRIMMED_NUM_LANDMARKS\n",
    "\n",
    "print(f\"Training landmark count: {TRIMMED_NUM_LANDMARKS}\")\n",
    "print(f\"Training landmark indices: {training_indices_list}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3889c89c",
   "metadata": {},
   "source": [
    "### 3. Dažādas palīgfunkcijas un augmentācijas funkcijas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f92bfdd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_description = {\n",
    "    \"landmarks\": tf.io.FixedLenFeature([], tf.string),\n",
    "    \"phrase\": tf.io.VarLenFeature(tf.int64),\n",
    "    \"length\": tf.io.FixedLenFeature([1], tf.int64),\n",
    "    \"phrase_length\": tf.io.FixedLenFeature([1], tf.int64)\n",
    "}\n",
    "\n",
    "def interp1d_(tensor, new_size, axis=0):\n",
    "    tensor_float = tf.cast(tensor, tf.float32)\n",
    "    if tf.rank(tensor_float) != 3:\n",
    "        raise ValueError(\"Input tensor must have rank 3 (time, landmarks, coords)\")\n",
    "\n",
    "    original_size = tf.shape(tensor_float)[axis]\n",
    "\n",
    "    if axis == 0: # Interpolate along time\n",
    "        reshaped = tf.reshape(tensor_float, [original_size, -1, 1])\n",
    "        resized = tf.image.resize(reshaped, [new_size, tf.shape(reshaped)[1]], method='bilinear')\n",
    "        output = tf.reshape(resized, [new_size, tf.shape(tensor_float)[1], tf.shape(tensor_float)[2]])\n",
    "    else:\n",
    "        raise ValueError(\"Interpolation along axis != 0 not implemented here\")\n",
    "\n",
    "    return output\n",
    "\n",
    "def find_next_experiment_index(base_models_dir):\n",
    "    index = 1\n",
    "    while True:\n",
    "        experiment_dir = os.path.join(base_models_dir, str(index))\n",
    "        if not os.path.isdir(experiment_dir):\n",
    "            return index\n",
    "        index += 1\n",
    "\n",
    "def format_time(seconds):\n",
    "    if seconds is None: return None\n",
    "    seconds = int(seconds)\n",
    "    hours = seconds // 3600\n",
    "    minutes = (seconds % 3600) // 60\n",
    "    secs = seconds % 60\n",
    "    return f\"{hours:02d}:{minutes:02d}:{secs:02d}\"\n",
    "\n",
    "def inspect_tensor(tensor, message=\"Tensor\"):\n",
    "    is_finite = tf.math.is_finite(tensor)\n",
    "    all_finite = tf.reduce_all(is_finite)\n",
    "    finite_values = tf.boolean_mask(tensor, is_finite)\n",
    "    has_finite_values = tf.size(finite_values) > 0\n",
    "\n",
    "    min_val = tf.cond(has_finite_values, lambda: tf.reduce_min(finite_values), lambda: tf.constant(0.0, dtype=tensor.dtype))\n",
    "    max_val = tf.cond(has_finite_values, lambda: tf.reduce_max(finite_values), lambda: tf.constant(0.0, dtype=tensor.dtype))\n",
    "    mean_val = tf.cond(has_finite_values, lambda: tf.reduce_mean(tf.cast(finite_values, tf.float32)), lambda: tf.constant(0.0, dtype=tf.float32))\n",
    "\n",
    "    tf.print(f\"DEBUG {message}: Shape={tf.shape(tensor)}, Min={min_val}, Max={max_val}, Mean={mean_val}, AllFinite={all_finite}\",\n",
    "        output_stream=sys.stderr)\n",
    "    return tensor\n",
    "\n",
    "\n",
    "LPOSE_IDXS = tf.constant([p[0] for p in POSE_SYMMETRY], dtype=tf.int32)\n",
    "RPOSE_IDXS = tf.constant([p[1] for p in POSE_SYMMETRY], dtype=tf.int32)\n",
    "LFACE_IDXS = tf.constant([p[0] for p in FACE_SYMMETRY], dtype=tf.int32)\n",
    "RFACE_IDXS = tf.constant([p[1] for p in FACE_SYMMETRY], dtype=tf.int32)\n",
    "LHAND_IDXS = tf.constant(LHAND_IDXS_ALL, dtype=tf.int32)\n",
    "RHAND_IDXS = tf.constant(RHAND_IDXS_ALL, dtype=tf.int32)\n",
    "\n",
    "LPOSE_SCATTER_IDX = LPOSE_IDXS[:, None]\n",
    "RPOSE_SCATTER_IDX = RPOSE_IDXS[:, None]\n",
    "LFACE_SCATTER_IDX = LFACE_IDXS[:, None]\n",
    "RFACE_SCATTER_IDX = RFACE_IDXS[:, None]\n",
    "LHAND_SCATTER_IDX = LHAND_IDXS[:, None]\n",
    "RHAND_SCATTER_IDX = RHAND_IDXS[:, None]\n",
    "\n",
    "@tf.function\n",
    "# Spoguļattēla augmentācija\n",
    "def flip_lr_adapted(x):\n",
    "    x_flipped = tf.stack([-x[..., 0], x[..., 1], x[..., 2]], axis=-1)\n",
    "\n",
    "    def swap_landmarks_for_frame(frame_flipped):\n",
    "        left_hand_vals = tf.gather(frame_flipped, LHAND_IDXS, axis=0)\n",
    "        right_hand_vals = tf.gather(frame_flipped, RHAND_IDXS, axis=0)\n",
    "        left_pose_vals = tf.gather(frame_flipped, LPOSE_IDXS, axis=0)\n",
    "        right_pose_vals = tf.gather(frame_flipped, RPOSE_IDXS, axis=0)\n",
    "        left_face_vals = tf.gather(frame_flipped, LFACE_IDXS, axis=0)\n",
    "        right_face_vals = tf.gather(frame_flipped, RFACE_IDXS, axis=0)\n",
    "\n",
    "        frame_swapped = frame_flipped\n",
    "        frame_swapped = tf.tensor_scatter_nd_update(frame_swapped, LHAND_SCATTER_IDX, right_hand_vals)\n",
    "        frame_swapped = tf.tensor_scatter_nd_update(frame_swapped, RHAND_SCATTER_IDX, left_hand_vals)\n",
    "        frame_swapped = tf.tensor_scatter_nd_update(frame_swapped, LPOSE_SCATTER_IDX, right_pose_vals)\n",
    "        frame_swapped = tf.tensor_scatter_nd_update(frame_swapped, RPOSE_SCATTER_IDX, left_pose_vals)\n",
    "        frame_swapped = tf.tensor_scatter_nd_update(frame_swapped, LFACE_SCATTER_IDX, right_face_vals)\n",
    "        frame_swapped = tf.tensor_scatter_nd_update(frame_swapped, RFACE_SCATTER_IDX, left_face_vals)\n",
    "        return frame_swapped\n",
    "\n",
    "    x_swapped_time_series = tf.map_fn(\n",
    "        swap_landmarks_for_frame,\n",
    "        tf.cast(x_flipped, tf.float32),\n",
    "        fn_output_signature=tf.float32\n",
    "    )\n",
    "    original_shape = tf.shape(x)\n",
    "    x_swapped_time_series = tf.reshape(x_swapped_time_series, original_shape)\n",
    "    return x_swapped_time_series\n",
    "\n",
    "# Telpiskās augmentācijas\n",
    "def spatial_random_affine_adapted(xyz,\n",
    "                                scale=(0.8, 1.2),\n",
    "                                shear=(-0.15, 0.15),\n",
    "                                shift=(-0.1, 0.1),\n",
    "                                degree=(-15, 15),\n",
    "                               ):\n",
    "    center = tf.constant([0.0, 0.0])\n",
    "    xyz_transformed = xyz\n",
    "\n",
    "    if scale is not None:\n",
    "        scale_factor = tf.random.uniform((), *scale)\n",
    "        xyz_transformed = scale_factor * xyz_transformed\n",
    "\n",
    "    if shear is not None:\n",
    "        xy = xyz_transformed[..., :2]\n",
    "        z = xyz_transformed[..., 2:]\n",
    "        shear_x = shear_y = tf.random.uniform((), *shear)\n",
    "        if tf.random.uniform(()) < 0.5: shear_x = 0.\n",
    "        else: shear_y = 0.\n",
    "        shear_mat = tf.convert_to_tensor([[1., shear_x], [shear_y, 1.]], dtype=tf.float32)\n",
    "        xy_sheared = tf.einsum('...ij,...j->...i', shear_mat, xy)\n",
    "        xyz_transformed = tf.concat([xy_sheared, z], axis=-1)\n",
    "\n",
    "    if degree is not None:\n",
    "        xy = xyz_transformed[..., :2]\n",
    "        z = xyz_transformed[..., 2:]\n",
    "        degree_val = tf.random.uniform((), *degree)\n",
    "        radian = degree_val / 180.0 * np.pi\n",
    "        c = tf.cos(radian)\n",
    "        s = tf.sin(radian)\n",
    "        rotate_mat = tf.convert_to_tensor([[c, s], [-s, c]], dtype=tf.float32)\n",
    "        xy_rotated = tf.einsum('...ij,...j->...i', rotate_mat, xy)\n",
    "        xyz_transformed = tf.concat([xy_rotated, z], axis=-1)\n",
    "\n",
    "    if shift is not None:\n",
    "        shift_val_x = tf.random.uniform((), *shift)\n",
    "        shift_val_y = tf.random.uniform((), *shift)\n",
    "        shift_val_z = tf.constant(0.0, dtype=tf.float32)\n",
    "        shift_vector = tf.stack([shift_val_x, shift_val_y, shift_val_z], axis=0)\n",
    "        xyz_transformed += shift_vector\n",
    "\n",
    "    return xyz_transformed\n",
    "\n",
    "# Laika ass augmentācija\n",
    "def resample_adapted(x, rate=(0.8, 1.2)):\n",
    "    rate = tf.random.uniform((), rate[0], rate[1])\n",
    "    length = tf.shape(x)[0]\n",
    "    new_size = tf.cast(rate * tf.cast(length, tf.float32), tf.int32)\n",
    "    new_size = tf.maximum(new_size, 1)\n",
    "    new_x = interp1d_(x, new_size, axis=0)\n",
    "    return new_x\n",
    "\n",
    "# Maskēšanas augmentācija\n",
    "def temporal_mask_adapted(x, size=(0.2, 0.4), mask_value=0.0):\n",
    "    l = tf.shape(x)[0]\n",
    "    if l <= 1:\n",
    "        return x\n",
    "\n",
    "    mask_size_ratio = tf.random.uniform((), *size)\n",
    "    mask_size = tf.cast(tf.cast(l, tf.float32) * mask_size_ratio, tf.int32)\n",
    "    mask_size = tf.clip_by_value(mask_size, 0, l)\n",
    "\n",
    "    if mask_size == 0:\n",
    "        return x\n",
    "\n",
    "    max_offset = l - mask_size\n",
    "    mask_offset = tf.random.uniform((), 0, max_offset + 1, dtype=tf.int32)\n",
    "\n",
    "    indices_to_update = tf.range(mask_offset, mask_offset + mask_size)\n",
    "    updates = tf.fill([mask_size, tf.shape(x)[1], tf.shape(x)[2]], tf.cast(mask_value, x.dtype))\n",
    "\n",
    "    x = tf.tensor_scatter_nd_update(x, indices_to_update[..., None], updates)\n",
    "    return x\n",
    "\n",
    "# Piemēro notikšanas varbūtību augmentāciju funkcijām\n",
    "def augment_fn_adapted(x, use_resample=True):\n",
    "    original_length = tf.shape(x)[0]\n",
    "    if use_resample:\n",
    "        if tf.random.uniform(()) < 0.9:\n",
    "            x = resample_adapted(x, (0.7, 1.3))\n",
    "\n",
    "    if tf.random.uniform(()) < 0.5:\n",
    "        x = temporal_mask_adapted(x, size=(0.1, 0.3))\n",
    "\n",
    "    if tf.random.uniform(()) < 0.75:\n",
    "        x = spatial_random_affine_adapted(x)\n",
    "\n",
    "    if USE_FLIP_AUGMENTATION:\n",
    "        if tf.random.uniform(()) < 0.5:\n",
    "            x = flip_lr_adapted(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "# Parsē TFRecord failu\n",
    "def parse_tfrecord_fn_for_filter(example):\n",
    "    features = tf.io.parse_single_example(example, feature_description)\n",
    "    landmarks = tf.io.decode_raw(features['landmarks'], tf.float32)\n",
    "    seq_len = features['length'][0]\n",
    "    phrase_len = features['phrase_length'][0]\n",
    "\n",
    "    landmarks = tf.reshape(landmarks, (seq_len, ORIGINAL_NUM_LANDMARKS, LANDMARK_DIMS))\n",
    "    phrase = tf.sparse.to_dense(features['phrase'])\n",
    "\n",
    "    return landmarks, phrase, seq_len, phrase_len\n",
    "\n",
    "# Filtrēšanas funkcija, lai atlasītu tikai piemērus ar pietiekamu garumu\n",
    "@tf.function\n",
    "def filter_ctc_length(landmarks, phrase, landmark_length, phrase_length):\n",
    "    phrase_length = phrase_length + CONV_KERNEL_SIZE\n",
    "    return tf.greater_equal(landmark_length, phrase_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa322a2c",
   "metadata": {},
   "source": [
    "### 4. Normalizācija\n",
    "\n",
    "Normalizācijas dati (standartnovirzes un vidējās vērtības) tiek izrēķināti uz vietas šajā grāmatiņā."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9f28f65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterating for mean/std started...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating LZV Stats: 253it [00:00, 282.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 253 LZV samples with 44934 total frames.\n",
      "\n",
      "LZV Combined mean shape for broadcasting: (1, 543, 3)\n",
      "LZV Combined std shape for broadcasting: (1, 543, 3)\n",
      "On-the-spot LZV normalization stats calculated and prepared.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "combined_mean = None\n",
    "combined_std = None\n",
    "num_lzv_train_samples_for_stats = 0\n",
    "\n",
    "try:\n",
    "    stats_raw_dataset_lzv = tf.data.TFRecordDataset([TFRECORD_FILE])\n",
    "    stats_parsed_dataset_lzv = stats_raw_dataset_lzv.map(\n",
    "        parse_tfrecord_fn_for_filter, num_parallel_calls=tf.data.AUTOTUNE\n",
    "    )\n",
    "    stats_filtered_dataset_lzv = stats_parsed_dataset_lzv.filter(filter_ctc_length)\n",
    "\n",
    "    print(\"Iterating for mean/std started...\")\n",
    "    total_frames_lzv = 0\n",
    "    landmark_sum_lzv = np.zeros((ORIGINAL_NUM_LANDMARKS, LANDMARK_DIMS), dtype=np.float64)\n",
    "    landmark_sum_sq_lzv = np.zeros((ORIGINAL_NUM_LANDMARKS, LANDMARK_DIMS), dtype=np.float64)\n",
    "\n",
    "    for landmarks_raw, _, landmark_length, _ in tqdm(stats_filtered_dataset_lzv, desc=\"Calculating LZV Stats\"):\n",
    "        current_frames = tf.shape(landmarks_raw)[0].numpy()\n",
    "        if current_frames > 0:\n",
    "            total_frames_lzv += current_frames\n",
    "            landmark_sum_lzv += np.sum(landmarks_raw.numpy().astype(np.float64), axis=0)\n",
    "            landmark_sum_sq_lzv += np.sum(np.square(landmarks_raw.numpy().astype(np.float64)), axis=0)\n",
    "            num_lzv_train_samples_for_stats += 1\n",
    "    \n",
    "    if total_frames_lzv == 0:\n",
    "        raise ValueError(\"No valid frames found in the filtered dataset to calculate statistics.\")\n",
    "\n",
    "    print(f\"Processed {num_lzv_train_samples_for_stats} LZV samples with {total_frames_lzv} total frames.\")\n",
    "\n",
    "    mean_np_lzv = (landmark_sum_lzv / total_frames_lzv).astype(np.float32)\n",
    "    variance_np_lzv = (landmark_sum_sq_lzv / total_frames_lzv) - np.square(mean_np_lzv)\n",
    "    variance_np_lzv = np.maximum(variance_np_lzv, 0) \n",
    "    std_np_lzv = np.sqrt(variance_np_lzv).astype(np.float32)\n",
    "\n",
    "    combined_mean = tf.constant(mean_np_lzv, dtype=tf.float32)[tf.newaxis, :, :]\n",
    "    combined_std = tf.constant(std_np_lzv, dtype=tf.float32)[tf.newaxis, :, :]\n",
    "\n",
    "    epsilon = 1e-6\n",
    "    combined_std = tf.where(combined_std < epsilon, epsilon, combined_std)\n",
    "\n",
    "    print(f\"\\nLZV Combined mean shape for broadcasting: {combined_mean.shape}\")\n",
    "    print(f\"LZV Combined std shape for broadcasting: {combined_std.shape}\")\n",
    "    print(\"On-the-spot LZV normalization stats calculated and prepared.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f4836a",
   "metadata": {},
   "source": [
    "### 5. ASL modeļa rekonstrukcija\n",
    "\n",
    "ASL modelis ir trenēts uz daudz vairāk datiem, nekā LZV. ASL modeļa struktūra ir tieši tāda pati, kādu izmanto LZV modelim.\n",
    "\n",
    "Lai varētu izmantot pārneses mācīšanās stratēģiju, ASL modeli ir nepieciešams rekonstruēt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa19cfd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reconstructing ASL model with corrected architecture to load weights from: c:\\Users\\liene\\Documents\\GitHub\\LZV-CSLR\\models\\asl\\42\\cslr_model_best_42.keras\n",
      "\n",
      " ASL architecture: input shape (None, None, 42, 3) and 60 ASL classes\n",
      "WARNING:tensorflow:From c:\\Users\\liene\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:204: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\liene\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\legacy\\backend.py:666: The name tf.nn.ctc_loss is deprecated. Please use tf.compat.v1.nn.ctc_loss instead.\n",
      "\n",
      "Corrected ASL architecture (training structure) reconstructed.\n",
      "Loading weights from c:\\Users\\liene\\Documents\\GitHub\\LZV-CSLR\\models\\asl\\42\\cslr_model_best_42.keras into corrected ASL training model shell...\n",
      "Weights loaded successfully into the corrected ASL model shell.\n",
      "Defining the base for fine-tuning (feature extractor part of the ASL model)...\n",
      "Fetched 'input_landmarks' from model.input dict: <KerasTensor shape=(None, None, 42, 3), dtype=float32, sparse=False, name=input_landmarks>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"asl_loaded_feature_base\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"asl_loaded_feature_base\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_landmarks (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">42</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ reshape_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">80,768</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batchnorm_conv                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bilstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">98,816</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batchnorm_lstm1                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_landmarks (\u001b[38;5;33mInputLayer\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m42\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ reshape_input (\u001b[38;5;33mReshape\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m126\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_layer (\u001b[38;5;33mConv1D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │        \u001b[38;5;34m80,768\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batchnorm_conv                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bilstm_1 (\u001b[38;5;33mBidirectional\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │        \u001b[38;5;34m98,816\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batchnorm_lstm1                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">180,608</span> (705.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m180,608\u001b[0m (705.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">180,096</span> (703.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m180,096\u001b[0m (703.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> (2.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m512\u001b[0m (2.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base model for fine-tuning created.\n",
      "\n",
      "Building fine-tune model with 46 LZV classes (incl. blank) using the provided feature_extractor_base\n",
      "Feature extractor base 'asl_loaded_feature_base' has been INITIALLY set to trainable=False.\n",
      "\n",
      "LZV Fine-tuning and Prediction models built.\n",
      "\n",
      "--- Final LZV Fine-tuning Model Summary ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\liene\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\models\\functional.py:106: UserWarning: When providing `inputs` as a dict, all keys in the dict must match the names of the corresponding tensors. Received key 'input_labels' mapping to value <KerasTensor shape=(None, None), dtype=int64, sparse=False, name=input_labels_lzv> which has name 'input_labels_lzv'. Change the tensor name to 'input_labels' (via `Input(..., name='input_labels')`)\n",
      "  warnings.warn(\n",
      "c:\\Users\\liene\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\models\\functional.py:106: UserWarning: When providing `inputs` as a dict, all keys in the dict must match the names of the corresponding tensors. Received key 'input_landmark_length' mapping to value <KerasTensor shape=(None, 1), dtype=int64, sparse=False, name=input_landmark_length_lzv> which has name 'input_landmark_length_lzv'. Change the tensor name to 'input_landmark_length' (via `Input(..., name='input_landmark_length')`)\n",
      "  warnings.warn(\n",
      "c:\\Users\\liene\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\models\\functional.py:106: UserWarning: When providing `inputs` as a dict, all keys in the dict must match the names of the corresponding tensors. Received key 'input_label_length' mapping to value <KerasTensor shape=(None, 1), dtype=int64, sparse=False, name=input_label_length_lzv> which has name 'input_label_length_lzv'. Change the tensor name to 'input_label_length' (via `Input(..., name='input_label_length')`)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"cslr_lzv_fine_tune_training_model\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"cslr_lzv_fine_tune_training_model\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                      </span>┃<span style=\"font-weight: bold\"> Output Shape                 </span>┃<span style=\"font-weight: bold\">           Param # </span>┃<span style=\"font-weight: bold\"> Connected to              </span>\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
       "│ input_landmarks (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">42</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)          │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                         \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ reshape_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>)            │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_landmarks[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ conv1d_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │            <span style=\"color: #00af00; text-decoration-color: #00af00\">80,768</span> │ reshape_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batchnorm_conv                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv1d_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ bilstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │            <span style=\"color: #00af00; text-decoration-color: #00af00\">98,816</span> │ batchnorm_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batchnorm_lstm1                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ bilstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ input_landmark_length_lzv         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                    │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                         \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                      │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ input_label_length_lzv            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                    │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                         \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                      │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ input_labels_lzv (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)                 │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                         \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ output_dense_softmax_lzv          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">5,934</span> │ batchnorm_lstm1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)                 │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ squeeze_lm_len_lzv (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)                       │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_landmark_length_lzv[\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ squeeze_ph_len_lzv (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)                       │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_label_length_lzv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ ctc_loss_lzv (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                    │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_labels_lzv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   \n",
       "│                                   │                              │                   │ output_dense_softmax_lzv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>\n",
       "│                                   │                              │                   │ squeeze_lm_len_lzv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], \n",
       "│                                   │                              │                   │ squeeze_ph_len_lzv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  \n",
       "└───────────────────────────────────┴──────────────────────────────┴───────────────────┴───────────────────────────\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape                \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m          Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
       "│ input_landmarks (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m42\u001b[0m, \u001b[38;5;34m3\u001b[0m)          │                 \u001b[38;5;34m0\u001b[0m │ -                         \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ reshape_input (\u001b[38;5;33mReshape\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m126\u001b[0m)            │                 \u001b[38;5;34m0\u001b[0m │ input_landmarks[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ conv1d_layer (\u001b[38;5;33mConv1D\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │            \u001b[38;5;34m80,768\u001b[0m │ reshape_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batchnorm_conv                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │               \u001b[38;5;34m512\u001b[0m │ conv1d_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        \n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ bilstm_1 (\u001b[38;5;33mBidirectional\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │            \u001b[38;5;34m98,816\u001b[0m │ batchnorm_conv[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batchnorm_lstm1                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │               \u001b[38;5;34m512\u001b[0m │ bilstm_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            \n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ input_landmark_length_lzv         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                    │                 \u001b[38;5;34m0\u001b[0m │ -                         \n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)                      │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ input_label_length_lzv            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                    │                 \u001b[38;5;34m0\u001b[0m │ -                         \n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)                      │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ input_labels_lzv (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)                 │                 \u001b[38;5;34m0\u001b[0m │ -                         \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ output_dense_softmax_lzv          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m46\u001b[0m)             │             \u001b[38;5;34m5,934\u001b[0m │ batchnorm_lstm1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     \n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)                 │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ squeeze_lm_len_lzv (\u001b[38;5;33mLambda\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m)                       │                 \u001b[38;5;34m0\u001b[0m │ input_landmark_length_lzv[\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ squeeze_ph_len_lzv (\u001b[38;5;33mLambda\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m)                       │                 \u001b[38;5;34m0\u001b[0m │ input_label_length_lzv[\u001b[38;5;34m0\u001b[0m][\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ ctc_loss_lzv (\u001b[38;5;33mLambda\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                    │                 \u001b[38;5;34m0\u001b[0m │ input_labels_lzv[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   \n",
       "│                                   │                              │                   │ output_dense_softmax_lzv[\u001b[38;5;34m0\u001b[0m\n",
       "│                                   │                              │                   │ squeeze_lm_len_lzv[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], \n",
       "│                                   │                              │                   │ squeeze_ph_len_lzv[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  \n",
       "└───────────────────────────────────┴──────────────────────────────┴───────────────────┴───────────────────────────\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">186,542</span> (728.68 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m186,542\u001b[0m (728.68 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,934</span> (23.18 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,934\u001b[0m (23.18 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">180,608</span> (705.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m180,608\u001b[0m (705.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final LZV Prediction Model Summary ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"cslr_lzv_prediction_model\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"cslr_lzv_prediction_model\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                               </span>┃<span style=\"font-weight: bold\"> Output Shape                    </span>┃<span style=\"font-weight: bold\">           Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_landmarks (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">42</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)             │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├────────────────────────────────────────────┼─────────────────────────────────┼───────────────────┤\n",
       "│ reshape_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>)               │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├────────────────────────────────────────────┼─────────────────────────────────┼───────────────────┤\n",
       "│ conv1d_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │            <span style=\"color: #00af00; text-decoration-color: #00af00\">80,768</span> │\n",
       "├────────────────────────────────────────────┼─────────────────────────────────┼───────────────────┤\n",
       "│ batchnorm_conv (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "├────────────────────────────────────────────┼─────────────────────────────────┼───────────────────┤\n",
       "│ bilstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │            <span style=\"color: #00af00; text-decoration-color: #00af00\">98,816</span> │\n",
       "├────────────────────────────────────────────┼─────────────────────────────────┼───────────────────┤\n",
       "│ batchnorm_lstm1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "├────────────────────────────────────────────┼─────────────────────────────────┼───────────────────┤\n",
       "│ output_dense_softmax_lzv (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>)                │             <span style=\"color: #00af00; text-decoration-color: #00af00\">5,934</span> │\n",
       "└────────────────────────────────────────────┴─────────────────────────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                              \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m          Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_landmarks (\u001b[38;5;33mInputLayer\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m42\u001b[0m, \u001b[38;5;34m3\u001b[0m)             │                 \u001b[38;5;34m0\u001b[0m │\n",
       "├────────────────────────────────────────────┼─────────────────────────────────┼───────────────────┤\n",
       "│ reshape_input (\u001b[38;5;33mReshape\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m126\u001b[0m)               │                 \u001b[38;5;34m0\u001b[0m │\n",
       "├────────────────────────────────────────────┼─────────────────────────────────┼───────────────────┤\n",
       "│ conv1d_layer (\u001b[38;5;33mConv1D\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │            \u001b[38;5;34m80,768\u001b[0m │\n",
       "├────────────────────────────────────────────┼─────────────────────────────────┼───────────────────┤\n",
       "│ batchnorm_conv (\u001b[38;5;33mBatchNormalization\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │               \u001b[38;5;34m512\u001b[0m │\n",
       "├────────────────────────────────────────────┼─────────────────────────────────┼───────────────────┤\n",
       "│ bilstm_1 (\u001b[38;5;33mBidirectional\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │            \u001b[38;5;34m98,816\u001b[0m │\n",
       "├────────────────────────────────────────────┼─────────────────────────────────┼───────────────────┤\n",
       "│ batchnorm_lstm1 (\u001b[38;5;33mBatchNormalization\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │               \u001b[38;5;34m512\u001b[0m │\n",
       "├────────────────────────────────────────────┼─────────────────────────────────┼───────────────────┤\n",
       "│ output_dense_softmax_lzv (\u001b[38;5;33mTimeDistributed\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m46\u001b[0m)                │             \u001b[38;5;34m5,934\u001b[0m │\n",
       "└────────────────────────────────────────────┴─────────────────────────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">186,542</span> (728.68 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m186,542\u001b[0m (728.68 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,934</span> (23.18 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,934\u001b[0m (23.18 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">180,608</span> (705.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m180,608\u001b[0m (705.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.config import enable_unsafe_deserialization\n",
    "enable_unsafe_deserialization()\n",
    "\n",
    "def build_asl_model_architecture_corrected(asl_num_landmarks, asl_landmark_dims, num_classes_asl, asl_num_lstm_units, asl_num_conv_filters, asl_conv_kernel_size, asl_conv_strides):\n",
    "    print(f\"\\n ASL architecture: input shape (None, None, {asl_num_landmarks}, {asl_landmark_dims}) and {num_classes_asl} ASL classes\")\n",
    "    \n",
    "    input_landmarks = keras.Input(shape=(None, asl_num_landmarks, asl_landmark_dims), dtype=tf.float32, name='input_landmarks')\n",
    "    input_labels = keras.Input(shape=(None,), dtype=tf.int64, name='input_labels')\n",
    "    input_landmark_length = keras.Input(shape=(1,), dtype=tf.int64, name='input_landmark_length')\n",
    "    input_label_length = keras.Input(shape=(1,), dtype=tf.int64, name='input_label_length')\n",
    "\n",
    "    x = layers.Reshape((-1, asl_num_landmarks * asl_landmark_dims), name='reshape_input')(input_landmarks)\n",
    "    \n",
    "    x = layers.Conv1D(filters=asl_num_conv_filters, kernel_size=asl_conv_kernel_size, strides=asl_conv_strides,\n",
    "                      padding='same', activation='relu', name='conv1d_layer')(x)\n",
    "    x = layers.BatchNormalization(name='batchnorm_conv')(x)\n",
    "    \n",
    "    x = layers.Bidirectional(layers.LSTM(asl_num_lstm_units, return_sequences=True), name='bilstm_1')(x)\n",
    "\n",
    "    bilstm_output = x\n",
    "    x = layers.BatchNormalization(name='batchnorm_lstm1')(x)\n",
    "    batchnorm_lstm1_output = x\n",
    "\n",
    "    output_logits = layers.TimeDistributed(layers.Dense(num_classes_asl, activation='softmax'), name='output_dense_softmax')(batchnorm_lstm1_output)\n",
    "    \n",
    "    squeezed_landmark_length = layers.Lambda(lambda t: tf.squeeze(t, axis=-1), name='squeeze_lm_len')(input_landmark_length)\n",
    "    squeezed_label_length = layers.Lambda(lambda t: tf.squeeze(t, axis=-1), name='squeeze_ph_len')(input_label_length)\n",
    "    \n",
    "    loss_output = tf.keras.layers.Lambda(\n",
    "        lambda args_in: tf.keras.backend.ctc_batch_cost(\n",
    "            y_true=args_in[0], y_pred=args_in[1],\n",
    "            input_length=tf.expand_dims(args_in[2], axis=-1), label_length=tf.expand_dims(args_in[3], axis=-1)\n",
    "        ), name='ctc_loss'\n",
    "    )([input_labels, output_logits, squeezed_landmark_length, squeezed_label_length])\n",
    "    \n",
    "    reconstructed_asl_training_model = keras.Model(\n",
    "        inputs={'input_landmarks': input_landmarks, 'input_labels': input_labels,\n",
    "                'input_landmark_length': input_landmark_length, 'input_label_length': input_label_length},\n",
    "        outputs=loss_output, name='cslr_training_model'\n",
    "    )\n",
    "    \n",
    "    print(\"Corrected ASL architecture (training structure) reconstructed.\")\n",
    "    return reconstructed_asl_training_model\n",
    "\n",
    "\n",
    "asl_training_model_base_loaded = None\n",
    "\n",
    "try:\n",
    "    print(f\"Reconstructing ASL model with corrected architecture to load weights from: {ASL_MODEL_PATH}\")\n",
    "    \n",
    "    reconstructed_asl_model_shell = build_asl_model_architecture_corrected(\n",
    "        asl_num_landmarks=ASL_USED_LANDMARKS_COUNT,\n",
    "        asl_landmark_dims=LANDMARK_DIMS,\n",
    "        num_classes_asl=ASL_NUM_CLASSES_WITH_BLANK,\n",
    "        asl_num_lstm_units=NUM_LSTM_UNITS,\n",
    "        asl_num_conv_filters=NUM_CONV_FILTERS,\n",
    "        asl_conv_kernel_size=CONV_KERNEL_SIZE,\n",
    "        asl_conv_strides=CONV_STRIDES\n",
    "    )\n",
    "\n",
    "    print(f\"Loading weights from {ASL_MODEL_PATH} into corrected ASL training model shell...\")\n",
    "    reconstructed_asl_model_shell.load_weights(ASL_MODEL_PATH)\n",
    "    print(\"Weights loaded successfully into the corrected ASL model shell.\")\n",
    "\n",
    "    print(\"Defining the base for fine-tuning (feature extractor part of the ASL model)...\")\n",
    "\n",
    "    if 'input_landmarks' in reconstructed_asl_model_shell.input:\n",
    "        feature_base_input = reconstructed_asl_model_shell.input['input_landmarks']\n",
    "        print(f\"Fetched 'input_landmarks' from model.input dict: {feature_base_input}\")\n",
    "    else:\n",
    "        raise ValueError(\"'input_landmarks' not found as a key in reconstructed_asl_model_shell.input dictionary.\")\n",
    "\n",
    "    if feature_base_input is None or (isinstance(feature_base_input, list) and not feature_base_input):\n",
    "        raise ValueError(f\"feature_base_input is None or empty. Value: {feature_base_input}\")\n",
    "\n",
    "    feature_base_output = reconstructed_asl_model_shell.get_layer('batchnorm_lstm1').output\n",
    "\n",
    "    asl_training_model_base_loaded = keras.Model(\n",
    "        inputs=feature_base_input,\n",
    "        outputs=feature_base_output,\n",
    "        name=\"asl_loaded_feature_base\"\n",
    "    )\n",
    "    asl_training_model_base_loaded.summary()\n",
    "    print(\"Base model for fine-tuning created.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    raise SystemExit(1)\n",
    "    \n",
    "\n",
    "def build_cslr_fine_tune_model(feature_extractor_base, num_lzv_classes_with_blank):\n",
    "    print(f\"\\nBuilding fine-tune model with {num_lzv_classes_with_blank} LZV classes (incl. blank) using the provided feature_extractor_base\")\n",
    "    \n",
    "    feature_extractor_base.trainable = False \n",
    "    print(f\"Feature extractor base '{feature_extractor_base.name}' has been INITIALLY set to trainable=False.\")\n",
    "\n",
    "    input_landmarks_lzv = feature_extractor_base.input\n",
    "    input_labels_lzv = keras.Input(shape=(None,), dtype=tf.int64, name='input_labels_lzv')\n",
    "    input_landmark_length_lzv = keras.Input(shape=(1,), dtype=tf.int64, name='input_landmark_length_lzv')\n",
    "    input_label_length_lzv = keras.Input(shape=(1,), dtype=tf.int64, name='input_label_length_lzv')\n",
    "\n",
    "    base_output = feature_extractor_base.output\n",
    "    output_logits_lzv = layers.TimeDistributed(\n",
    "        layers.Dense(num_lzv_classes_with_blank, activation='softmax'), name='output_dense_softmax_lzv'\n",
    "    )(base_output)\n",
    "    \n",
    "    squeezed_landmark_length_lzv = layers.Lambda(lambda t: tf.squeeze(t, axis=-1), name='squeeze_lm_len_lzv')(input_landmark_length_lzv)\n",
    "    squeezed_label_length_lzv = layers.Lambda(lambda t: tf.squeeze(t, axis=-1), name='squeeze_ph_len_lzv')(input_label_length_lzv)\n",
    "\n",
    "    loss_output_lzv = tf.keras.layers.Lambda(\n",
    "        lambda args: tf.keras.backend.ctc_batch_cost(\n",
    "            y_true=args[0], y_pred=args[1],\n",
    "            input_length=tf.expand_dims(args[2], axis=-1), label_length=tf.expand_dims(args[3], axis=-1)\n",
    "        ), name='ctc_loss_lzv'\n",
    "    )([input_labels_lzv, output_logits_lzv, squeezed_landmark_length_lzv, squeezed_label_length_lzv])\n",
    "\n",
    "    fine_tune_training_model = keras.Model(\n",
    "        inputs={'input_landmarks': input_landmarks_lzv, 'input_labels': input_labels_lzv,\n",
    "                'input_landmark_length': input_landmark_length_lzv, 'input_label_length': input_label_length_lzv},\n",
    "        outputs=loss_output_lzv, name='cslr_lzv_fine_tune_training_model'\n",
    "    )\n",
    "    lzv_prediction_model = keras.Model(inputs=input_landmarks_lzv, outputs=output_logits_lzv, name='cslr_lzv_prediction_model')\n",
    "    print(\"\\nLZV Fine-tuning and Prediction models built.\")\n",
    "    return fine_tune_training_model, lzv_prediction_model\n",
    "\n",
    "\n",
    "if asl_training_model_base_loaded is not None:\n",
    "    training_model, prediction_model = build_cslr_fine_tune_model(\n",
    "        feature_extractor_base=asl_training_model_base_loaded,\n",
    "        num_lzv_classes_with_blank=NUM_CLASSES_WITH_BLANK\n",
    "    )\n",
    "    print(\"\\n--- Final LZV Fine-tuning Model Summary ---\")\n",
    "    training_model.summary(line_length=120)\n",
    "    print(\"\\n--- Final LZV Prediction Model Summary ---\")\n",
    "    prediction_model.summary(line_length=100)\n",
    "else:\n",
    "    print(\"Error: ASL model was not reconstrued properly.\")\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bccf45a7",
   "metadata": {},
   "source": [
    "### 6. Modeļa slāņu atsaldēšana\n",
    "\n",
    "Konfigurācija modeļa pakāpeniskai 3 fāžu slāņu atsaldēšanai."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3abe4a43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Unfroze layer: batchnorm_conv\n",
      "  Unfroze layer: bilstm_1\n",
      "  Unfroze layer: batchnorm_lstm1\n",
      "Trainable status of 3 base layers updated.\n",
      "\n",
      "Summary of 'training_model' AFTER adjusting layer trainability & recompiling:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"cslr_lzv_fine_tune_training_model\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"cslr_lzv_fine_tune_training_model\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                      </span>┃<span style=\"font-weight: bold\"> Output Shape                 </span>┃<span style=\"font-weight: bold\">           Param # </span>┃<span style=\"font-weight: bold\"> Connected to              </span>\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
       "│ input_landmarks (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">42</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)          │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                         \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ reshape_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>)            │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_landmarks[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ conv1d_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │            <span style=\"color: #00af00; text-decoration-color: #00af00\">80,768</span> │ reshape_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batchnorm_conv                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv1d_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ bilstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │            <span style=\"color: #00af00; text-decoration-color: #00af00\">98,816</span> │ batchnorm_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batchnorm_lstm1                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ bilstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ input_landmark_length_lzv         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                    │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                         \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                      │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ input_label_length_lzv            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                    │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                         \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                      │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ input_labels_lzv (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)                 │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                         \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ output_dense_softmax_lzv          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">5,934</span> │ batchnorm_lstm1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)                 │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ squeeze_lm_len_lzv (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)                       │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_landmark_length_lzv[\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ squeeze_ph_len_lzv (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)                       │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_label_length_lzv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ ctc_loss_lzv (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                    │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_labels_lzv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   \n",
       "│                                   │                              │                   │ output_dense_softmax_lzv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>\n",
       "│                                   │                              │                   │ squeeze_lm_len_lzv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], \n",
       "│                                   │                              │                   │ squeeze_ph_len_lzv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  \n",
       "└───────────────────────────────────┴──────────────────────────────┴───────────────────┴───────────────────────────\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape                \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m          Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
       "│ input_landmarks (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m42\u001b[0m, \u001b[38;5;34m3\u001b[0m)          │                 \u001b[38;5;34m0\u001b[0m │ -                         \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ reshape_input (\u001b[38;5;33mReshape\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m126\u001b[0m)            │                 \u001b[38;5;34m0\u001b[0m │ input_landmarks[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ conv1d_layer (\u001b[38;5;33mConv1D\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │            \u001b[38;5;34m80,768\u001b[0m │ reshape_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batchnorm_conv                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │               \u001b[38;5;34m512\u001b[0m │ conv1d_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        \n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ bilstm_1 (\u001b[38;5;33mBidirectional\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │            \u001b[38;5;34m98,816\u001b[0m │ batchnorm_conv[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batchnorm_lstm1                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │               \u001b[38;5;34m512\u001b[0m │ bilstm_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            \n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ input_landmark_length_lzv         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                    │                 \u001b[38;5;34m0\u001b[0m │ -                         \n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)                      │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ input_label_length_lzv            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                    │                 \u001b[38;5;34m0\u001b[0m │ -                         \n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)                      │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ input_labels_lzv (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)                 │                 \u001b[38;5;34m0\u001b[0m │ -                         \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ output_dense_softmax_lzv          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m46\u001b[0m)             │             \u001b[38;5;34m5,934\u001b[0m │ batchnorm_lstm1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     \n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)                 │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ squeeze_lm_len_lzv (\u001b[38;5;33mLambda\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m)                       │                 \u001b[38;5;34m0\u001b[0m │ input_landmark_length_lzv[\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ squeeze_ph_len_lzv (\u001b[38;5;33mLambda\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m)                       │                 \u001b[38;5;34m0\u001b[0m │ input_label_length_lzv[\u001b[38;5;34m0\u001b[0m][\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ ctc_loss_lzv (\u001b[38;5;33mLambda\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                    │                 \u001b[38;5;34m0\u001b[0m │ input_labels_lzv[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   \n",
       "│                                   │                              │                   │ output_dense_softmax_lzv[\u001b[38;5;34m0\u001b[0m\n",
       "│                                   │                              │                   │ squeeze_lm_len_lzv[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], \n",
       "│                                   │                              │                   │ squeeze_ph_len_lzv[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  \n",
       "└───────────────────────────────────┴──────────────────────────────┴───────────────────┴───────────────────────────\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">186,542</span> (728.68 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m186,542\u001b[0m (728.68 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">105,262</span> (411.18 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m105,262\u001b[0m (411.18 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">81,280</span> (317.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m81,280\u001b[0m (317.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "UNFREEZE_BN_IN_BASE = True\n",
    "UNFREEZE_LAST_BILSTM_IN_BASE = True\n",
    "UNFREEZE_CONV1D_IN_BASE = False\n",
    "\n",
    "if 'training_model' in locals() and training_model is not None:\n",
    "    made_layer_trainable_changes = 0\n",
    "    for layer in training_model.layers:\n",
    "        if layer.name == 'conv1d_layer':\n",
    "            if layer.trainable and not UNFREEZE_CONV1D_IN_BASE:\n",
    "                layer.trainable = False\n",
    "                made_layer_trainable_changes +=1\n",
    "                print(f\"  Froze layer: {layer.name}\")\n",
    "            elif not layer.trainable and UNFREEZE_CONV1D_IN_BASE:\n",
    "                layer.trainable = True\n",
    "                made_layer_trainable_changes +=1\n",
    "                print(f\"  Unfroze layer: {layer.name}\")\n",
    "        elif layer.name == 'bilstm_1':\n",
    "            if not layer.trainable and UNFREEZE_LAST_BILSTM_IN_BASE:\n",
    "                layer.trainable = True\n",
    "                made_layer_trainable_changes +=1\n",
    "                print(f\"  Unfroze layer: {layer.name}\")\n",
    "            elif layer.trainable and not UNFREEZE_LAST_BILSTM_IN_BASE:\n",
    "                layer.trainable = False\n",
    "                made_layer_trainable_changes +=1\n",
    "                print(f\"  Froze layer: {layer.name}\")\n",
    "        elif layer.name in ['batchnorm_conv', 'batchnorm_lstm1']:\n",
    "            if not layer.trainable and UNFREEZE_BN_IN_BASE:\n",
    "                layer.trainable = True\n",
    "                made_layer_trainable_changes +=1\n",
    "                print(f\"  Unfroze layer: {layer.name}\")\n",
    "            elif layer.trainable and not UNFREEZE_BN_IN_BASE:\n",
    "                layer.trainable = False\n",
    "                made_layer_trainable_changes +=1\n",
    "                print(f\"  Froze layer: {layer.name}\")\n",
    "\n",
    "    if made_layer_trainable_changes > 0:\n",
    "        print(f\"Trainable status of {made_layer_trainable_changes} base layers updated.\")\n",
    "    else:\n",
    "        print(\"No changes needed.\")\n",
    "\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=LEARNING_RATE, clipnorm=1.0) \n",
    "    training_model.compile(optimizer=optimizer, loss=lambda y_true, y_pred: y_pred)\n",
    "\n",
    "    print(\"\\nSummary of 'training_model' AFTER adjusting layer trainability & recompiling:\")\n",
    "    training_model.summary(line_length=120) # Trenējamie parametriem vajadzētu būt: ~105,262\n",
    "else:\n",
    "    print(\"Error: 'training_model' not defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc0105c",
   "metadata": {},
   "source": [
    "### 7. WER metrika\n",
    "\n",
    "Modeļu novērtēšanai tiek izmantota WER (word error rate) metrika, kas nepieciešama modeļa apmācībā, lai novērtētu precizitāti uz validācijas kopu.\n",
    "\n",
    "Jo WER ir tuvāks 0, jo modelis spēj atpazīt zīmes labāk.\n",
    "\n",
    "Pēc noklusējuma tiek izmantots alkatīgais algoritms (greedy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca6b1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WERCallback(Callback):\n",
    "    # Inicializē WERCallback\n",
    "    def __init__(self, prediction_model, validation_dataset, validation_steps,\n",
    "                 inverse_char_map, epoch_frequency=1, use_beam_search=False, log_prefix='val_wer'):\n",
    "        super().__init__()\n",
    "        self.prediction_model = prediction_model\n",
    "        self.validation_dataset = validation_dataset\n",
    "        self.validation_steps = validation_steps\n",
    "        self.inverse_char_map = inverse_char_map\n",
    "        self.epoch_frequency = max(1, epoch_frequency)\n",
    "        self.use_beam_search = use_beam_search\n",
    "        self.log_prefix = log_prefix\n",
    "        self.best_metric = float('inf')\n",
    "        self.best_metric_epoch = 0\n",
    "        print(f\"\\nWERCallback initialized:\")\n",
    "        print(f\"  Decoder: {'Beam Search' if self.use_beam_search else 'Greedy'}\")\n",
    "        print(f\"  Metric Log Name: {self.log_prefix}\")\n",
    "\n",
    "    # Dekodē prognozes no modeļa un atgriež indeksu secību\n",
    "    def decode_batch_predictions(self, y_pred_softmax):\n",
    "        y_pred_time_major = tf.transpose(y_pred_softmax, perm=[1, 0, 2])\n",
    "        pred_seq_len = tf.cast(tf.fill(tf.shape(y_pred_softmax)[:1], tf.shape(y_pred_softmax)[1]), dtype=tf.int32)\n",
    "\n",
    "        if self.use_beam_search:\n",
    "            decoded_sparse_list, _ = tf.nn.ctc_beam_search_decoder(\n",
    "                y_pred_time_major, sequence_length=pred_seq_len, beam_width=10, top_paths=1)\n",
    "            decoded_sparse = decoded_sparse_list[0]\n",
    "        else:\n",
    "            decoded_list, _ = tf.nn.ctc_greedy_decoder(\n",
    "                y_pred_time_major, sequence_length=pred_seq_len)\n",
    "            decoded_sparse = decoded_list[0]\n",
    "\n",
    "        dense_decoded = tf.sparse.to_dense(decoded_sparse, default_value=-1).numpy()\n",
    "        return dense_decoded\n",
    "\n",
    "    # Izmanto vārdnīcu, lai indeksus pārvērstu uz zīmēm\n",
    "    def map_indices_to_signs(self, index_sequence):\n",
    "        filtered_sequence = [int(idx) for idx in index_sequence if idx != -1]\n",
    "        return \" \".join([self.inverse_char_map.get(idx, '?') for idx in filtered_sequence])\n",
    "\n",
    "    # Notiek pēc katras epohas beigām\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        if (epoch + 1) % self.epoch_frequency == 0:\n",
    "            print(f\"\\nEpoch {epoch + 1}: Calculating Validation WER/CER...\")\n",
    "            all_true_phrases_str = []\n",
    "            all_pred_phrases_str = []\n",
    "            successfully_processed_pairs = 0\n",
    "\n",
    "            if self.validation_dataset is None:\n",
    "                print(\"  Error: Validation dataset not provided. Skipping WER.\")\n",
    "                current_metric = float('inf')\n",
    "            else:\n",
    "                iterator = iter(self.validation_dataset)\n",
    "                steps_done = 0\n",
    "                try:\n",
    "                    while self.validation_steps is None or steps_done < self.validation_steps:\n",
    "                        batch_landmarks, batch_phrase, batch_landmark_len, batch_phrase_len = next(iterator)\n",
    "                        \n",
    "                        y_pred_softmax = None\n",
    "                        decoded_indices_batch = None\n",
    "                        try:\n",
    "                            y_pred_softmax = self.prediction_model.predict(batch_landmarks, verbose=0)\n",
    "                            decoded_indices_batch = self.decode_batch_predictions(y_pred_softmax)\n",
    "                        except Exception as e_batch_pred_decode:\n",
    "                            print(f\"  Error during batch-level prediction/decoding in batch {steps_done}: {e_batch_pred_decode}\")\n",
    "                            pass\n",
    "\n",
    "                        for j in range(tf.shape(batch_landmarks)[0].numpy()):\n",
    "                            sample_processed_successfully = False\n",
    "                            try:\n",
    "                                true_idxs_padded = batch_phrase[j]\n",
    "                                true_len_scalar = batch_phrase_len[j].numpy()\n",
    "                                if isinstance(true_len_scalar, np.ndarray) and true_len_scalar.ndim > 0:\n",
    "                                    true_len_scalar = true_len_scalar[0]\n",
    "                                true_idxs = true_idxs_padded[:true_len_scalar].numpy()\n",
    "                                true_str = self.map_indices_to_signs(true_idxs)\n",
    "                                if not true_str: true_str = \"<empty_true>\"\n",
    "\n",
    "                                if decoded_indices_batch is not None and j < len(decoded_indices_batch):\n",
    "                                    pred_idxs = decoded_indices_batch[j]\n",
    "                                    pred_str = self.map_indices_to_signs(pred_idxs)\n",
    "                                    if not pred_str: pred_str = \"<empty_pred>\"\n",
    "                                else:\n",
    "                                    pred_str = \"<pred_decode_error>\"\n",
    "                                    print(f\"  WARNING: Issue with decoded_indices_batch for sample {j} in batch {steps_done}.\")\n",
    "\n",
    "\n",
    "                                all_true_phrases_str.append(true_str)\n",
    "                                all_pred_phrases_str.append(pred_str)\n",
    "                                successfully_processed_pairs += 1\n",
    "                                sample_processed_successfully = True\n",
    "\n",
    "                                if steps_done == 0 and j == 0 and sample_processed_successfully:\n",
    "                                    print(f\"  Example True: '{true_str}'\")\n",
    "                                    print(f\"  Example Pred: '{pred_str}'\")\n",
    "\n",
    "                            except Exception as e_sample:\n",
    "                                print(f\"  ERROR processing sample {j} in batch {steps_done}: {e_sample}\")\n",
    "                                all_true_phrases_str.append(f\"<error_true_s{j}_b{steps_done}>\")\n",
    "                                all_pred_phrases_str.append(f\"<error_pred_s{j}_b{steps_done}>\")\n",
    "                                successfully_processed_pairs +=1\n",
    "\n",
    "                        steps_done += 1\n",
    "                \n",
    "                except tf.errors.OutOfRangeError:\n",
    "                    if self.validation_steps is None: print(\"  Reached end of validation dataset.\")\n",
    "                except StopIteration:\n",
    "                    print(\"  Validation iterator exhausted.\")\n",
    "                except Exception as e_outer:\n",
    "                    print(f\"  Error during validation data iteration: {e_outer}\")\n",
    "\n",
    "                if not all_true_phrases_str or not all_pred_phrases_str or len(all_true_phrases_str) != len(all_pred_phrases_str):\n",
    "                    print(\"  CRITICAL ERROR JIWER: Mismatch in lengths or empty lists for true/pred phrases. Skipping WER calculation for this epoch.\")\n",
    "                    current_metric = float('inf')\n",
    "                else:\n",
    "                    try:\n",
    "                        current_metric = jiwer.wer(all_true_phrases_str, all_pred_phrases_str)\n",
    "                        print(f\"  Successfully calculated WER: {current_metric:.4f} using {len(all_true_phrases_str)} pairs.\")\n",
    "                    except Exception as e_jiwer:\n",
    "                        print(f\"  ERROR during jiwer.wer calculation: {e_jiwer}\")\n",
    "                        current_metric = float('inf')\n",
    "            \n",
    "            logs[self.log_prefix] = current_metric\n",
    "\n",
    "            # Labākās metrikas izvade\n",
    "            if current_metric < self.best_metric:\n",
    "                print(f\"  New best validation WER: {current_metric:.4f} (previous: {self.best_metric:.4f} at epoch {self.best_metric_epoch})\")\n",
    "                self.best_metric = current_metric\n",
    "                self.best_metric_epoch = epoch + 1\n",
    "            elif current_metric != float('inf'):\n",
    "                 print(f\"  Validation WER ({current_metric:.4f}) did not improve. Best: {self.best_metric:.4f} at epoch {self.best_metric_epoch}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28573fa0",
   "metadata": {},
   "source": [
    "### 8. LZV modeļa nokompilēšana\n",
    "\n",
    "Tiek izmantots gan trenēšanas modelis (training), gan modelis minējumu veikšanai (predictions). Minējumu modelis neiekļauj CTC slāni un lambdu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "298ae10c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LZV Fine-tuning model compiled successfully.\n",
      "\n",
      "--- LZV Training Model Summary (Fine-tuning) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"cslr_lzv_fine_tune_training_model\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"cslr_lzv_fine_tune_training_model\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                      </span>┃<span style=\"font-weight: bold\"> Output Shape                 </span>┃<span style=\"font-weight: bold\">           Param # </span>┃<span style=\"font-weight: bold\"> Connected to              </span>\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
       "│ input_landmarks (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">42</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)          │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                         \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ reshape_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>)            │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_landmarks[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ conv1d_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │            <span style=\"color: #00af00; text-decoration-color: #00af00\">80,768</span> │ reshape_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batchnorm_conv                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv1d_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ bilstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │            <span style=\"color: #00af00; text-decoration-color: #00af00\">98,816</span> │ batchnorm_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batchnorm_lstm1                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ bilstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ input_landmark_length_lzv         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                    │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                         \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                      │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ input_label_length_lzv            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                    │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                         \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                      │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ input_labels_lzv (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)                 │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                         \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ output_dense_softmax_lzv          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">5,934</span> │ batchnorm_lstm1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)                 │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ squeeze_lm_len_lzv (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)                       │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_landmark_length_lzv[\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ squeeze_ph_len_lzv (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)                       │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_label_length_lzv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ ctc_loss_lzv (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                    │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_labels_lzv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   \n",
       "│                                   │                              │                   │ output_dense_softmax_lzv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>\n",
       "│                                   │                              │                   │ squeeze_lm_len_lzv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], \n",
       "│                                   │                              │                   │ squeeze_ph_len_lzv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  \n",
       "└───────────────────────────────────┴──────────────────────────────┴───────────────────┴───────────────────────────\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape                \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m          Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
       "│ input_landmarks (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m42\u001b[0m, \u001b[38;5;34m3\u001b[0m)          │                 \u001b[38;5;34m0\u001b[0m │ -                         \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ reshape_input (\u001b[38;5;33mReshape\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m126\u001b[0m)            │                 \u001b[38;5;34m0\u001b[0m │ input_landmarks[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ conv1d_layer (\u001b[38;5;33mConv1D\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │            \u001b[38;5;34m80,768\u001b[0m │ reshape_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batchnorm_conv                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │               \u001b[38;5;34m512\u001b[0m │ conv1d_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        \n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ bilstm_1 (\u001b[38;5;33mBidirectional\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │            \u001b[38;5;34m98,816\u001b[0m │ batchnorm_conv[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batchnorm_lstm1                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │               \u001b[38;5;34m512\u001b[0m │ bilstm_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            \n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ input_landmark_length_lzv         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                    │                 \u001b[38;5;34m0\u001b[0m │ -                         \n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)                      │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ input_label_length_lzv            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                    │                 \u001b[38;5;34m0\u001b[0m │ -                         \n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)                      │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ input_labels_lzv (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)                 │                 \u001b[38;5;34m0\u001b[0m │ -                         \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ output_dense_softmax_lzv          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m46\u001b[0m)             │             \u001b[38;5;34m5,934\u001b[0m │ batchnorm_lstm1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     \n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)                 │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ squeeze_lm_len_lzv (\u001b[38;5;33mLambda\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m)                       │                 \u001b[38;5;34m0\u001b[0m │ input_landmark_length_lzv[\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ squeeze_ph_len_lzv (\u001b[38;5;33mLambda\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m)                       │                 \u001b[38;5;34m0\u001b[0m │ input_label_length_lzv[\u001b[38;5;34m0\u001b[0m][\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ ctc_loss_lzv (\u001b[38;5;33mLambda\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                    │                 \u001b[38;5;34m0\u001b[0m │ input_labels_lzv[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   \n",
       "│                                   │                              │                   │ output_dense_softmax_lzv[\u001b[38;5;34m0\u001b[0m\n",
       "│                                   │                              │                   │ squeeze_lm_len_lzv[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], \n",
       "│                                   │                              │                   │ squeeze_ph_len_lzv[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  \n",
       "└───────────────────────────────────┴──────────────────────────────┴───────────────────┴───────────────────────────\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">186,542</span> (728.68 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m186,542\u001b[0m (728.68 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">105,262</span> (411.18 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m105,262\u001b[0m (411.18 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">81,280</span> (317.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m81,280\u001b[0m (317.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- LZV Prediction Model Summary ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"cslr_lzv_prediction_model\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"cslr_lzv_prediction_model\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                               </span>┃<span style=\"font-weight: bold\"> Output Shape                    </span>┃<span style=\"font-weight: bold\">           Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_landmarks (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">42</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)             │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├────────────────────────────────────────────┼─────────────────────────────────┼───────────────────┤\n",
       "│ reshape_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>)               │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├────────────────────────────────────────────┼─────────────────────────────────┼───────────────────┤\n",
       "│ conv1d_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │            <span style=\"color: #00af00; text-decoration-color: #00af00\">80,768</span> │\n",
       "├────────────────────────────────────────────┼─────────────────────────────────┼───────────────────┤\n",
       "│ batchnorm_conv (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "├────────────────────────────────────────────┼─────────────────────────────────┼───────────────────┤\n",
       "│ bilstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │            <span style=\"color: #00af00; text-decoration-color: #00af00\">98,816</span> │\n",
       "├────────────────────────────────────────────┼─────────────────────────────────┼───────────────────┤\n",
       "│ batchnorm_lstm1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "├────────────────────────────────────────────┼─────────────────────────────────┼───────────────────┤\n",
       "│ output_dense_softmax_lzv (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>)                │             <span style=\"color: #00af00; text-decoration-color: #00af00\">5,934</span> │\n",
       "└────────────────────────────────────────────┴─────────────────────────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                              \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m          Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_landmarks (\u001b[38;5;33mInputLayer\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m42\u001b[0m, \u001b[38;5;34m3\u001b[0m)             │                 \u001b[38;5;34m0\u001b[0m │\n",
       "├────────────────────────────────────────────┼─────────────────────────────────┼───────────────────┤\n",
       "│ reshape_input (\u001b[38;5;33mReshape\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m126\u001b[0m)               │                 \u001b[38;5;34m0\u001b[0m │\n",
       "├────────────────────────────────────────────┼─────────────────────────────────┼───────────────────┤\n",
       "│ conv1d_layer (\u001b[38;5;33mConv1D\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │            \u001b[38;5;34m80,768\u001b[0m │\n",
       "├────────────────────────────────────────────┼─────────────────────────────────┼───────────────────┤\n",
       "│ batchnorm_conv (\u001b[38;5;33mBatchNormalization\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │               \u001b[38;5;34m512\u001b[0m │\n",
       "├────────────────────────────────────────────┼─────────────────────────────────┼───────────────────┤\n",
       "│ bilstm_1 (\u001b[38;5;33mBidirectional\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │            \u001b[38;5;34m98,816\u001b[0m │\n",
       "├────────────────────────────────────────────┼─────────────────────────────────┼───────────────────┤\n",
       "│ batchnorm_lstm1 (\u001b[38;5;33mBatchNormalization\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │               \u001b[38;5;34m512\u001b[0m │\n",
       "├────────────────────────────────────────────┼─────────────────────────────────┼───────────────────┤\n",
       "│ output_dense_softmax_lzv (\u001b[38;5;33mTimeDistributed\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m46\u001b[0m)                │             \u001b[38;5;34m5,934\u001b[0m │\n",
       "└────────────────────────────────────────────┴─────────────────────────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">186,542</span> (728.68 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m186,542\u001b[0m (728.68 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">105,262</span> (411.18 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m105,262\u001b[0m (411.18 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">81,280</span> (317.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m81,280\u001b[0m (317.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=LEARNING_RATE, clipnorm=1.0)\n",
    "training_model.compile(optimizer=optimizer, loss=lambda y_true, y_pred: y_pred)\n",
    "\n",
    "print(\"\\nLZV Fine-tuning model compiled successfully.\")\n",
    "print(\"\\n--- LZV Training Model Summary (Fine-tuning) ---\")\n",
    "training_model.summary(line_length=120)\n",
    "\n",
    "print(\"\\n--- LZV Prediction Model Summary ---\")\n",
    "prediction_model.summary(line_length=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f215a2eb",
   "metadata": {},
   "source": [
    "### 9. Datu apstrādes funkcijas\n",
    "\n",
    "Dažādas funkcijas, ko izmanto modeļa trenēšanai."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "57898262",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual train samples after filter_ctc_length: 253\n",
      "Actual val samples after filter_ctc_length: 64\n",
      "Cache skipped.\n",
      "Using shuffle buffer size for training: 1000\n",
      "Building final training pipeline...\n",
      "Training pipeline built.\n",
      "Building final validation pipeline...\n",
      "Batched validation dataset for WER callback built.\n",
      "Validation pipeline prepared for Keras.\n"
     ]
    }
   ],
   "source": [
    "# Priekšapstrādes funkcija\n",
    "def preprocess_train_data(landmarks_raw, phrase, landmark_length, phrase_length):\n",
    "    if combined_mean is not None and combined_std is not None:\n",
    "        landmarks_norm = (landmarks_raw - combined_mean) / combined_std\n",
    "        landmarks_norm = tf.where(tf.math.is_finite(landmarks_norm), landmarks_norm, tf.zeros_like(landmarks_norm)) # Aizstāj NaN/Inf ar 0\n",
    "    else:\n",
    "        tf.print(\"Critical Error: Normalization stats missing during training preprocessing.\", output_stream=tf.sys.stderr)\n",
    "        landmarks_norm = landmarks_raw\n",
    "\n",
    "    if USE_AUGMENTATION:\n",
    "        landmarks_processed = augment_fn_adapted(landmarks_norm, use_resample=False)\n",
    "    else:\n",
    "        landmarks_processed = landmarks_norm\n",
    "\n",
    "    landmarks_subset = tf.gather(landmarks_processed, TRAINING_IDXS, axis=1)\n",
    "    landmarks_subset = tf.ensure_shape(landmarks_subset, [None, NUM_LANDMARKS, LANDMARK_DIMS])\n",
    "    landmarks_subset = tf.debugging.check_numerics(landmarks_subset, \"Landmarks check failed after train preprocessing\")\n",
    "\n",
    "    return landmarks_subset, phrase, landmark_length, phrase_length\n",
    "\n",
    "# Priekšapstrādes funkcija validācijas datiem\n",
    "def preprocess_val_data(landmarks_raw, phrase, landmark_length, phrase_length):\n",
    "    if combined_mean is not None and combined_std is not None:\n",
    "        landmarks_norm = (landmarks_raw - combined_mean) / combined_std\n",
    "        landmarks_norm = tf.where(tf.math.is_finite(landmarks_norm), landmarks_norm, tf.zeros_like(landmarks_norm)) # Aizstāj NaN/Inf ar 0\n",
    "    else:\n",
    "        tf.print(\"Critical Error: Normalization stats missing during validation preprocessing.\", output_stream=tf.sys.stderr)\n",
    "        landmarks_norm = landmarks_raw\n",
    "\n",
    "    landmarks_subset = tf.gather(landmarks_norm, TRAINING_IDXS, axis=1)\n",
    "    landmarks_subset = tf.ensure_shape(landmarks_subset, [None, NUM_LANDMARKS, LANDMARK_DIMS])\n",
    "    landmarks_subset = tf.debugging.check_numerics(landmarks_subset, \"Landmarks check failed after val preprocessing\")\n",
    "\n",
    "    return landmarks_subset, phrase, landmark_length, phrase_length\n",
    "\n",
    "# Sagatavo datu kopu Keras\n",
    "def prepare_dataset_for_keras(landmarks, phrase, landmark_len, phrase_len):\n",
    "    return {\n",
    "        'input_landmarks': landmarks,\n",
    "        'input_labels': phrase,\n",
    "        'input_landmark_length': tf.cast(landmark_len[:, tf.newaxis], tf.int64),\n",
    "        'input_label_length': tf.cast(phrase_len[:, tf.newaxis], tf.int64)\n",
    "    }, tf.zeros((tf.shape(landmark_len)[0], 1))\n",
    "\n",
    "# Generē un ieraksta prognozes JSON formātā\n",
    "def generate_and_log_predictions(phase_name, model_to_predict_with, val_dataset, wer_callback_instance, num_examples, batch_size, target_list_in_run_data):\n",
    "    print(f\"\\nGenerating LZV prediction examples for JSON ({phase_name})...\")\n",
    "    examples_count = 0\n",
    "    \n",
    "    if model_to_predict_with is not None and val_dataset is not None and wer_callback_instance is not None:\n",
    "        for batch_landmarks_tensor, batch_true_phrases_numeric, batch_lm_lengths_tensor, batch_ph_lengths_tensor in val_dataset.take(math.ceil(num_examples / batch_size)):\n",
    "            if examples_count >= num_examples:\n",
    "                break\n",
    "\n",
    "            y_pred_softmax = model_to_predict_with.predict(batch_landmarks_tensor, verbose=0)\n",
    "            decoded_indices_batch = wer_callback_instance.decode_batch_predictions(y_pred_softmax)\n",
    "\n",
    "            for j in range(tf.shape(batch_landmarks_tensor)[0].numpy()):\n",
    "                if examples_count >= num_examples:\n",
    "                    break\n",
    "                \n",
    "                true_idxs_padded = batch_true_phrases_numeric[j]\n",
    "                true_len_scalar = batch_ph_lengths_tensor[j].numpy() # Already scalar from dataset\n",
    "                true_idxs = true_idxs_padded[:true_len_scalar].numpy()\n",
    "                true_str = wer_callback_instance.map_indices_to_signs(true_idxs)\n",
    "\n",
    "                pred_idxs = decoded_indices_batch[j]\n",
    "                pred_str = wer_callback_instance.map_indices_to_signs(pred_idxs)\n",
    "                \n",
    "                target_list_in_run_data.append({ \n",
    "                    \"ground_truth\": true_str if true_str else \"<empty_true>\",\n",
    "                    \"prediction\": pred_str if pred_str else \"<empty_pred>\"\n",
    "                })\n",
    "                examples_count += 1\n",
    "        print(f\"Generated {examples_count} LZV prediction examples for {phase_name}.\")\n",
    "        print(f\"  Content of target_list_in_run_data for {phase_name} after generation: {target_list_in_run_data}\")\n",
    "    else:\n",
    "        print(f\"Skipping LZV prediction examples generation for {phase_name} (missing components).\")\n",
    "\n",
    "\n",
    "train_dataset_prepared = None\n",
    "validation_dataset_batched = None\n",
    "validation_dataset_prepared = None\n",
    "\n",
    "try:\n",
    "    train_raw_dataset = tf.data.TFRecordDataset([TFRECORD_FILE])\n",
    "    validation_raw_dataset = tf.data.TFRecordDataset([TFRECORD_FILE_VAL])\n",
    "\n",
    "    train_parsed_dataset = train_raw_dataset.map(parse_tfrecord_fn_for_filter, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    validation_parsed_dataset = validation_raw_dataset.map(parse_tfrecord_fn_for_filter, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "    # Filtrēšanas datu kopas, lai atlasītu tikai piemērus ar pietiekamu garumu\n",
    "    train_filtered_dataset = train_parsed_dataset.filter(filter_ctc_length)\n",
    "    validation_filtered_dataset = validation_parsed_dataset.filter(filter_ctc_length)\n",
    "\n",
    "    actual_train_samples_after_filter = sum(1 for _ in train_filtered_dataset)\n",
    "    actual_val_samples_after_filter = sum(1 for _ in validation_filtered_dataset)\n",
    "    print(f\"Actual train samples after filter_ctc_length: {actual_train_samples_after_filter}\")\n",
    "    print(f\"Actual val samples after filter_ctc_length: {actual_val_samples_after_filter}\")\n",
    "\n",
    "    print(\"Cache skipped.\")\n",
    "    train_filtered_cached = train_filtered_dataset\n",
    "    validation_filtered_cached = validation_filtered_dataset\n",
    "\n",
    "    if NUM_TRAIN_SAMPLES_AFTER_FILTER <= 0 or NUM_VAL_SAMPLES_AFTER_FILTER <= 0:\n",
    "        raise ValueError(\"Train or validation sample count is zero or less based on pre-calculated values.\")\n",
    "\n",
    "    print(f\"Using shuffle buffer size for training: {shuffle_buffer}\")\n",
    "    padding_values_tuple = (\n",
    "        0.0,\n",
    "        tf.cast(VOCAB_SIZE, tf.int64),\n",
    "        tf.cast(0, tf.int64),\n",
    "        tf.cast(0, tf.int64)\n",
    "    )\n",
    "\n",
    "    # Trenēsanas Pipeline\n",
    "    print(\"Building final training pipeline...\")\n",
    "    train_dataset = train_filtered_cached\n",
    "    train_dataset = train_dataset.shuffle(shuffle_buffer)\n",
    "    train_dataset = train_dataset.map(preprocess_train_data, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    train_dataset = train_dataset.repeat()\n",
    "    train_dataset = train_dataset.padded_batch(\n",
    "        BATCH_SIZE,\n",
    "        padded_shapes=(tf.TensorShape([None, NUM_LANDMARKS, LANDMARK_DIMS]), tf.TensorShape([None]), tf.TensorShape([]), tf.TensorShape([])),\n",
    "        padding_values=padding_values_tuple, drop_remainder=False\n",
    "    )\n",
    "    train_dataset_prepared = train_dataset.map(prepare_dataset_for_keras)\n",
    "    train_dataset_prepared = train_dataset_prepared.prefetch(tf.data.AUTOTUNE)\n",
    "    print(\"Training pipeline built.\")\n",
    "\n",
    "    # Validācijas Pipeline\n",
    "    print(\"Building final validation pipeline...\")\n",
    "    validation_dataset = validation_filtered_cached\n",
    "    validation_dataset = validation_dataset.map(preprocess_val_data, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    validation_dataset_batched = validation_dataset.padded_batch(\n",
    "        BATCH_SIZE,\n",
    "        padded_shapes=(tf.TensorShape([None, NUM_LANDMARKS, LANDMARK_DIMS]), tf.TensorShape([None]), tf.TensorShape([]), tf.TensorShape([])),\n",
    "        padding_values=padding_values_tuple, \n",
    "        drop_remainder=False\n",
    "    ).prefetch(tf.data.AUTOTUNE)\n",
    "    print(\"Batched validation dataset for WER callback built.\")\n",
    "    validation_dataset_prepared = validation_dataset_batched.map(prepare_dataset_for_keras)\n",
    "    print(\"Validation pipeline prepared for Keras.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d53a02",
   "metadata": {},
   "source": [
    "### 10. LZV modeļa apmācība ar pārneses mācīšanās stratēģiju no ASL modeļa.\n",
    "\n",
    "Modeļa apmācība, datu saglabāšana."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "48d6e9c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Preparing for training ---\n",
      "LZV Training Samples (post-filter): 254\n",
      "LZV Validation Samples (post-filter): 64\n",
      "Batch Size: 4\n",
      "Learning Rate for fine-tuning: 1e-06\n",
      "Calculated steps_per_epoch: 64\n",
      "Calculated validation_steps (for Keras & WER Callback): 16\n",
      "\n",
      "LZV experiment results will be saved in: c:\\Users\\liene\\Documents\\GitHub\\LZV-CSLR\\models\\lzv\\1\n",
      "\n",
      "Started at: 2025-05-30 17:34:00)...\n",
      "\n",
      "--- PHASE 1 ---\n",
      "Base model 'asl_loaded_feature_base' trainable: False\n",
      "Trainable params for Phase 1:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"cslr_lzv_fine_tune_training_model\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"cslr_lzv_fine_tune_training_model\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                </span>┃<span style=\"font-weight: bold\"> Output Shape            </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to            </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_landmarks             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">42</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)     │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                │                         │                │                         │\n",
       "├─────────────────────────────┼─────────────────────────┼────────────────┼─────────────────────────┤\n",
       "│ reshape_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_landmarks[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────────────┼─────────────────────────┼────────────────┼─────────────────────────┤\n",
       "│ conv1d_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">80,768</span> │ reshape_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────────────┼─────────────────────────┼────────────────┼─────────────────────────┤\n",
       "│ batchnorm_conv              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv1d_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)        │                         │                │                         │\n",
       "├─────────────────────────────┼─────────────────────────┼────────────────┼─────────────────────────┤\n",
       "│ bilstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">98,816</span> │ batchnorm_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────────────┼─────────────────────────┼────────────────┼─────────────────────────┤\n",
       "│ batchnorm_lstm1             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ bilstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)        │                         │                │                         │\n",
       "├─────────────────────────────┼─────────────────────────┼────────────────┼─────────────────────────┤\n",
       "│ input_landmark_length_lzv   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)               │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                │                         │                │                         │\n",
       "├─────────────────────────────┼─────────────────────────┼────────────────┼─────────────────────────┤\n",
       "│ input_label_length_lzv      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)               │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                │                         │                │                         │\n",
       "├─────────────────────────────┼─────────────────────────┼────────────────┼─────────────────────────┤\n",
       "│ input_labels_lzv            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                │                         │                │                         │\n",
       "├─────────────────────────────┼─────────────────────────┼────────────────┼─────────────────────────┤\n",
       "│ output_dense_softmax_lzv    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">5,934</span> │ batchnorm_lstm1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)           │                         │                │                         │\n",
       "├─────────────────────────────┼─────────────────────────┼────────────────┼─────────────────────────┤\n",
       "│ squeeze_lm_len_lzv (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)                  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_landmark_length_… │\n",
       "├─────────────────────────────┼─────────────────────────┼────────────────┼─────────────────────────┤\n",
       "│ squeeze_ph_len_lzv (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)                  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_label_length_lzv… │\n",
       "├─────────────────────────────┼─────────────────────────┼────────────────┼─────────────────────────┤\n",
       "│ ctc_loss_lzv (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)               │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_labels_lzv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
       "│                             │                         │                │ output_dense_softmax_l… │\n",
       "│                             │                         │                │ squeeze_lm_len_lzv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                             │                         │                │ squeeze_ph_len_lzv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "└─────────────────────────────┴─────────────────────────┴────────────────┴─────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape           \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to           \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_landmarks             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m42\u001b[0m, \u001b[38;5;34m3\u001b[0m)     │              \u001b[38;5;34m0\u001b[0m │ -                       │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)                │                         │                │                         │\n",
       "├─────────────────────────────┼─────────────────────────┼────────────────┼─────────────────────────┤\n",
       "│ reshape_input (\u001b[38;5;33mReshape\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m126\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ input_landmarks[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────────────┼─────────────────────────┼────────────────┼─────────────────────────┤\n",
       "│ conv1d_layer (\u001b[38;5;33mConv1D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │         \u001b[38;5;34m80,768\u001b[0m │ reshape_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────────────┼─────────────────────────┼────────────────┼─────────────────────────┤\n",
       "│ batchnorm_conv              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │            \u001b[38;5;34m512\u001b[0m │ conv1d_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)        │                         │                │                         │\n",
       "├─────────────────────────────┼─────────────────────────┼────────────────┼─────────────────────────┤\n",
       "│ bilstm_1 (\u001b[38;5;33mBidirectional\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │         \u001b[38;5;34m98,816\u001b[0m │ batchnorm_conv[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────────────┼─────────────────────────┼────────────────┼─────────────────────────┤\n",
       "│ batchnorm_lstm1             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │            \u001b[38;5;34m512\u001b[0m │ bilstm_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)        │                         │                │                         │\n",
       "├─────────────────────────────┼─────────────────────────┼────────────────┼─────────────────────────┤\n",
       "│ input_landmark_length_lzv   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)               │              \u001b[38;5;34m0\u001b[0m │ -                       │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)                │                         │                │                         │\n",
       "├─────────────────────────────┼─────────────────────────┼────────────────┼─────────────────────────┤\n",
       "│ input_label_length_lzv      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)               │              \u001b[38;5;34m0\u001b[0m │ -                       │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)                │                         │                │                         │\n",
       "├─────────────────────────────┼─────────────────────────┼────────────────┼─────────────────────────┤\n",
       "│ input_labels_lzv            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ -                       │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)                │                         │                │                         │\n",
       "├─────────────────────────────┼─────────────────────────┼────────────────┼─────────────────────────┤\n",
       "│ output_dense_softmax_lzv    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m46\u001b[0m)        │          \u001b[38;5;34m5,934\u001b[0m │ batchnorm_lstm1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)           │                         │                │                         │\n",
       "├─────────────────────────────┼─────────────────────────┼────────────────┼─────────────────────────┤\n",
       "│ squeeze_lm_len_lzv (\u001b[38;5;33mLambda\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m)                  │              \u001b[38;5;34m0\u001b[0m │ input_landmark_length_… │\n",
       "├─────────────────────────────┼─────────────────────────┼────────────────┼─────────────────────────┤\n",
       "│ squeeze_ph_len_lzv (\u001b[38;5;33mLambda\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m)                  │              \u001b[38;5;34m0\u001b[0m │ input_label_length_lzv… │\n",
       "├─────────────────────────────┼─────────────────────────┼────────────────┼─────────────────────────┤\n",
       "│ ctc_loss_lzv (\u001b[38;5;33mLambda\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)               │              \u001b[38;5;34m0\u001b[0m │ input_labels_lzv[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
       "│                             │                         │                │ output_dense_softmax_l… │\n",
       "│                             │                         │                │ squeeze_lm_len_lzv[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│                             │                         │                │ squeeze_ph_len_lzv[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "└─────────────────────────────┴─────────────────────────┴────────────────┴─────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">186,542</span> (728.68 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m186,542\u001b[0m (728.68 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">105,262</span> (411.18 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m105,262\u001b[0m (411.18 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">81,280</span> (317.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m81,280\u001b[0m (317.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compiled for Phase 1 with LR: 0.001\n",
      "\n",
      "WERCallback initialized:\n",
      "  Decoder: Greedy\n",
      "  Metric Log Name: val_wer_phase1\n",
      "Starting Phase 1 training for 50 epochs...\n",
      "Epoch 1/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step - loss: 366.8881\\nEpoch 1: Calculating Validation WER/CER...\n",
      "  Example True: '9   ļ o t i   s ē ņ o'\n",
      "  Example Pred: '<empty_pred>'\n",
      "  Successfully calculated WER: 1.5200 using 64 pairs.\n",
      "  New best validation WER: 1.5200 (previous: inf at epoch 0)\n",
      "\n",
      "Epoch 1: val_wer_phase1 improved from inf to 1.52000, saving model to c:\\Users\\liene\\Documents\\GitHub\\LZV-CSLR\\models\\lzv\\1\\lzv_model_phase1_best_exp1.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 285ms/step - loss: 364.4161 - val_loss: 26.5461 - val_wer_phase1: 1.5200 - learning_rate: 0.0010\n",
      "Epoch 2/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\liene\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\saving\\serialization_lib.py:390: UserWarning: The object being serialized includes a `lambda`. This is unsafe. In order to reload the object, you will have to pass `safe_mode=False` to the loading function. Please avoid using `lambda` in the future, and use named Python functions instead. This is the `lambda` being serialized:     training_model.compile(optimizer=optimizer_phase1, loss=lambda y_true, y_pred: y_pred, metrics=[])\n",
      "\n",
      "  return {key: serialize_keras_object(value) for key, value in obj.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217ms/step - loss: 34.8211\\nEpoch 2: Calculating Validation WER/CER...\n",
      "  Example True: '9   ļ o t i   s ē ņ o'\n",
      "  Example Pred: '<empty_pred>'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\liene\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\contextlib.py:158: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Successfully calculated WER: 1.3567 using 64 pairs.\n",
      "  New best validation WER: 1.3567 (previous: 1.5200 at epoch 1)\n",
      "\n",
      "Epoch 2: val_wer_phase1 improved from 1.52000 to 1.35667, saving model to c:\\Users\\liene\\Documents\\GitHub\\LZV-CSLR\\models\\lzv\\1\\lzv_model_phase1_best_exp1.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 238ms/step - loss: 34.8101 - val_wer_phase1: 1.3567 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 236ms/step - loss: 23.8250\\nEpoch 3: Calculating Validation WER/CER...\n",
      "  Example True: '9   ļ o t i   s ē ņ o'\n",
      "  Example Pred: '<empty_pred>'\n",
      "  Successfully calculated WER: 2.3733 using 64 pairs.\n",
      "  Validation WER (2.3733) did not improve. Best: 1.3567 at epoch 2\n",
      "\n",
      "Epoch 3: val_wer_phase1 did not improve from 1.35667\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 266ms/step - loss: 23.8328 - val_loss: 15.6024 - val_wer_phase1: 2.3733 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 255ms/step - loss: 19.7471\\nEpoch 4: Calculating Validation WER/CER...\n",
      "  Example True: '9   ļ o t i   s ē ņ o'\n",
      "  Example Pred: '<empty_pred>'\n",
      "  Successfully calculated WER: 2.1433 using 64 pairs.\n",
      "  Validation WER (2.1433) did not improve. Best: 1.3567 at epoch 2\n",
      "\n",
      "Epoch 4: val_wer_phase1 did not improve from 1.35667\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 274ms/step - loss: 19.7409 - val_wer_phase1: 2.1433 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 263ms/step - loss: 13.1522\\nEpoch 5: Calculating Validation WER/CER...\n",
      "  Example True: '9   ļ o t i   s ē ņ o'\n",
      "  Example Pred: 't i s'\n",
      "  Successfully calculated WER: 1.8233 using 64 pairs.\n",
      "  Validation WER (1.8233) did not improve. Best: 1.3567 at epoch 2\n",
      "\n",
      "Epoch 5: val_wer_phase1 did not improve from 1.35667\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 290ms/step - loss: 13.1525 - val_loss: 10.4659 - val_wer_phase1: 1.8233 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 230ms/step - loss: 11.1251\\nEpoch 6: Calculating Validation WER/CER...\n",
      "  Example True: '9   ļ o t i   s ē ņ o'\n",
      "  Example Pred: 't i s'\n",
      "  Successfully calculated WER: 1.0200 using 64 pairs.\n",
      "  New best validation WER: 1.0200 (previous: 1.3567 at epoch 2)\n",
      "\n",
      "Epoch 6: val_wer_phase1 improved from 1.35667 to 1.02000, saving model to c:\\Users\\liene\\Documents\\GitHub\\LZV-CSLR\\models\\lzv\\1\\lzv_model_phase1_best_exp1.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 250ms/step - loss: 11.1239 - val_wer_phase1: 1.0200 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 267ms/step - loss: 8.9048\\nEpoch 7: Calculating Validation WER/CER...\n",
      "  Example True: '9   ļ o t i   s ē ņ o'\n",
      "  Example Pred: '9 o t i s o'\n",
      "  Successfully calculated WER: 0.8633 using 64 pairs.\n",
      "  New best validation WER: 0.8633 (previous: 1.0200 at epoch 6)\n",
      "\n",
      "Epoch 7: val_wer_phase1 improved from 1.02000 to 0.86333, saving model to c:\\Users\\liene\\Documents\\GitHub\\LZV-CSLR\\models\\lzv\\1\\lzv_model_phase1_best_exp1.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 293ms/step - loss: 8.9167 - val_loss: 8.1056 - val_wer_phase1: 0.8633 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 262ms/step - loss: 8.2712\\nEpoch 8: Calculating Validation WER/CER...\n",
      "  Example True: '9   ļ o t i   s ē ņ o'\n",
      "  Example Pred: '9 o t i s o'\n",
      "  Successfully calculated WER: 0.8233 using 64 pairs.\n",
      "  New best validation WER: 0.8233 (previous: 0.8633 at epoch 7)\n",
      "\n",
      "Epoch 8: val_wer_phase1 improved from 0.86333 to 0.82333, saving model to c:\\Users\\liene\\Documents\\GitHub\\LZV-CSLR\\models\\lzv\\1\\lzv_model_phase1_best_exp1.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 285ms/step - loss: 8.2789 - val_wer_phase1: 0.8233 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 248ms/step - loss: 7.7046\\nEpoch 9: Calculating Validation WER/CER...\n",
      "  Example True: '9   ļ o t i   s ē ņ o'\n",
      "  Example Pred: '9 o t i s ē ņ o'\n",
      "  Successfully calculated WER: 0.8633 using 64 pairs.\n",
      "  Validation WER (0.8633) did not improve. Best: 0.8233 at epoch 8\n",
      "\n",
      "Epoch 9: val_wer_phase1 did not improve from 0.82333\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 276ms/step - loss: 7.6963 - val_loss: 7.2406 - val_wer_phase1: 0.8633 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 262ms/step - loss: 6.8646\\nEpoch 10: Calculating Validation WER/CER...\n",
      "  Example True: '9   ļ o t i   s ē ņ o'\n",
      "  Example Pred: '9 o t i s ē ņ o'\n",
      "  Successfully calculated WER: 0.6267 using 64 pairs.\n",
      "  New best validation WER: 0.6267 (previous: 0.8233 at epoch 8)\n",
      "\n",
      "Epoch 10: val_wer_phase1 improved from 0.82333 to 0.62667, saving model to c:\\Users\\liene\\Documents\\GitHub\\LZV-CSLR\\models\\lzv\\1\\lzv_model_phase1_best_exp1.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 291ms/step - loss: 6.8621 - val_wer_phase1: 0.6267 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 241ms/step - loss: 5.8041\\nEpoch 11: Calculating Validation WER/CER...\n",
      "  Example True: '9   ļ o t i   s ē ņ o'\n",
      "  Example Pred: '9 o t i s ē ņ o'\n",
      "  Successfully calculated WER: 0.5400 using 64 pairs.\n",
      "  New best validation WER: 0.5400 (previous: 0.6267 at epoch 10)\n",
      "\n",
      "Epoch 11: val_wer_phase1 improved from 0.62667 to 0.54000, saving model to c:\\Users\\liene\\Documents\\GitHub\\LZV-CSLR\\models\\lzv\\1\\lzv_model_phase1_best_exp1.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 268ms/step - loss: 5.8090 - val_loss: 6.4502 - val_wer_phase1: 0.5400 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 272ms/step - loss: 5.6607\\nEpoch 12: Calculating Validation WER/CER...\n",
      "  Example True: '9   ļ o t i   s ē ņ o'\n",
      "  Example Pred: '9 o t i s ņ o'\n",
      "  Successfully calculated WER: 0.4667 using 64 pairs.\n",
      "  New best validation WER: 0.4667 (previous: 0.5400 at epoch 11)\n",
      "\n",
      "Epoch 12: val_wer_phase1 improved from 0.54000 to 0.46667, saving model to c:\\Users\\liene\\Documents\\GitHub\\LZV-CSLR\\models\\lzv\\1\\lzv_model_phase1_best_exp1.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 319ms/step - loss: 5.6651 - val_wer_phase1: 0.4667 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 421ms/step - loss: 5.0102\\nEpoch 13: Calculating Validation WER/CER...\n",
      "  Example True: '9   ļ o t i   s ē ņ o'\n",
      "  Example Pred: '9 o t i s ē ņ o'\n",
      "  Successfully calculated WER: 0.4100 using 64 pairs.\n",
      "  New best validation WER: 0.4100 (previous: 0.4667 at epoch 12)\n",
      "\n",
      "Epoch 13: val_wer_phase1 improved from 0.46667 to 0.41000, saving model to c:\\Users\\liene\\Documents\\GitHub\\LZV-CSLR\\models\\lzv\\1\\lzv_model_phase1_best_exp1.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 481ms/step - loss: 5.0129 - val_loss: 5.6990 - val_wer_phase1: 0.4100 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 337ms/step - loss: 4.7663\\nEpoch 14: Calculating Validation WER/CER...\n",
      "  Example True: '9   ļ o t i   s ē ņ o'\n",
      "  Example Pred: '9 o t i s ē ņ o'\n",
      "  Successfully calculated WER: 0.5000 using 64 pairs.\n",
      "  Validation WER (0.5000) did not improve. Best: 0.4100 at epoch 13\n",
      "\n",
      "Epoch 14: val_wer_phase1 did not improve from 0.41000\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 355ms/step - loss: 4.7676 - val_wer_phase1: 0.5000 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 365ms/step - loss: 4.7456\\nEpoch 15: Calculating Validation WER/CER...\n",
      "  Example True: '9   ļ o t i   s ē ņ o'\n",
      "  Example Pred: '9 o t i s ē ņ o'\n",
      "  Successfully calculated WER: 0.3767 using 64 pairs.\n",
      "  New best validation WER: 0.3767 (previous: 0.4100 at epoch 13)\n",
      "\n",
      "Epoch 15: val_wer_phase1 improved from 0.41000 to 0.37667, saving model to c:\\Users\\liene\\Documents\\GitHub\\LZV-CSLR\\models\\lzv\\1\\lzv_model_phase1_best_exp1.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 417ms/step - loss: 4.7467 - val_loss: 5.4468 - val_wer_phase1: 0.3767 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384ms/step - loss: 4.4285\\nEpoch 16: Calculating Validation WER/CER...\n",
      "  Example True: '9   ļ o t i   s ē ņ o'\n",
      "  Example Pred: '9   ļ o t i s ē ņ o'\n",
      "  Successfully calculated WER: 0.5800 using 64 pairs.\n",
      "  Validation WER (0.5800) did not improve. Best: 0.3767 at epoch 15\n",
      "\n",
      "Epoch 16: val_wer_phase1 did not improve from 0.37667\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 470ms/step - loss: 4.4277 - val_wer_phase1: 0.5800 - learning_rate: 0.0010\n",
      "Epoch 17/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 363ms/step - loss: 3.8418\\nEpoch 17: Calculating Validation WER/CER...\n",
      "  Example True: '9   ļ o t i   s ē ņ o'\n",
      "  Example Pred: '9   o t i s ē ņ o'\n",
      "  Successfully calculated WER: 0.3500 using 64 pairs.\n",
      "  New best validation WER: 0.3500 (previous: 0.3767 at epoch 15)\n",
      "\n",
      "Epoch 17: val_wer_phase1 improved from 0.37667 to 0.35000, saving model to c:\\Users\\liene\\Documents\\GitHub\\LZV-CSLR\\models\\lzv\\1\\lzv_model_phase1_best_exp1.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 391ms/step - loss: 3.8489 - val_loss: 5.6548 - val_wer_phase1: 0.3500 - learning_rate: 0.0010\n",
      "Epoch 18/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 236ms/step - loss: 3.9236\\nEpoch 18: Calculating Validation WER/CER...\n",
      "  Example True: '9   ļ o t i   s ē ņ o'\n",
      "  Example Pred: '9   o t i s ē ņ o'\n",
      "  Successfully calculated WER: 0.4633 using 64 pairs.\n",
      "  Validation WER (0.4633) did not improve. Best: 0.3500 at epoch 17\n",
      "\n",
      "Epoch 18: val_wer_phase1 did not improve from 0.35000\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 255ms/step - loss: 3.9256 - val_wer_phase1: 0.4633 - learning_rate: 0.0010\n",
      "Epoch 19/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 266ms/step - loss: 4.1241\\nEpoch 19: Calculating Validation WER/CER...\n",
      "  Example True: '9   ļ o t i   s ē ņ o'\n",
      "  Example Pred: '9   o t i s ē ņ o'\n",
      "  Successfully calculated WER: 0.2967 using 64 pairs.\n",
      "  New best validation WER: 0.2967 (previous: 0.3500 at epoch 17)\n",
      "\n",
      "Epoch 19: val_wer_phase1 improved from 0.35000 to 0.29667, saving model to c:\\Users\\liene\\Documents\\GitHub\\LZV-CSLR\\models\\lzv\\1\\lzv_model_phase1_best_exp1.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 297ms/step - loss: 4.1241 - val_loss: 5.3052 - val_wer_phase1: 0.2967 - learning_rate: 0.0010\n",
      "Epoch 20/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 278ms/step - loss: 3.8544\\nEpoch 20: Calculating Validation WER/CER...\n",
      "  Example True: '9   ļ o t i   s ē ņ o'\n",
      "  Example Pred: '9   ļ o t i s ē ņ o'\n",
      "  Successfully calculated WER: 2.9200 using 64 pairs.\n",
      "  Validation WER (2.9200) did not improve. Best: 0.2967 at epoch 19\n",
      "\n",
      "Epoch 20: val_wer_phase1 did not improve from 0.29667\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 300ms/step - loss: 3.8527 - val_wer_phase1: 2.9200 - learning_rate: 0.0010\n",
      "Epoch 21/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 265ms/step - loss: 3.3791\\nEpoch 21: Calculating Validation WER/CER...\n",
      "  Example True: '9   ļ o t i   s ē ņ o'\n",
      "  Example Pred: '9   o t i s ē ņ o'\n",
      "  Successfully calculated WER: 0.2900 using 64 pairs.\n",
      "  New best validation WER: 0.2900 (previous: 0.2967 at epoch 19)\n",
      "\n",
      "Epoch 21: val_wer_phase1 improved from 0.29667 to 0.29000, saving model to c:\\Users\\liene\\Documents\\GitHub\\LZV-CSLR\\models\\lzv\\1\\lzv_model_phase1_best_exp1.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 296ms/step - loss: 3.3788 - val_loss: 5.4126 - val_wer_phase1: 0.2900 - learning_rate: 0.0010\n",
      "Epoch 22/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 279ms/step - loss: 3.3523\\nEpoch 22: Calculating Validation WER/CER...\n",
      "  Example True: '9   ļ o t i   s ē ņ o'\n",
      "  Example Pred: '9   ļ o t i s ē ņ o'\n",
      "  Successfully calculated WER: 0.2867 using 64 pairs.\n",
      "  New best validation WER: 0.2867 (previous: 0.2900 at epoch 21)\n",
      "\n",
      "Epoch 22: val_wer_phase1 improved from 0.29000 to 0.28667, saving model to c:\\Users\\liene\\Documents\\GitHub\\LZV-CSLR\\models\\lzv\\1\\lzv_model_phase1_best_exp1.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 300ms/step - loss: 3.3497 - val_wer_phase1: 0.2867 - learning_rate: 0.0010\n",
      "Epoch 23/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 250ms/step - loss: 2.9913\\nEpoch 23: Calculating Validation WER/CER...\n",
      "  Example True: '9   ļ o t i   s ē ņ o'\n",
      "  Example Pred: '9   o t i s ē ņ o'\n",
      "  Successfully calculated WER: 0.2867 using 64 pairs.\n",
      "  Validation WER (0.2867) did not improve. Best: 0.2867 at epoch 22\n",
      "\n",
      "Epoch 23: val_wer_phase1 did not improve from 0.28667\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 276ms/step - loss: 2.9928 - val_loss: 5.1748 - val_wer_phase1: 0.2867 - learning_rate: 0.0010\n",
      "Epoch 24/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 252ms/step - loss: 3.0284\\nEpoch 24: Calculating Validation WER/CER...\n",
      "  Example True: '9   ļ o t i   s ē ņ o'\n",
      "  Example Pred: '9   o t i s ē ņ o'\n",
      "  Successfully calculated WER: 0.2533 using 64 pairs.\n",
      "  New best validation WER: 0.2533 (previous: 0.2867 at epoch 22)\n",
      "\n",
      "Epoch 24: val_wer_phase1 improved from 0.28667 to 0.25333, saving model to c:\\Users\\liene\\Documents\\GitHub\\LZV-CSLR\\models\\lzv\\1\\lzv_model_phase1_best_exp1.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 275ms/step - loss: 3.0276 - val_wer_phase1: 0.2533 - learning_rate: 0.0010\n",
      "Epoch 25/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 281ms/step - loss: 2.9416\\nEpoch 25: Calculating Validation WER/CER...\n",
      "  Example True: '9   ļ o t i   s ē ņ o'\n",
      "  Example Pred: '9   ļ o t i   s ē ņ o'\n",
      "  Successfully calculated WER: 0.2600 using 64 pairs.\n",
      "  Validation WER (0.2600) did not improve. Best: 0.2533 at epoch 24\n",
      "\n",
      "Epoch 25: val_wer_phase1 did not improve from 0.25333\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 310ms/step - loss: 2.9392 - val_loss: 5.4817 - val_wer_phase1: 0.2600 - learning_rate: 0.0010\n",
      "Epoch 26/50\n",
      "\u001b[1m63/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 256ms/step - loss: 2.8174\\nEpoch 26: Calculating Validation WER/CER...\n",
      "  Example True: '9   ļ o t i   s ē ņ o'\n",
      "  Example Pred: '9   ļ o t i   s ē ņ o'\n",
      "  Successfully calculated WER: 0.2567 using 64 pairs.\n",
      "  Validation WER (0.2567) did not improve. Best: 0.2533 at epoch 24\n",
      "\n",
      "Epoch 26: val_wer_phase1 did not improve from 0.25333\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 274ms/step - loss: 2.8160 - val_wer_phase1: 0.2567 - learning_rate: 0.0010\n",
      "Epoch 27/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 252ms/step - loss: 3.4248\\nEpoch 27: Calculating Validation WER/CER...\n",
      "  Example True: '9   ļ o t i   s ē ņ o'\n",
      "  Example Pred: '9   o t i   s ē ņ o'\n",
      "  Successfully calculated WER: 0.2533 using 64 pairs.\n",
      "  Validation WER (0.2533) did not improve. Best: 0.2533 at epoch 24\n",
      "\n",
      "Epoch 27: val_wer_phase1 did not improve from 0.25333\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 282ms/step - loss: 3.4166 - val_loss: 5.0527 - val_wer_phase1: 0.2533 - learning_rate: 0.0010\n",
      "Epoch 28/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 265ms/step - loss: 2.4531\\nEpoch 28: Calculating Validation WER/CER...\n",
      "  Example True: '9   ļ o t i   s ē ņ o'\n",
      "  Example Pred: '9   o t i   s ē ņ o'\n",
      "  Successfully calculated WER: 0.2433 using 64 pairs.\n",
      "  New best validation WER: 0.2433 (previous: 0.2533 at epoch 24)\n",
      "\n",
      "Epoch 28: val_wer_phase1 improved from 0.25333 to 0.24333, saving model to c:\\Users\\liene\\Documents\\GitHub\\LZV-CSLR\\models\\lzv\\1\\lzv_model_phase1_best_exp1.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 285ms/step - loss: 2.4561 - val_wer_phase1: 0.2433 - learning_rate: 0.0010\n",
      "Epoch 29/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 233ms/step - loss: 2.8603\\nEpoch 29: Calculating Validation WER/CER...\n",
      "  Example True: '9   ļ o t i   s ē ņ o'\n",
      "  Example Pred: '9   o t i   s ē ņ o'\n",
      "  Successfully calculated WER: 0.2533 using 64 pairs.\n",
      "  Validation WER (0.2533) did not improve. Best: 0.2433 at epoch 28\n",
      "\n",
      "Epoch 29: val_wer_phase1 did not improve from 0.24333\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 260ms/step - loss: 2.8562 - val_loss: 5.6815 - val_wer_phase1: 0.2533 - learning_rate: 0.0010\n",
      "Epoch 30/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 242ms/step - loss: 3.0536\\nEpoch 30: Calculating Validation WER/CER...\n",
      "  Example True: '9   ļ o t i   s ē ņ o'\n",
      "  Example Pred: '9   o t i   s ē ņ o'\n",
      "  Successfully calculated WER: 0.2700 using 64 pairs.\n",
      "  Validation WER (0.2700) did not improve. Best: 0.2433 at epoch 28\n",
      "\n",
      "Epoch 30: val_wer_phase1 did not improve from 0.24333\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 262ms/step - loss: 3.0504 - val_wer_phase1: 0.2700 - learning_rate: 0.0010\n",
      "Epoch 31/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 272ms/step - loss: 2.8266\\nEpoch 31: Calculating Validation WER/CER...\n",
      "  Example True: '9   ļ o t i   s ē ņ o'\n",
      "  Example Pred: '9   o t i   s ē ņ o'\n",
      "  Successfully calculated WER: 0.2533 using 64 pairs.\n",
      "  Validation WER (0.2533) did not improve. Best: 0.2433 at epoch 28\n",
      "\n",
      "Epoch 31: val_wer_phase1 did not improve from 0.24333\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 299ms/step - loss: 2.8235 - val_loss: 4.8221 - val_wer_phase1: 0.2533 - learning_rate: 0.0010\n",
      "Epoch 32/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 288ms/step - loss: 2.2088\\nEpoch 32: Calculating Validation WER/CER...\n",
      "  Example True: '9   ļ o t i   s ē ņ o'\n",
      "  Example Pred: '9   ļ o t i   s ē ņ o'\n",
      "  Successfully calculated WER: 0.2200 using 64 pairs.\n",
      "  New best validation WER: 0.2200 (previous: 0.2433 at epoch 28)\n",
      "\n",
      "Epoch 32: val_wer_phase1 improved from 0.24333 to 0.22000, saving model to c:\\Users\\liene\\Documents\\GitHub\\LZV-CSLR\\models\\lzv\\1\\lzv_model_phase1_best_exp1.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 320ms/step - loss: 2.2125 - val_wer_phase1: 0.2200 - learning_rate: 0.0010\n",
      "Epoch 33/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 289ms/step - loss: 2.2740\\nEpoch 33: Calculating Validation WER/CER...\n",
      "  Example True: '9   ļ o t i   s ē ņ o'\n",
      "  Example Pred: '9   ļ o t i   s ē ņ o'\n",
      "  Successfully calculated WER: 0.2433 using 64 pairs.\n",
      "  Validation WER (0.2433) did not improve. Best: 0.2200 at epoch 32\n",
      "\n",
      "Epoch 33: val_wer_phase1 did not improve from 0.22000\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 318ms/step - loss: 2.2747 - val_loss: 5.3419 - val_wer_phase1: 0.2433 - learning_rate: 0.0010\n",
      "Epoch 34/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 337ms/step - loss: 2.3039\\nEpoch 34: Calculating Validation WER/CER...\n",
      "  Example True: '9   ļ o t i   s ē ņ o'\n",
      "  Example Pred: '9   ļ o t i   s ē ņ o'\n",
      "  Successfully calculated WER: 0.2500 using 64 pairs.\n",
      "  Validation WER (0.2500) did not improve. Best: 0.2200 at epoch 32\n",
      "\n",
      "Epoch 34: val_wer_phase1 did not improve from 0.22000\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 380ms/step - loss: 2.3052 - val_wer_phase1: 0.2500 - learning_rate: 0.0010\n",
      "Epoch 35/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456ms/step - loss: 2.5019\\nEpoch 35: Calculating Validation WER/CER...\n",
      "  Example True: '9   ļ o t i   s ē ņ o'\n",
      "  Example Pred: '9   ļ o t i   s ē ņ o'\n",
      "  Successfully calculated WER: 0.2433 using 64 pairs.\n",
      "  Validation WER (0.2433) did not improve. Best: 0.2200 at epoch 32\n",
      "\n",
      "Epoch 35: val_wer_phase1 did not improve from 0.22000\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 517ms/step - loss: 2.5017 - val_loss: 5.5020 - val_wer_phase1: 0.2433 - learning_rate: 0.0010\n",
      "Epoch 36/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 328ms/step - loss: 2.0767\\nEpoch 36: Calculating Validation WER/CER...\n",
      "  Example True: '9   ļ o t i   s ē ņ o'\n",
      "  Example Pred: '9   ļ o t i   s ē ņ o'\n",
      "  Successfully calculated WER: 0.2367 using 64 pairs.\n",
      "  Validation WER (0.2367) did not improve. Best: 0.2200 at epoch 32\n",
      "\n",
      "Epoch 36: val_wer_phase1 did not improve from 0.22000\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 377ms/step - loss: 2.0751 - val_wer_phase1: 0.2367 - learning_rate: 0.0010\n",
      "Epoch 37/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384ms/step - loss: 2.1725\\nEpoch 37: Calculating Validation WER/CER...\n",
      "  Example True: '9   ļ o t i   s ē ņ o'\n",
      "  Example Pred: '9   ļ o t i   s ē ņ o'\n",
      "  Successfully calculated WER: 0.2433 using 64 pairs.\n",
      "  Validation WER (0.2433) did not improve. Best: 0.2200 at epoch 32\n",
      "\n",
      "Epoch 37: val_wer_phase1 did not improve from 0.22000\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 440ms/step - loss: 2.1702 - val_loss: 5.7354 - val_wer_phase1: 0.2433 - learning_rate: 0.0010\n",
      "Epoch 38/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 274ms/step - loss: 1.9289\\nEpoch 38: Calculating Validation WER/CER...\n",
      "  Example True: '9   ļ o t i   s ē ņ o'\n",
      "  Example Pred: '9   ļ o t i   s ē ņ o'\n",
      "  Successfully calculated WER: 0.2400 using 64 pairs.\n",
      "  Validation WER (0.2400) did not improve. Best: 0.2200 at epoch 32\n",
      "\n",
      "Epoch 38: val_wer_phase1 did not improve from 0.22000\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 296ms/step - loss: 1.9298 - val_wer_phase1: 0.2400 - learning_rate: 0.0010\n",
      "Epoch 39/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 271ms/step - loss: 2.1945\\nEpoch 39: Calculating Validation WER/CER...\n",
      "  Example True: '9   ļ o t i   s ē ņ o'\n",
      "  Example Pred: '9   o t i   s ē ņ o'\n",
      "  Successfully calculated WER: 0.2267 using 64 pairs.\n",
      "  Validation WER (0.2267) did not improve. Best: 0.2200 at epoch 32\n",
      "\n",
      "Epoch 39: val_wer_phase1 did not improve from 0.22000\n",
      "\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 298ms/step - loss: 2.1957 - val_loss: 5.3439 - val_wer_phase1: 0.2267 - learning_rate: 0.0010\n",
      "Epoch 40/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 247ms/step - loss: 1.8213\\nEpoch 40: Calculating Validation WER/CER...\n",
      "  Example True: '9   ļ o t i   s ē ņ o'\n",
      "  Example Pred: '9   o t i   s ē ņ o'\n",
      "  Successfully calculated WER: 0.2367 using 64 pairs.\n",
      "  Validation WER (0.2367) did not improve. Best: 0.2200 at epoch 32\n",
      "\n",
      "Epoch 40: val_wer_phase1 did not improve from 0.22000\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 271ms/step - loss: 1.8210 - val_wer_phase1: 0.2367 - learning_rate: 3.0000e-04\n",
      "Epoch 41/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 261ms/step - loss: 1.8944\\nEpoch 41: Calculating Validation WER/CER...\n",
      "  Example True: '9   ļ o t i   s ē ņ o'\n",
      "  Example Pred: '9   ļ o t i   s ē ņ o'\n",
      "  Successfully calculated WER: 0.2267 using 64 pairs.\n",
      "  Validation WER (0.2267) did not improve. Best: 0.2200 at epoch 32\n",
      "\n",
      "Epoch 41: val_wer_phase1 did not improve from 0.22000\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 288ms/step - loss: 1.8952 - val_loss: 4.8930 - val_wer_phase1: 0.2267 - learning_rate: 3.0000e-04\n",
      "Epoch 42/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 274ms/step - loss: 1.8529\\nEpoch 42: Calculating Validation WER/CER...\n",
      "  Example True: '9   ļ o t i   s ē ņ o'\n",
      "  Example Pred: '9   ļ o t i   s ē ņ o'\n",
      "  Successfully calculated WER: 0.2467 using 64 pairs.\n",
      "  Validation WER (0.2467) did not improve. Best: 0.2200 at epoch 32\n",
      "\n",
      "Epoch 42: val_wer_phase1 did not improve from 0.22000\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 294ms/step - loss: 1.8569 - val_wer_phase1: 0.2467 - learning_rate: 3.0000e-04\n",
      "Epoch 43/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 265ms/step - loss: 1.8061\\nEpoch 43: Calculating Validation WER/CER...\n",
      "  Example True: '9   ļ o t i   s ē ņ o'\n",
      "  Example Pred: '9   ļ o t i   s ē ņ o'\n",
      "  Successfully calculated WER: 0.2400 using 64 pairs.\n",
      "  Validation WER (0.2400) did not improve. Best: 0.2200 at epoch 32\n",
      "\n",
      "Epoch 43: val_wer_phase1 did not improve from 0.22000\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 328ms/step - loss: 1.8061 - val_loss: 5.0468 - val_wer_phase1: 0.2400 - learning_rate: 3.0000e-04\n",
      "Epoch 44/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 336ms/step - loss: 1.4577\\nEpoch 44: Calculating Validation WER/CER...\n",
      "  Example True: '9   ļ o t i   s ē ņ o'\n",
      "  Example Pred: '9   ļ o t i   s ē ņ o'\n",
      "  Successfully calculated WER: 0.2367 using 64 pairs.\n",
      "  Validation WER (0.2367) did not improve. Best: 0.2200 at epoch 32\n",
      "\n",
      "Epoch 44: val_wer_phase1 did not improve from 0.22000\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 357ms/step - loss: 1.4622 - val_wer_phase1: 0.2367 - learning_rate: 3.0000e-04\n",
      "Epoch 45/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 267ms/step - loss: 1.8555\\nEpoch 45: Calculating Validation WER/CER...\n",
      "  Example True: '9   ļ o t i   s ē ņ o'\n",
      "  Example Pred: '9   ļ o t i   s ē ņ o'\n",
      "  Successfully calculated WER: 0.2400 using 64 pairs.\n",
      "  Validation WER (0.2400) did not improve. Best: 0.2200 at epoch 32\n",
      "\n",
      "Epoch 45: val_wer_phase1 did not improve from 0.22000\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 296ms/step - loss: 1.8550 - val_loss: 5.1492 - val_wer_phase1: 0.2400 - learning_rate: 3.0000e-04\n",
      "Epoch 46/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 269ms/step - loss: 1.7259\\nEpoch 46: Calculating Validation WER/CER...\n",
      "  Example True: '9   ļ o t i   s ē ņ o'\n",
      "  Example Pred: '9   ļ o t i   s ē ņ o'\n",
      "  Successfully calculated WER: 0.2300 using 64 pairs.\n",
      "  Validation WER (0.2300) did not improve. Best: 0.2200 at epoch 32\n",
      "\n",
      "Epoch 46: val_wer_phase1 did not improve from 0.22000\n",
      "\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 290ms/step - loss: 1.7262 - val_wer_phase1: 0.2300 - learning_rate: 3.0000e-04\n",
      "Epoch 47/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 297ms/step - loss: 2.0548\\nEpoch 47: Calculating Validation WER/CER...\n",
      "  Example True: '9   ļ o t i   s ē ņ o'\n",
      "  Example Pred: '9   ļ o t i   s ē ņ o'\n",
      "  Successfully calculated WER: 0.2267 using 64 pairs.\n",
      "  Validation WER (0.2267) did not improve. Best: 0.2200 at epoch 32\n",
      "\n",
      "Epoch 47: val_wer_phase1 did not improve from 0.22000\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 329ms/step - loss: 2.0555 - val_loss: 5.0644 - val_wer_phase1: 0.2267 - learning_rate: 9.0000e-05\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Loading best weights from Phase 1 checkpoint: c:\\Users\\liene\\Documents\\GitHub\\LZV-CSLR\\models\\lzv\\1\\lzv_model_phase1_best_exp1.keras\n",
      "\n",
      "--- PHASE 2: Fine-tuning Top Layers of the Base Model ---\n",
      "  Unfrozen in Phase 2: None (already trainable or not found)\n",
      "  Base model 'asl_loaded_feature_base' trainable: True\n",
      "Trainable params for Phase 2:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"cslr_lzv_fine_tune_training_model\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"cslr_lzv_fine_tune_training_model\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                </span>┃<span style=\"font-weight: bold\"> Output Shape            </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to            </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_landmarks             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">42</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)     │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                │                         │                │                         │\n",
       "├─────────────────────────────┼─────────────────────────┼────────────────┼─────────────────────────┤\n",
       "│ reshape_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_landmarks[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────────────┼─────────────────────────┼────────────────┼─────────────────────────┤\n",
       "│ conv1d_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">80,768</span> │ reshape_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────────────┼─────────────────────────┼────────────────┼─────────────────────────┤\n",
       "│ batchnorm_conv              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv1d_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)        │                         │                │                         │\n",
       "├─────────────────────────────┼─────────────────────────┼────────────────┼─────────────────────────┤\n",
       "│ bilstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">98,816</span> │ batchnorm_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────────────┼─────────────────────────┼────────────────┼─────────────────────────┤\n",
       "│ batchnorm_lstm1             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ bilstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)        │                         │                │                         │\n",
       "├─────────────────────────────┼─────────────────────────┼────────────────┼─────────────────────────┤\n",
       "│ input_landmark_length_lzv   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)               │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                │                         │                │                         │\n",
       "├─────────────────────────────┼─────────────────────────┼────────────────┼─────────────────────────┤\n",
       "│ input_label_length_lzv      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)               │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                │                         │                │                         │\n",
       "├─────────────────────────────┼─────────────────────────┼────────────────┼─────────────────────────┤\n",
       "│ input_labels_lzv            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                │                         │                │                         │\n",
       "├─────────────────────────────┼─────────────────────────┼────────────────┼─────────────────────────┤\n",
       "│ output_dense_softmax_lzv    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">5,934</span> │ batchnorm_lstm1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)           │                         │                │                         │\n",
       "├─────────────────────────────┼─────────────────────────┼────────────────┼─────────────────────────┤\n",
       "│ squeeze_lm_len_lzv (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)                  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_landmark_length_… │\n",
       "├─────────────────────────────┼─────────────────────────┼────────────────┼─────────────────────────┤\n",
       "│ squeeze_ph_len_lzv (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)                  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_label_length_lzv… │\n",
       "├─────────────────────────────┼─────────────────────────┼────────────────┼─────────────────────────┤\n",
       "│ ctc_loss_lzv (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)               │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_labels_lzv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
       "│                             │                         │                │ output_dense_softmax_l… │\n",
       "│                             │                         │                │ squeeze_lm_len_lzv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                             │                         │                │ squeeze_ph_len_lzv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "└─────────────────────────────┴─────────────────────────┴────────────────┴─────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape           \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to           \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_landmarks             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m42\u001b[0m, \u001b[38;5;34m3\u001b[0m)     │              \u001b[38;5;34m0\u001b[0m │ -                       │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)                │                         │                │                         │\n",
       "├─────────────────────────────┼─────────────────────────┼────────────────┼─────────────────────────┤\n",
       "│ reshape_input (\u001b[38;5;33mReshape\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m126\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ input_landmarks[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────────────┼─────────────────────────┼────────────────┼─────────────────────────┤\n",
       "│ conv1d_layer (\u001b[38;5;33mConv1D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │         \u001b[38;5;34m80,768\u001b[0m │ reshape_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────────────┼─────────────────────────┼────────────────┼─────────────────────────┤\n",
       "│ batchnorm_conv              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │            \u001b[38;5;34m512\u001b[0m │ conv1d_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)        │                         │                │                         │\n",
       "├─────────────────────────────┼─────────────────────────┼────────────────┼─────────────────────────┤\n",
       "│ bilstm_1 (\u001b[38;5;33mBidirectional\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │         \u001b[38;5;34m98,816\u001b[0m │ batchnorm_conv[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────────────┼─────────────────────────┼────────────────┼─────────────────────────┤\n",
       "│ batchnorm_lstm1             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │            \u001b[38;5;34m512\u001b[0m │ bilstm_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)        │                         │                │                         │\n",
       "├─────────────────────────────┼─────────────────────────┼────────────────┼─────────────────────────┤\n",
       "│ input_landmark_length_lzv   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)               │              \u001b[38;5;34m0\u001b[0m │ -                       │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)                │                         │                │                         │\n",
       "├─────────────────────────────┼─────────────────────────┼────────────────┼─────────────────────────┤\n",
       "│ input_label_length_lzv      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)               │              \u001b[38;5;34m0\u001b[0m │ -                       │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)                │                         │                │                         │\n",
       "├─────────────────────────────┼─────────────────────────┼────────────────┼─────────────────────────┤\n",
       "│ input_labels_lzv            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ -                       │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)                │                         │                │                         │\n",
       "├─────────────────────────────┼─────────────────────────┼────────────────┼─────────────────────────┤\n",
       "│ output_dense_softmax_lzv    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m46\u001b[0m)        │          \u001b[38;5;34m5,934\u001b[0m │ batchnorm_lstm1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)           │                         │                │                         │\n",
       "├─────────────────────────────┼─────────────────────────┼────────────────┼─────────────────────────┤\n",
       "│ squeeze_lm_len_lzv (\u001b[38;5;33mLambda\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m)                  │              \u001b[38;5;34m0\u001b[0m │ input_landmark_length_… │\n",
       "├─────────────────────────────┼─────────────────────────┼────────────────┼─────────────────────────┤\n",
       "│ squeeze_ph_len_lzv (\u001b[38;5;33mLambda\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m)                  │              \u001b[38;5;34m0\u001b[0m │ input_label_length_lzv… │\n",
       "├─────────────────────────────┼─────────────────────────┼────────────────┼─────────────────────────┤\n",
       "│ ctc_loss_lzv (\u001b[38;5;33mLambda\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)               │              \u001b[38;5;34m0\u001b[0m │ input_labels_lzv[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
       "│                             │                         │                │ output_dense_softmax_l… │\n",
       "│                             │                         │                │ squeeze_lm_len_lzv[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│                             │                         │                │ squeeze_ph_len_lzv[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "└─────────────────────────────┴─────────────────────────┴────────────────┴─────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">397,068</span> (1.51 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m397,068\u001b[0m (1.51 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">105,006</span> (410.18 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m105,006\u001b[0m (410.18 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">81,536</span> (318.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m81,536\u001b[0m (318.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">210,526</span> (822.37 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m210,526\u001b[0m (822.37 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model re-compiled for Phase 2 with LR: 5e-05\n",
      "\n",
      "WERCallback initialized:\n",
      "  Decoder: Greedy\n",
      "  Metric Log Name: val_wer_phase2\n",
      "Starting Phase 2 training for 200 epochs, continuing from epoch 47...\n",
      "Epoch 48/247\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 298ms/step - loss: 2.1750\\nEpoch 48: Calculating Validation WER/CER...\n",
      "  Example True: '9   ļ o t i   s ē ņ o'\n",
      "  Example Pred: '9   ļ o t i   s ē ņ o'\n",
      "  Successfully calculated WER: 0.2167 using 64 pairs.\n",
      "  New best validation WER: 0.2167 (previous: inf at epoch 0)\n",
      "\n",
      "Epoch 48: val_wer_phase2 improved from inf to 0.21667, saving model to c:\\Users\\liene\\Documents\\GitHub\\LZV-CSLR\\models\\lzv\\1\\lzv_model_phase2_best_exp1.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 362ms/step - loss: 2.1725 - val_loss: 5.0032 - val_wer_phase2: 0.2167 - learning_rate: 5.0000e-05\n",
      "Epoch 49/247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\liene\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\saving\\serialization_lib.py:390: UserWarning: The object being serialized includes a `lambda`. This is unsafe. In order to reload the object, you will have to pass `safe_mode=False` to the loading function. Please avoid using `lambda` in the future, and use named Python functions instead. This is the `lambda` being serialized:     training_model.compile(optimizer=optimizer_phase2, loss=lambda y_true, y_pred: y_pred, metrics=[])\n",
      "\n",
      "  return {key: serialize_keras_object(value) for key, value in obj.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 311ms/step - loss: 2.0790\\nEpoch 49: Calculating Validation WER/CER...\n",
      "  Example True: '9   ļ o t i   s ē ņ o'\n",
      "  Example Pred: '9   ļ o t i   s ē ņ o'\n",
      "  Successfully calculated WER: 0.2133 using 64 pairs.\n",
      "  New best validation WER: 0.2133 (previous: 0.2167 at epoch 48)\n",
      "\n",
      "Epoch 49: val_wer_phase2 improved from 0.21667 to 0.21333, saving model to c:\\Users\\liene\\Documents\\GitHub\\LZV-CSLR\\models\\lzv\\1\\lzv_model_phase2_best_exp1.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 347ms/step - loss: 2.0840 - val_wer_phase2: 0.2133 - learning_rate: 5.0000e-05\n",
      "Epoch 50/247\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 302ms/step - loss: 2.1888\\nEpoch 50: Calculating Validation WER/CER...\n",
      "  Example True: '9   ļ o t i   s ē ņ o'\n",
      "  Example Pred: '9   ļ o t i   s ē ņ o'\n",
      "  Successfully calculated WER: 0.2167 using 64 pairs.\n",
      "  Validation WER (0.2167) did not improve. Best: 0.2133 at epoch 49\n",
      "\n",
      "Epoch 50: val_wer_phase2 did not improve from 0.21333\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 349ms/step - loss: 2.1881 - val_loss: 4.9691 - val_wer_phase2: 0.2167 - learning_rate: 5.0000e-05\n",
      "Epoch 51/247\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 256ms/step - loss: 2.4564\\nEpoch 51: Calculating Validation WER/CER...\n",
      "  Example True: '9   ļ o t i   s ē ņ o'\n",
      "  Example Pred: '9   ļ o t i   s ē ņ o'\n",
      "  Successfully calculated WER: 0.2200 using 64 pairs.\n",
      "  Validation WER (0.2200) did not improve. Best: 0.2133 at epoch 49\n",
      "\n",
      "Epoch 51: val_wer_phase2 did not improve from 0.21333\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 284ms/step - loss: 2.4528 - val_wer_phase2: 0.2200 - learning_rate: 5.0000e-05\n",
      "Epoch 52/247\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 280ms/step - loss: 1.8293\\nEpoch 52: Calculating Validation WER/CER...\n",
      "  Example True: '9   ļ o t i   s ē ņ o'\n",
      "  Example Pred: '9   ļ o t i   s ē ņ o'\n",
      "  Successfully calculated WER: 0.2167 using 64 pairs.\n",
      "  Validation WER (0.2167) did not improve. Best: 0.2133 at epoch 49\n",
      "\n",
      "Epoch 52: val_wer_phase2 did not improve from 0.21333\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 317ms/step - loss: 1.8312 - val_loss: 4.9693 - val_wer_phase2: 0.2167 - learning_rate: 5.0000e-05\n",
      "Epoch 53/247\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 286ms/step - loss: 1.9871\\nEpoch 53: Calculating Validation WER/CER...\n",
      "  Example True: '9   ļ o t i   s ē ņ o'\n",
      "  Example Pred: '9   ļ o t i   s ē ņ o'\n",
      "  Successfully calculated WER: 0.2133 using 64 pairs.\n",
      "  Validation WER (0.2133) did not improve. Best: 0.2133 at epoch 49\n",
      "\n",
      "Epoch 53: val_wer_phase2 did not improve from 0.21333\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 313ms/step - loss: 1.9854 - val_wer_phase2: 0.2133 - learning_rate: 5.0000e-05\n",
      "Epoch 54/247\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 300ms/step - loss: 1.4169\\nEpoch 54: Calculating Validation WER/CER...\n",
      "  Example True: '9   ļ o t i   s ē ņ o'\n",
      "  Example Pred: '9   ļ o t i   s ē ņ o'\n",
      "  Successfully calculated WER: 0.2133 using 64 pairs.\n",
      "  Validation WER (0.2133) did not improve. Best: 0.2133 at epoch 49\n",
      "\n",
      "Epoch 54: val_wer_phase2 did not improve from 0.21333\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 338ms/step - loss: 1.4216 - val_loss: 4.9698 - val_wer_phase2: 0.2133 - learning_rate: 5.0000e-05\n",
      "Epoch 55/247\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 303ms/step - loss: 2.0261\\nEpoch 55: Calculating Validation WER/CER...\n",
      "  Example True: '9   ļ o t i   s ē ņ o'\n",
      "  Example Pred: '9   ļ o t i   s ē ņ o'\n",
      "  Successfully calculated WER: 0.2200 using 64 pairs.\n",
      "  Validation WER (0.2200) did not improve. Best: 0.2133 at epoch 49\n",
      "\n",
      "Epoch 55: val_wer_phase2 did not improve from 0.21333\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 353ms/step - loss: 2.0259 - val_wer_phase2: 0.2200 - learning_rate: 5.0000e-05\n",
      "Epoch 56/247\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 368ms/step - loss: 2.2839\\nEpoch 56: Calculating Validation WER/CER...\n",
      "  Example True: '9   ļ o t i   s ē ņ o'\n",
      "  Example Pred: '9   ļ o t i   s ē ņ o'\n",
      "  Successfully calculated WER: 0.2100 using 64 pairs.\n",
      "  New best validation WER: 0.2100 (previous: 0.2133 at epoch 49)\n",
      "\n",
      "Epoch 56: val_wer_phase2 improved from 0.21333 to 0.21000, saving model to c:\\Users\\liene\\Documents\\GitHub\\LZV-CSLR\\models\\lzv\\1\\lzv_model_phase2_best_exp1.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 436ms/step - loss: 2.2847 - val_loss: 4.9297 - val_wer_phase2: 0.2100 - learning_rate: 5.0000e-05\n",
      "Epoch 57/247\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 353ms/step - loss: 2.1566\\nEpoch 57: Calculating Validation WER/CER...\n",
      "  Example True: '9   ļ o t i   s ē ņ o'\n",
      "  Example Pred: '9   ļ o t i   s ē ņ o'\n",
      "  Successfully calculated WER: 0.2167 using 64 pairs.\n",
      "  Validation WER (0.2167) did not improve. Best: 0.2100 at epoch 56\n",
      "\n",
      "Epoch 57: val_wer_phase2 did not improve from 0.21000\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 408ms/step - loss: 2.1580 - val_wer_phase2: 0.2167 - learning_rate: 5.0000e-05\n",
      "Epoch 58/247\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 418ms/step - loss: 1.9968\\nEpoch 58: Calculating Validation WER/CER...\n",
      "  Example True: '9   ļ o t i   s ē ņ o'\n",
      "  Example Pred: '9   ļ o t i   s ē ņ o'\n",
      "  Successfully calculated WER: 0.2133 using 64 pairs.\n",
      "  Validation WER (0.2133) did not improve. Best: 0.2100 at epoch 56\n",
      "\n",
      "Epoch 58: val_wer_phase2 did not improve from 0.21000\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 481ms/step - loss: 1.9952 - val_loss: 4.9704 - val_wer_phase2: 0.2133 - learning_rate: 5.0000e-05\n",
      "Epoch 59/247\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 423ms/step - loss: 1.8968\\nEpoch 59: Calculating Validation WER/CER...\n",
      "  Example True: '9   ļ o t i   s ē ņ o'\n",
      "  Example Pred: '9   ļ o t i   s ē ņ o'\n",
      "  Successfully calculated WER: 0.2133 using 64 pairs.\n",
      "  Validation WER (0.2133) did not improve. Best: 0.2100 at epoch 56\n",
      "\n",
      "Epoch 59: val_wer_phase2 did not improve from 0.21000\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 477ms/step - loss: 1.8977 - val_wer_phase2: 0.2133 - learning_rate: 5.0000e-05\n",
      "Epoch 60/247\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 450ms/step - loss: 1.6514\\nEpoch 60: Calculating Validation WER/CER...\n",
      "  Example True: '9   ļ o t i   s ē ņ o'\n",
      "  Example Pred: '9   ļ o t i   s ē ņ o'\n",
      "  Successfully calculated WER: 0.2167 using 64 pairs.\n",
      "  Validation WER (0.2167) did not improve. Best: 0.2100 at epoch 56\n",
      "\n",
      "Epoch 60: val_wer_phase2 did not improve from 0.21000\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 517ms/step - loss: 1.6519 - val_loss: 4.9833 - val_wer_phase2: 0.2167 - learning_rate: 5.0000e-05\n",
      "Epoch 61/247\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 436ms/step - loss: 2.1982\\nEpoch 61: Calculating Validation WER/CER...\n",
      "  Example True: '9   ļ o t i   s ē ņ o'\n",
      "  Example Pred: '9   ļ o t i   s ē ņ o'\n",
      "  Successfully calculated WER: 0.2100 using 64 pairs.\n",
      "  Validation WER (0.2100) did not improve. Best: 0.2100 at epoch 56\n",
      "\n",
      "Epoch 61: val_wer_phase2 did not improve from 0.21000\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 491ms/step - loss: 2.1934 - val_wer_phase2: 0.2100 - learning_rate: 5.0000e-05\n",
      "Epoch 62/247\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 406ms/step - loss: 1.7553\\nEpoch 62: Calculating Validation WER/CER...\n",
      "  Example True: '9   ļ o t i   s ē ņ o'\n",
      "  Example Pred: '9   ļ o t i   s ē ņ o'\n",
      "  Successfully calculated WER: 0.2100 using 64 pairs.\n",
      "  Validation WER (0.2100) did not improve. Best: 0.2100 at epoch 56\n",
      "\n",
      "Epoch 62: val_wer_phase2 did not improve from 0.21000\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 470ms/step - loss: 1.7540 - val_loss: 4.9858 - val_wer_phase2: 0.2100 - learning_rate: 5.0000e-05\n",
      "Epoch 63/247\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 464ms/step - loss: 1.7768\\nEpoch 63: Calculating Validation WER/CER...\n",
      "  Example True: '9   ļ o t i   s ē ņ o'\n",
      "  Example Pred: '9   ļ o t i   s ē ņ o'\n",
      "  Successfully calculated WER: 0.2167 using 64 pairs.\n",
      "  Validation WER (0.2167) did not improve. Best: 0.2100 at epoch 56\n",
      "\n",
      "Epoch 63: val_wer_phase2 did not improve from 0.21000\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 512ms/step - loss: 1.7776 - val_wer_phase2: 0.2167 - learning_rate: 5.0000e-05\n",
      "Epoch 64/247\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 411ms/step - loss: 2.4047\\nEpoch 64: Calculating Validation WER/CER...\n",
      "  Example True: '9   ļ o t i   s ē ņ o'\n",
      "  Example Pred: '9   ļ o t i   s ē ņ o'\n",
      "  Successfully calculated WER: 0.2200 using 64 pairs.\n",
      "  Validation WER (0.2200) did not improve. Best: 0.2100 at epoch 56\n",
      "\n",
      "Epoch 64: val_wer_phase2 did not improve from 0.21000\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 481ms/step - loss: 2.3978 - val_loss: 4.9413 - val_wer_phase2: 0.2200 - learning_rate: 5.0000e-05\n",
      "Epoch 65/247\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 463ms/step - loss: 1.9118\\nEpoch 65: Calculating Validation WER/CER...\n",
      "  Example True: '9   ļ o t i   s ē ņ o'\n",
      "  Example Pred: '9   ļ o t i   s ē ņ o'\n",
      "  Successfully calculated WER: 0.2133 using 64 pairs.\n",
      "  Validation WER (0.2133) did not improve. Best: 0.2100 at epoch 56\n",
      "\n",
      "Epoch 65: val_wer_phase2 did not improve from 0.21000\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 515ms/step - loss: 1.9104 - val_wer_phase2: 0.2133 - learning_rate: 5.0000e-05\n",
      "Epoch 66/247\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 404ms/step - loss: 1.5430\\nEpoch 66: Calculating Validation WER/CER...\n",
      "  Example True: '9   ļ o t i   s ē ņ o'\n",
      "  Example Pred: '9   ļ o t i   s ē ņ o'\n",
      "  Successfully calculated WER: 0.2167 using 64 pairs.\n",
      "  Validation WER (0.2167) did not improve. Best: 0.2100 at epoch 56\n",
      "\n",
      "Epoch 66: val_wer_phase2 did not improve from 0.21000\n",
      "\n",
      "Epoch 66: ReduceLROnPlateau reducing learning rate to 1.4999999621068127e-05.\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 473ms/step - loss: 1.5437 - val_loss: 4.9352 - val_wer_phase2: 0.2167 - learning_rate: 5.0000e-05\n",
      "Epoch 67/247\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 408ms/step - loss: 1.8523\\nEpoch 67: Calculating Validation WER/CER...\n",
      "  Example True: '9   ļ o t i   s ē ņ o'\n",
      "  Example Pred: '9   ļ o t i   s ē ņ o'\n",
      "  Successfully calculated WER: 0.2200 using 64 pairs.\n",
      "  Validation WER (0.2200) did not improve. Best: 0.2100 at epoch 56\n",
      "\n",
      "Epoch 67: val_wer_phase2 did not improve from 0.21000\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 463ms/step - loss: 1.8520 - val_wer_phase2: 0.2200 - learning_rate: 1.5000e-05\n",
      "Epoch 68/247\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 450ms/step - loss: 1.6955\\nEpoch 68: Calculating Validation WER/CER...\n",
      "  Example True: '9   ļ o t i   s ē ņ o'\n",
      "  Example Pred: '9   ļ o t i   s ē ņ o'\n",
      "  Successfully calculated WER: 0.2133 using 64 pairs.\n",
      "  Validation WER (0.2133) did not improve. Best: 0.2100 at epoch 56\n",
      "\n",
      "Epoch 68: val_wer_phase2 did not improve from 0.21000\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 521ms/step - loss: 1.6957 - val_loss: 4.9458 - val_wer_phase2: 0.2133 - learning_rate: 1.5000e-05\n",
      "Epoch 69/247\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 429ms/step - loss: 1.6378\\nEpoch 69: Calculating Validation WER/CER...\n",
      "  Example True: '9   ļ o t i   s ē ņ o'\n",
      "  Example Pred: '9   ļ o t i   s ē ņ o'\n",
      "  Successfully calculated WER: 0.2133 using 64 pairs.\n",
      "  Validation WER (0.2133) did not improve. Best: 0.2100 at epoch 56\n",
      "\n",
      "Epoch 69: val_wer_phase2 did not improve from 0.21000\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 481ms/step - loss: 1.6355 - val_wer_phase2: 0.2133 - learning_rate: 1.5000e-05\n",
      "Epoch 70/247\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 367ms/step - loss: 1.5636\\nEpoch 70: Calculating Validation WER/CER...\n",
      "  Example True: '9   ļ o t i   s ē ņ o'\n",
      "  Example Pred: '9   ļ o t i   s ē ņ o'\n",
      "  Successfully calculated WER: 0.2067 using 64 pairs.\n",
      "  New best validation WER: 0.2067 (previous: 0.2100 at epoch 56)\n",
      "\n",
      "Epoch 70: val_wer_phase2 improved from 0.21000 to 0.20667, saving model to c:\\Users\\liene\\Documents\\GitHub\\LZV-CSLR\\models\\lzv\\1\\lzv_model_phase2_best_exp1.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 435ms/step - loss: 1.5665 - val_loss: 4.9656 - val_wer_phase2: 0.2067 - learning_rate: 1.5000e-05\n",
      "Epoch 71/247\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390ms/step - loss: 1.7254\\nEpoch 71: Calculating Validation WER/CER...\n",
      "  Example True: '9   ļ o t i   s ē ņ o'\n",
      "  Example Pred: '9   ļ o t i   s ē ņ o'\n",
      "  Successfully calculated WER: 0.2100 using 64 pairs.\n",
      "  Validation WER (0.2100) did not improve. Best: 0.2067 at epoch 70\n",
      "\n",
      "Epoch 71: val_wer_phase2 did not improve from 0.20667\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 441ms/step - loss: 1.7250 - val_wer_phase2: 0.2100 - learning_rate: 1.5000e-05\n",
      "Epoch 72/247\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 398ms/step - loss: 2.2191\\nEpoch 72: Calculating Validation WER/CER...\n",
      "  Example True: '9   ļ o t i   s ē ņ o'\n",
      "  Example Pred: '9   ļ o t i   s ē ņ o'\n",
      "  Successfully calculated WER: 0.2167 using 64 pairs.\n",
      "  Validation WER (0.2167) did not improve. Best: 0.2067 at epoch 70\n",
      "\n",
      "Epoch 72: val_wer_phase2 did not improve from 0.20667\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 470ms/step - loss: 2.2156 - val_loss: 4.9243 - val_wer_phase2: 0.2167 - learning_rate: 1.5000e-05\n",
      "Epoch 73/247\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 422ms/step - loss: 1.6233\\nEpoch 73: Calculating Validation WER/CER...\n",
      "  Example True: '9   ļ o t i   s ē ņ o'\n",
      "  Example Pred: '9   ļ o t i   s ē ņ o'\n",
      "  Successfully calculated WER: 0.2133 using 64 pairs.\n",
      "  Validation WER (0.2133) did not improve. Best: 0.2067 at epoch 70\n",
      "\n",
      "Epoch 73: val_wer_phase2 did not improve from 0.20667\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 474ms/step - loss: 1.6271 - val_wer_phase2: 0.2133 - learning_rate: 1.5000e-05\n",
      "Epoch 74/247\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390ms/step - loss: 1.5888\\nEpoch 74: Calculating Validation WER/CER...\n",
      "  Example True: '9   ļ o t i   s ē ņ o'\n",
      "  Example Pred: '9   ļ o t i   s ē ņ o'\n",
      "  Successfully calculated WER: 0.2133 using 64 pairs.\n",
      "  Validation WER (0.2133) did not improve. Best: 0.2067 at epoch 70\n",
      "\n",
      "Epoch 74: val_wer_phase2 did not improve from 0.20667\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 457ms/step - loss: 1.5879 - val_loss: 4.9347 - val_wer_phase2: 0.2133 - learning_rate: 1.5000e-05\n",
      "Epoch 75/247\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383ms/step - loss: 1.5558\\nEpoch 75: Calculating Validation WER/CER...\n",
      "  Example True: '9   ļ o t i   s ē ņ o'\n",
      "  Example Pred: '9   ļ o t i   s ē ņ o'\n",
      "  Successfully calculated WER: 0.2133 using 64 pairs.\n",
      "  Validation WER (0.2133) did not improve. Best: 0.2067 at epoch 70\n",
      "\n",
      "Epoch 75: val_wer_phase2 did not improve from 0.20667\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 432ms/step - loss: 1.5574 - val_wer_phase2: 0.2133 - learning_rate: 1.5000e-05\n",
      "Epoch 76/247\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 435ms/step - loss: 1.4225\\nEpoch 76: Calculating Validation WER/CER...\n",
      "  Example True: '9   ļ o t i   s ē ņ o'\n",
      "  Example Pred: '9   ļ o t i   s ē ņ o'\n",
      "  Successfully calculated WER: 0.2167 using 64 pairs.\n",
      "  Validation WER (0.2167) did not improve. Best: 0.2067 at epoch 70\n",
      "\n",
      "Epoch 76: val_wer_phase2 did not improve from 0.20667\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 502ms/step - loss: 1.4228 - val_loss: 4.9414 - val_wer_phase2: 0.2167 - learning_rate: 1.5000e-05\n",
      "Epoch 77/247\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 398ms/step - loss: 2.0918\\nEpoch 77: Calculating Validation WER/CER...\n",
      "  Example True: '9   ļ o t i   s ē ņ o'\n",
      "  Example Pred: '9   ļ o t i   s ē ņ o'\n",
      "  Successfully calculated WER: 0.2100 using 64 pairs.\n",
      "  Validation WER (0.2100) did not improve. Best: 0.2067 at epoch 70\n",
      "\n",
      "Epoch 77: val_wer_phase2 did not improve from 0.20667\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 447ms/step - loss: 2.0896 - val_wer_phase2: 0.2100 - learning_rate: 1.5000e-05\n",
      "Epoch 78/247\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457ms/step - loss: 1.5198\\nEpoch 78: Calculating Validation WER/CER...\n",
      "  Example True: '9   ļ o t i   s ē ņ o'\n",
      "  Example Pred: '9   ļ o t i   s ē ņ o'\n",
      "  Successfully calculated WER: 0.2133 using 64 pairs.\n",
      "  Validation WER (0.2133) did not improve. Best: 0.2067 at epoch 70\n",
      "\n",
      "Epoch 78: val_wer_phase2 did not improve from 0.20667\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 518ms/step - loss: 1.5192 - val_loss: 4.9609 - val_wer_phase2: 0.2133 - learning_rate: 1.5000e-05\n",
      "Epoch 79/247\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 405ms/step - loss: 1.8461\\nEpoch 79: Calculating Validation WER/CER...\n",
      "  Example True: '9   ļ o t i   s ē ņ o'\n",
      "  Example Pred: '9   ļ o t i   s ē ņ o'\n",
      "  Successfully calculated WER: 0.2133 using 64 pairs.\n",
      "  Validation WER (0.2133) did not improve. Best: 0.2067 at epoch 70\n",
      "\n",
      "Epoch 79: val_wer_phase2 did not improve from 0.20667\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 451ms/step - loss: 1.8451 - val_wer_phase2: 0.2133 - learning_rate: 1.5000e-05\n",
      "Epoch 80/247\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 426ms/step - loss: 1.8338\\nEpoch 80: Calculating Validation WER/CER...\n",
      "  Example True: '9   ļ o t i   s ē ņ o'\n",
      "  Example Pred: '9   ļ o t i   s ē ņ o'\n",
      "  Successfully calculated WER: 0.2100 using 64 pairs.\n",
      "  Validation WER (0.2100) did not improve. Best: 0.2067 at epoch 70\n",
      "\n",
      "Epoch 80: val_wer_phase2 did not improve from 0.20667\n",
      "\n",
      "Epoch 80: ReduceLROnPlateau reducing learning rate to 4.499999886320438e-06.\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 492ms/step - loss: 1.8309 - val_loss: 4.9544 - val_wer_phase2: 0.2100 - learning_rate: 1.5000e-05\n",
      "Epoch 81/247\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 482ms/step - loss: 1.6153\\nEpoch 81: Calculating Validation WER/CER...\n",
      "  Example True: '9   ļ o t i   s ē ņ o'\n",
      "  Example Pred: '9   ļ o t i   s ē ņ o'\n",
      "  Successfully calculated WER: 0.2133 using 64 pairs.\n",
      "  Validation WER (0.2133) did not improve. Best: 0.2067 at epoch 70\n",
      "\n",
      "Epoch 81: val_wer_phase2 did not improve from 0.20667\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 528ms/step - loss: 1.6147 - val_wer_phase2: 0.2133 - learning_rate: 4.5000e-06\n",
      "Epoch 82/247\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 434ms/step - loss: 1.9366\\nEpoch 82: Calculating Validation WER/CER...\n",
      "  Example True: '9   ļ o t i   s ē ņ o'\n",
      "  Example Pred: '9   ļ o t i   s ē ņ o'\n",
      "  Successfully calculated WER: 0.2133 using 64 pairs.\n",
      "  Validation WER (0.2133) did not improve. Best: 0.2067 at epoch 70\n",
      "\n",
      "Epoch 82: val_wer_phase2 did not improve from 0.20667\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 497ms/step - loss: 1.9341 - val_loss: 4.9427 - val_wer_phase2: 0.2133 - learning_rate: 4.5000e-06\n",
      "Epoch 83/247\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384ms/step - loss: 1.9006\\nEpoch 83: Calculating Validation WER/CER...\n",
      "  Example True: '9   ļ o t i   s ē ņ o'\n",
      "  Example Pred: '9   ļ o t i   s ē ņ o'\n",
      "  Successfully calculated WER: 0.2133 using 64 pairs.\n",
      "  Validation WER (0.2133) did not improve. Best: 0.2067 at epoch 70\n",
      "\n",
      "Epoch 83: val_wer_phase2 did not improve from 0.20667\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 430ms/step - loss: 1.8978 - val_wer_phase2: 0.2133 - learning_rate: 4.5000e-06\n",
      "Epoch 84/247\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 467ms/step - loss: 1.3620\\nEpoch 84: Calculating Validation WER/CER...\n",
      "  Example True: '9   ļ o t i   s ē ņ o'\n",
      "  Example Pred: '9   ļ o t i   s ē ņ o'\n",
      "  Successfully calculated WER: 0.2133 using 64 pairs.\n",
      "  Validation WER (0.2133) did not improve. Best: 0.2067 at epoch 70\n",
      "\n",
      "Epoch 84: val_wer_phase2 did not improve from 0.20667\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 530ms/step - loss: 1.3646 - val_loss: 4.9545 - val_wer_phase2: 0.2133 - learning_rate: 4.5000e-06\n",
      "Epoch 85/247\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 467ms/step - loss: 1.5987\\nEpoch 85: Calculating Validation WER/CER...\n",
      "  Example True: '9   ļ o t i   s ē ņ o'\n",
      "  Example Pred: '9   ļ o t i   s ē ņ o'\n",
      "  Successfully calculated WER: 0.2167 using 64 pairs.\n",
      "  Validation WER (0.2167) did not improve. Best: 0.2067 at epoch 70\n",
      "\n",
      "Epoch 85: val_wer_phase2 did not improve from 0.20667\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 515ms/step - loss: 1.6010 - val_wer_phase2: 0.2167 - learning_rate: 4.5000e-06\n",
      "Epoch 86/247\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 426ms/step - loss: 1.6821\\nEpoch 86: Calculating Validation WER/CER...\n",
      "  Example True: '9   ļ o t i   s ē ņ o'\n",
      "  Example Pred: '9   ļ o t i   s ē ņ o'\n",
      "  Successfully calculated WER: 0.2200 using 64 pairs.\n",
      "  Validation WER (0.2200) did not improve. Best: 0.2067 at epoch 70\n",
      "\n",
      "Epoch 86: val_wer_phase2 did not improve from 0.20667\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 488ms/step - loss: 1.6809 - val_loss: 4.9198 - val_wer_phase2: 0.2200 - learning_rate: 4.5000e-06\n",
      "Epoch 87/247\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 410ms/step - loss: 1.8365\\nEpoch 87: Calculating Validation WER/CER...\n",
      "  Example True: '9   ļ o t i   s ē ņ o'\n",
      "  Example Pred: '9   ļ o t i   s ē ņ o'\n",
      "  Successfully calculated WER: 0.2133 using 64 pairs.\n",
      "  Validation WER (0.2133) did not improve. Best: 0.2067 at epoch 70\n",
      "\n",
      "Epoch 87: val_wer_phase2 did not improve from 0.20667\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 454ms/step - loss: 1.8350 - val_wer_phase2: 0.2133 - learning_rate: 4.5000e-06\n",
      "Epoch 88/247\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 496ms/step - loss: 1.5322\\nEpoch 88: Calculating Validation WER/CER...\n",
      "  Example True: '9   ļ o t i   s ē ņ o'\n",
      "  Example Pred: '9   ļ o t i   s ē ņ o'\n",
      "  Successfully calculated WER: 0.2167 using 64 pairs.\n",
      "  Validation WER (0.2167) did not improve. Best: 0.2067 at epoch 70\n",
      "\n",
      "Epoch 88: val_wer_phase2 did not improve from 0.20667\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 562ms/step - loss: 1.5363 - val_loss: 4.9304 - val_wer_phase2: 0.2167 - learning_rate: 4.5000e-06\n",
      "Epoch 89/247\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452ms/step - loss: 1.8827\\nEpoch 89: Calculating Validation WER/CER...\n",
      "  Example True: '9   ļ o t i   s ē ņ o'\n",
      "  Example Pred: '9   ļ o t i   s ē ņ o'\n",
      "  Successfully calculated WER: 0.2167 using 64 pairs.\n",
      "  Validation WER (0.2167) did not improve. Best: 0.2067 at epoch 70\n",
      "\n",
      "Epoch 89: val_wer_phase2 did not improve from 0.20667\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 494ms/step - loss: 1.8786 - val_wer_phase2: 0.2167 - learning_rate: 4.5000e-06\n",
      "Epoch 90/247\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 428ms/step - loss: 1.4590\\nEpoch 90: Calculating Validation WER/CER...\n",
      "  Example True: '9   ļ o t i   s ē ņ o'\n",
      "  Example Pred: '9   ļ o t i   s ē ņ o'\n",
      "  Successfully calculated WER: 0.2167 using 64 pairs.\n",
      "  Validation WER (0.2167) did not improve. Best: 0.2067 at epoch 70\n",
      "\n",
      "Epoch 90: val_wer_phase2 did not improve from 0.20667\n",
      "\n",
      "Epoch 90: ReduceLROnPlateau reducing learning rate to 1.3499999113264492e-06.\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 488ms/step - loss: 1.4617 - val_loss: 4.9647 - val_wer_phase2: 0.2167 - learning_rate: 4.5000e-06\n",
      "Epoch 91/247\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - loss: 1.5347\\nEpoch 91: Calculating Validation WER/CER...\n",
      "  Example True: '9   ļ o t i   s ē ņ o'\n",
      "  Example Pred: '9   ļ o t i   s ē ņ o'\n",
      "  Successfully calculated WER: 0.2167 using 64 pairs.\n",
      "  Validation WER (0.2167) did not improve. Best: 0.2067 at epoch 70\n",
      "\n",
      "Epoch 91: val_wer_phase2 did not improve from 0.20667\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 458ms/step - loss: 1.5356 - val_wer_phase2: 0.2167 - learning_rate: 1.3500e-06\n",
      "Epoch 92/247\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479ms/step - loss: 2.1885\\nEpoch 92: Calculating Validation WER/CER...\n",
      "  Example True: '9   ļ o t i   s ē ņ o'\n",
      "  Example Pred: '9   ļ o t i   s ē ņ o'\n",
      "  Successfully calculated WER: 0.2133 using 64 pairs.\n",
      "  Validation WER (0.2133) did not improve. Best: 0.2067 at epoch 70\n",
      "\n",
      "Epoch 92: val_wer_phase2 did not improve from 0.20667\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 543ms/step - loss: 2.1846 - val_loss: 4.9439 - val_wer_phase2: 0.2133 - learning_rate: 1.3500e-06\n",
      "Epoch 93/247\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 437ms/step - loss: 1.6579\\nEpoch 93: Calculating Validation WER/CER...\n",
      "  Example True: '9   ļ o t i   s ē ņ o'\n",
      "  Example Pred: '9   ļ o t i   s ē ņ o'\n",
      "  Successfully calculated WER: 0.2133 using 64 pairs.\n",
      "  Validation WER (0.2133) did not improve. Best: 0.2067 at epoch 70\n",
      "\n",
      "Epoch 93: val_wer_phase2 did not improve from 0.20667\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 484ms/step - loss: 1.6595 - val_wer_phase2: 0.2133 - learning_rate: 1.3500e-06\n",
      "Epoch 94/247\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403ms/step - loss: 1.5461\\nEpoch 94: Calculating Validation WER/CER...\n",
      "  Example True: '9   ļ o t i   s ē ņ o'\n",
      "  Example Pred: '9   ļ o t i   s ē ņ o'\n",
      "  Successfully calculated WER: 0.2200 using 64 pairs.\n",
      "  Validation WER (0.2200) did not improve. Best: 0.2067 at epoch 70\n",
      "\n",
      "Epoch 94: val_wer_phase2 did not improve from 0.20667\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 466ms/step - loss: 1.5462 - val_loss: 4.9320 - val_wer_phase2: 0.2200 - learning_rate: 1.3500e-06\n",
      "Epoch 95/247\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 438ms/step - loss: 1.6342\\nEpoch 95: Calculating Validation WER/CER...\n",
      "  Example True: '9   ļ o t i   s ē ņ o'\n",
      "  Example Pred: '9   ļ o t i   s ē ņ o'\n",
      "  Successfully calculated WER: 0.2167 using 64 pairs.\n",
      "  Validation WER (0.2167) did not improve. Best: 0.2067 at epoch 70\n",
      "\n",
      "Epoch 95: val_wer_phase2 did not improve from 0.20667\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 489ms/step - loss: 1.6368 - val_wer_phase2: 0.2167 - learning_rate: 1.3500e-06\n",
      "Epoch 95: early stopping\n",
      "Restoring model weights from the end of the best epoch: 70.\n",
      "Loading best weights from Phase 2 checkpoint: c:\\Users\\liene\\Documents\\GitHub\\LZV-CSLR\\models\\lzv\\1\\lzv_model_phase2_best_exp1.keras\n",
      "\n",
      "--- PHASE 3: Fine-tuning More Base Layers (including Conv1D) ---\n",
      "Setting trainable status for Phase 3:\n",
      "  Unfrozen in Phase 3 (or confirmed): ['conv1d_layer', 'batchnorm_conv']\n",
      "Trainable params for Phase 3:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"cslr_lzv_fine_tune_training_model\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"cslr_lzv_fine_tune_training_model\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                </span>┃<span style=\"font-weight: bold\"> Output Shape            </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to            </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_landmarks             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">42</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)     │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                │                         │                │                         │\n",
       "├─────────────────────────────┼─────────────────────────┼────────────────┼─────────────────────────┤\n",
       "│ reshape_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_landmarks[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────────────┼─────────────────────────┼────────────────┼─────────────────────────┤\n",
       "│ conv1d_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">80,768</span> │ reshape_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────────────┼─────────────────────────┼────────────────┼─────────────────────────┤\n",
       "│ batchnorm_conv              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv1d_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)        │                         │                │                         │\n",
       "├─────────────────────────────┼─────────────────────────┼────────────────┼─────────────────────────┤\n",
       "│ bilstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">98,816</span> │ batchnorm_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────────────┼─────────────────────────┼────────────────┼─────────────────────────┤\n",
       "│ batchnorm_lstm1             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ bilstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)        │                         │                │                         │\n",
       "├─────────────────────────────┼─────────────────────────┼────────────────┼─────────────────────────┤\n",
       "│ input_landmark_length_lzv   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)               │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                │                         │                │                         │\n",
       "├─────────────────────────────┼─────────────────────────┼────────────────┼─────────────────────────┤\n",
       "│ input_label_length_lzv      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)               │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                │                         │                │                         │\n",
       "├─────────────────────────────┼─────────────────────────┼────────────────┼─────────────────────────┤\n",
       "│ input_labels_lzv            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                │                         │                │                         │\n",
       "├─────────────────────────────┼─────────────────────────┼────────────────┼─────────────────────────┤\n",
       "│ output_dense_softmax_lzv    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">5,934</span> │ batchnorm_lstm1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)           │                         │                │                         │\n",
       "├─────────────────────────────┼─────────────────────────┼────────────────┼─────────────────────────┤\n",
       "│ squeeze_lm_len_lzv (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)                  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_landmark_length_… │\n",
       "├─────────────────────────────┼─────────────────────────┼────────────────┼─────────────────────────┤\n",
       "│ squeeze_ph_len_lzv (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)                  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_label_length_lzv… │\n",
       "├─────────────────────────────┼─────────────────────────┼────────────────┼─────────────────────────┤\n",
       "│ ctc_loss_lzv (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)               │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_labels_lzv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
       "│                             │                         │                │ output_dense_softmax_l… │\n",
       "│                             │                         │                │ squeeze_lm_len_lzv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                             │                         │                │ squeeze_ph_len_lzv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "└─────────────────────────────┴─────────────────────────┴────────────────┴─────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape           \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to           \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_landmarks             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m42\u001b[0m, \u001b[38;5;34m3\u001b[0m)     │              \u001b[38;5;34m0\u001b[0m │ -                       │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)                │                         │                │                         │\n",
       "├─────────────────────────────┼─────────────────────────┼────────────────┼─────────────────────────┤\n",
       "│ reshape_input (\u001b[38;5;33mReshape\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m126\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ input_landmarks[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────────────┼─────────────────────────┼────────────────┼─────────────────────────┤\n",
       "│ conv1d_layer (\u001b[38;5;33mConv1D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │         \u001b[38;5;34m80,768\u001b[0m │ reshape_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────────────┼─────────────────────────┼────────────────┼─────────────────────────┤\n",
       "│ batchnorm_conv              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │            \u001b[38;5;34m512\u001b[0m │ conv1d_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)        │                         │                │                         │\n",
       "├─────────────────────────────┼─────────────────────────┼────────────────┼─────────────────────────┤\n",
       "│ bilstm_1 (\u001b[38;5;33mBidirectional\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │         \u001b[38;5;34m98,816\u001b[0m │ batchnorm_conv[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────────────┼─────────────────────────┼────────────────┼─────────────────────────┤\n",
       "│ batchnorm_lstm1             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │            \u001b[38;5;34m512\u001b[0m │ bilstm_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)        │                         │                │                         │\n",
       "├─────────────────────────────┼─────────────────────────┼────────────────┼─────────────────────────┤\n",
       "│ input_landmark_length_lzv   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)               │              \u001b[38;5;34m0\u001b[0m │ -                       │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)                │                         │                │                         │\n",
       "├─────────────────────────────┼─────────────────────────┼────────────────┼─────────────────────────┤\n",
       "│ input_label_length_lzv      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)               │              \u001b[38;5;34m0\u001b[0m │ -                       │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)                │                         │                │                         │\n",
       "├─────────────────────────────┼─────────────────────────┼────────────────┼─────────────────────────┤\n",
       "│ input_labels_lzv            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ -                       │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)                │                         │                │                         │\n",
       "├─────────────────────────────┼─────────────────────────┼────────────────┼─────────────────────────┤\n",
       "│ output_dense_softmax_lzv    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m46\u001b[0m)        │          \u001b[38;5;34m5,934\u001b[0m │ batchnorm_lstm1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)           │                         │                │                         │\n",
       "├─────────────────────────────┼─────────────────────────┼────────────────┼─────────────────────────┤\n",
       "│ squeeze_lm_len_lzv (\u001b[38;5;33mLambda\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m)                  │              \u001b[38;5;34m0\u001b[0m │ input_landmark_length_… │\n",
       "├─────────────────────────────┼─────────────────────────┼────────────────┼─────────────────────────┤\n",
       "│ squeeze_ph_len_lzv (\u001b[38;5;33mLambda\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m)                  │              \u001b[38;5;34m0\u001b[0m │ input_label_length_lzv… │\n",
       "├─────────────────────────────┼─────────────────────────┼────────────────┼─────────────────────────┤\n",
       "│ ctc_loss_lzv (\u001b[38;5;33mLambda\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)               │              \u001b[38;5;34m0\u001b[0m │ input_labels_lzv[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
       "│                             │                         │                │ output_dense_softmax_l… │\n",
       "│                             │                         │                │ squeeze_lm_len_lzv[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│                             │                         │                │ squeeze_ph_len_lzv[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "└─────────────────────────────┴─────────────────────────┴────────────────┴─────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">396,556</span> (1.51 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m396,556\u001b[0m (1.51 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">186,030</span> (726.68 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m186,030\u001b[0m (726.68 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> (2.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m512\u001b[0m (2.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">210,014</span> (820.37 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m210,014\u001b[0m (820.37 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model re-compiled for Phase 3 with LR: 1e-06\n",
      "\n",
      "WERCallback initialized:\n",
      "  Decoder: Greedy\n",
      "  Metric Log Name: val_wer_phase3\n",
      "Starting Phase 3 training for 100 epochs, continuing from epoch 94...\n",
      "Epoch 95/194\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 441ms/step - loss: 2.0106\\nEpoch 95: Calculating Validation WER/CER...\n",
      "  Example True: '9   ļ o t i   s ē ņ o'\n",
      "  Example Pred: '9   ļ o t i   s ē ņ o'\n",
      "  Successfully calculated WER: 0.2133 using 64 pairs.\n",
      "  New best validation WER: 0.2133 (previous: inf at epoch 0)\n",
      "\n",
      "Epoch 95: val_wer_phase3 improved from inf to 0.21333, saving model to c:\\Users\\liene\\Documents\\GitHub\\LZV-CSLR\\models\\lzv\\1\\lzv_model_phase3_best_exp1.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 526ms/step - loss: 2.0073 - val_loss: 4.8997 - val_wer_phase3: 0.2133 - learning_rate: 1.0000e-06\n",
      "Epoch 96/194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\liene\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\saving\\serialization_lib.py:390: UserWarning: The object being serialized includes a `lambda`. This is unsafe. In order to reload the object, you will have to pass `safe_mode=False` to the loading function. Please avoid using `lambda` in the future, and use named Python functions instead. This is the `lambda` being serialized:     training_model.compile(optimizer=optimizer_phase3, loss=lambda y_true, y_pred: y_pred, metrics=[])\n",
      "\n",
      "  return {key: serialize_keras_object(value) for key, value in obj.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 487ms/step - loss: 1.8462\\nEpoch 96: Calculating Validation WER/CER...\n",
      "  Example True: '9   ļ o t i   s ē ņ o'\n",
      "  Example Pred: '9   ļ o t i   s ē ņ o'\n",
      "  Successfully calculated WER: 0.2133 using 64 pairs.\n",
      "  Validation WER (0.2133) did not improve. Best: 0.2133 at epoch 95\n",
      "\n",
      "Epoch 96: val_wer_phase3 did not improve from 0.21333\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 538ms/step - loss: 1.8501 - val_wer_phase3: 0.2133 - learning_rate: 1.0000e-06\n",
      "Epoch 97/194\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 486ms/step - loss: 2.0604\\nEpoch 97: Calculating Validation WER/CER...\n",
      "  Example True: '9   ļ o t i   s ē ņ o'\n",
      "  Example Pred: '9   ļ o t i   s ē ņ o'\n",
      "  Successfully calculated WER: 0.2167 using 64 pairs.\n",
      "  Validation WER (0.2167) did not improve. Best: 0.2133 at epoch 95\n",
      "\n",
      "Epoch 97: val_wer_phase3 did not improve from 0.21333\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 543ms/step - loss: 2.0607 - val_loss: 4.8867 - val_wer_phase3: 0.2167 - learning_rate: 1.0000e-06\n",
      "Epoch 98/194\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453ms/step - loss: 1.9193\\nEpoch 98: Calculating Validation WER/CER...\n",
      "  Example True: '9   ļ o t i   s ē ņ o'\n",
      "  Example Pred: '9   ļ o t i   s ē ņ o'\n",
      "  Successfully calculated WER: 0.2200 using 64 pairs.\n",
      "  Validation WER (0.2200) did not improve. Best: 0.2133 at epoch 95\n",
      "\n",
      "Epoch 98: val_wer_phase3 did not improve from 0.21333\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 498ms/step - loss: 1.9207 - val_wer_phase3: 0.2200 - learning_rate: 1.0000e-06\n",
      "Epoch 99/194\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 468ms/step - loss: 1.6559\\nEpoch 99: Calculating Validation WER/CER...\n",
      "  Example True: '9   ļ o t i   s ē ņ o'\n",
      "  Example Pred: '9   ļ o t i   s ē ņ o'\n",
      "  Successfully calculated WER: 0.2133 using 64 pairs.\n",
      "  Validation WER (0.2133) did not improve. Best: 0.2133 at epoch 95\n",
      "\n",
      "Epoch 99: val_wer_phase3 did not improve from 0.21333\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 531ms/step - loss: 1.6566 - val_loss: 4.9621 - val_wer_phase3: 0.2133 - learning_rate: 1.0000e-06\n",
      "Epoch 100/194\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489ms/step - loss: 1.8767\\nEpoch 100: Calculating Validation WER/CER...\n",
      "  Example True: '9   ļ o t i   s ē ņ o'\n",
      "  Example Pred: '9   ļ o t i   s ē ņ o'\n",
      "  Successfully calculated WER: 0.2167 using 64 pairs.\n",
      "  Validation WER (0.2167) did not improve. Best: 0.2133 at epoch 95\n",
      "\n",
      "Epoch 100: val_wer_phase3 did not improve from 0.21333\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 535ms/step - loss: 1.8768 - val_wer_phase3: 0.2167 - learning_rate: 1.0000e-06\n",
      "Epoch 101/194\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 458ms/step - loss: 1.9923\\nEpoch 101: Calculating Validation WER/CER...\n",
      "  Example True: '9   ļ o t i   s ē ņ o'\n",
      "  Example Pred: '9   ļ o t i   s ē ņ o'\n",
      "  Successfully calculated WER: 0.2133 using 64 pairs.\n",
      "  Validation WER (0.2133) did not improve. Best: 0.2133 at epoch 95\n",
      "\n",
      "Epoch 101: val_wer_phase3 did not improve from 0.21333\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 520ms/step - loss: 1.9902 - val_loss: 4.9147 - val_wer_phase3: 0.2133 - learning_rate: 1.0000e-06\n",
      "Epoch 102/194\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 464ms/step - loss: 1.8971\\nEpoch 102: Calculating Validation WER/CER...\n",
      "  Example True: '9   ļ o t i   s ē ņ o'\n",
      "  Example Pred: '9   ļ o t i   s ē ņ o'\n",
      "  Successfully calculated WER: 0.2100 using 64 pairs.\n",
      "  New best validation WER: 0.2100 (previous: 0.2133 at epoch 95)\n",
      "\n",
      "Epoch 102: val_wer_phase3 improved from 0.21333 to 0.21000, saving model to c:\\Users\\liene\\Documents\\GitHub\\LZV-CSLR\\models\\lzv\\1\\lzv_model_phase3_best_exp1.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 515ms/step - loss: 1.8970 - val_wer_phase3: 0.2100 - learning_rate: 1.0000e-06\n",
      "Epoch 103/194\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457ms/step - loss: 1.9848\\nEpoch 103: Calculating Validation WER/CER...\n",
      "  Example True: '9   ļ o t i   s ē ņ o'\n",
      "  Example Pred: '9   ļ o t i   s ē ņ o'\n",
      "  Successfully calculated WER: 0.2133 using 64 pairs.\n",
      "  Validation WER (0.2133) did not improve. Best: 0.2100 at epoch 102\n",
      "\n",
      "Epoch 103: val_wer_phase3 did not improve from 0.21000\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 525ms/step - loss: 1.9821 - val_loss: 4.8884 - val_wer_phase3: 0.2133 - learning_rate: 1.0000e-06\n",
      "Epoch 104/194\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489ms/step - loss: 1.9173\\nEpoch 104: Calculating Validation WER/CER...\n",
      "  Example True: '9   ļ o t i   s ē ņ o'\n",
      "  Example Pred: '9   ļ o t i   s ē ņ o'\n",
      "  Successfully calculated WER: 0.2067 using 64 pairs.\n",
      "  New best validation WER: 0.2067 (previous: 0.2100 at epoch 102)\n",
      "\n",
      "Epoch 104: val_wer_phase3 improved from 0.21000 to 0.20667, saving model to c:\\Users\\liene\\Documents\\GitHub\\LZV-CSLR\\models\\lzv\\1\\lzv_model_phase3_best_exp1.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 539ms/step - loss: 1.9203 - val_wer_phase3: 0.2067 - learning_rate: 1.0000e-06\n",
      "Epoch 105/194\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457ms/step - loss: 1.8315\\nEpoch 105: Calculating Validation WER/CER...\n",
      "  Example True: '9   ļ o t i   s ē ņ o'\n",
      "  Example Pred: '9   ļ o t i   s ē ņ o'\n",
      "  Successfully calculated WER: 0.2200 using 64 pairs.\n",
      "  Validation WER (0.2200) did not improve. Best: 0.2067 at epoch 104\n",
      "\n",
      "Epoch 105: val_wer_phase3 did not improve from 0.20667\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 520ms/step - loss: 1.8350 - val_loss: 4.9037 - val_wer_phase3: 0.2200 - learning_rate: 1.0000e-06\n",
      "Epoch 106/194\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 448ms/step - loss: 1.8083\\nEpoch 106: Calculating Validation WER/CER...\n",
      "  Example True: '9   ļ o t i   s ē ņ o'\n",
      "  Example Pred: '9   ļ o t i   s ē ņ o'\n",
      "  Successfully calculated WER: 0.2167 using 64 pairs.\n",
      "  Validation WER (0.2167) did not improve. Best: 0.2067 at epoch 104\n",
      "\n",
      "Epoch 106: val_wer_phase3 did not improve from 0.20667\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 493ms/step - loss: 1.8112 - val_wer_phase3: 0.2167 - learning_rate: 1.0000e-06\n",
      "Epoch 107/194\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477ms/step - loss: 2.0678\\nEpoch 107: Calculating Validation WER/CER...\n",
      "  Example True: '9   ļ o t i   s ē ņ o'\n",
      "  Example Pred: '9   ļ o t i   s ē ņ o'\n",
      "  Successfully calculated WER: 0.2133 using 64 pairs.\n",
      "  Validation WER (0.2133) did not improve. Best: 0.2067 at epoch 104\n",
      "\n",
      "Epoch 107: val_wer_phase3 did not improve from 0.20667\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 544ms/step - loss: 2.0626 - val_loss: 4.8804 - val_wer_phase3: 0.2133 - learning_rate: 1.0000e-06\n",
      "Epoch 108/194\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 473ms/step - loss: 2.1130\\nEpoch 108: Calculating Validation WER/CER...\n",
      "  Example True: '9   ļ o t i   s ē ņ o'\n",
      "  Example Pred: '9   ļ o t i   s ē ņ o'\n",
      "  Successfully calculated WER: 0.2133 using 64 pairs.\n",
      "  Validation WER (0.2133) did not improve. Best: 0.2067 at epoch 104\n",
      "\n",
      "Epoch 108: val_wer_phase3 did not improve from 0.20667\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 518ms/step - loss: 2.1179 - val_wer_phase3: 0.2133 - learning_rate: 1.0000e-06\n",
      "Epoch 109/194\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 431ms/step - loss: 2.0025\\nEpoch 109: Calculating Validation WER/CER...\n",
      "  Example True: '9   ļ o t i   s ē ņ o'\n",
      "  Example Pred: '9   ļ o t i   s ē ņ o'\n",
      "  Successfully calculated WER: 0.2133 using 64 pairs.\n",
      "  Validation WER (0.2133) did not improve. Best: 0.2067 at epoch 104\n",
      "\n",
      "Epoch 109: val_wer_phase3 did not improve from 0.20667\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 495ms/step - loss: 2.0009 - val_loss: 4.9042 - val_wer_phase3: 0.2133 - learning_rate: 1.0000e-06\n",
      "Epoch 110/194\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 473ms/step - loss: 1.7743\\nEpoch 110: Calculating Validation WER/CER...\n",
      "  Example True: '9   ļ o t i   s ē ņ o'\n",
      "  Example Pred: '9   ļ o t i   s ē ņ o'\n",
      "  Successfully calculated WER: 0.2233 using 64 pairs.\n",
      "  Validation WER (0.2233) did not improve. Best: 0.2067 at epoch 104\n",
      "\n",
      "Epoch 110: val_wer_phase3 did not improve from 0.20667\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 521ms/step - loss: 1.7734 - val_wer_phase3: 0.2233 - learning_rate: 1.0000e-06\n",
      "Epoch 111/194\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 516ms/step - loss: 1.9405\\nEpoch 111: Calculating Validation WER/CER...\n",
      "  Example True: '9   ļ o t i   s ē ņ o'\n",
      "  Example Pred: '9   ļ o t i   s ē ņ o'\n",
      "  Successfully calculated WER: 0.2167 using 64 pairs.\n",
      "  Validation WER (0.2167) did not improve. Best: 0.2067 at epoch 104\n",
      "\n",
      "Epoch 111: val_wer_phase3 did not improve from 0.20667\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 581ms/step - loss: 1.9419 - val_loss: 4.8765 - val_wer_phase3: 0.2167 - learning_rate: 1.0000e-06\n",
      "Epoch 112/194\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 431ms/step - loss: 1.6666\\nEpoch 112: Calculating Validation WER/CER...\n",
      "  Example True: '9   ļ o t i   s ē ņ o'\n",
      "  Example Pred: '9   ļ o t i   s ē ņ o'\n",
      "  Successfully calculated WER: 0.2133 using 64 pairs.\n",
      "  Validation WER (0.2133) did not improve. Best: 0.2067 at epoch 104\n",
      "\n",
      "Epoch 112: val_wer_phase3 did not improve from 0.20667\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 475ms/step - loss: 1.6675 - val_wer_phase3: 0.2133 - learning_rate: 1.0000e-06\n",
      "Epoch 113/194\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 438ms/step - loss: 2.3405\\nEpoch 113: Calculating Validation WER/CER...\n",
      "  Example True: '9   ļ o t i   s ē ņ o'\n",
      "  Example Pred: '9   ļ o t i   s ē ņ o'\n",
      "  Successfully calculated WER: 0.2100 using 64 pairs.\n",
      "  Validation WER (0.2100) did not improve. Best: 0.2067 at epoch 104\n",
      "\n",
      "Epoch 113: val_wer_phase3 did not improve from 0.20667\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 501ms/step - loss: 2.3359 - val_loss: 4.9265 - val_wer_phase3: 0.2100 - learning_rate: 1.0000e-06\n",
      "Epoch 114/194\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 519ms/step - loss: 2.4749\\nEpoch 114: Calculating Validation WER/CER...\n",
      "  Example True: '9   ļ o t i   s ē ņ o'\n",
      "  Example Pred: '9   ļ o t i   s ē ņ o'\n",
      "  Successfully calculated WER: 0.2100 using 64 pairs.\n",
      "  Validation WER (0.2100) did not improve. Best: 0.2067 at epoch 104\n",
      "\n",
      "Epoch 114: val_wer_phase3 did not improve from 0.20667\n",
      "\n",
      "Epoch 114: ReduceLROnPlateau reducing learning rate to 2.999999992425728e-07.\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 566ms/step - loss: 2.4706 - val_wer_phase3: 0.2100 - learning_rate: 1.0000e-06\n",
      "Epoch 115/194\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 480ms/step - loss: 1.9427\\nEpoch 115: Calculating Validation WER/CER...\n",
      "  Example True: '9   ļ o t i   s ē ņ o'\n",
      "  Example Pred: '9   ļ o t i   s ē ņ o'\n",
      "  Successfully calculated WER: 0.2133 using 64 pairs.\n",
      "  Validation WER (0.2133) did not improve. Best: 0.2067 at epoch 104\n",
      "\n",
      "Epoch 115: val_wer_phase3 did not improve from 0.20667\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 536ms/step - loss: 1.9452 - val_loss: 4.9146 - val_wer_phase3: 0.2133 - learning_rate: 3.0000e-07\n",
      "Epoch 116/194\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 461ms/step - loss: 1.9182\\nEpoch 116: Calculating Validation WER/CER...\n",
      "  Example True: '9   ļ o t i   s ē ņ o'\n",
      "  Example Pred: '9   ļ o t i   s ē ņ o'\n",
      "  Successfully calculated WER: 0.2133 using 64 pairs.\n",
      "  Validation WER (0.2133) did not improve. Best: 0.2067 at epoch 104\n",
      "\n",
      "Epoch 116: val_wer_phase3 did not improve from 0.20667\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 506ms/step - loss: 1.9183 - val_wer_phase3: 0.2133 - learning_rate: 3.0000e-07\n",
      "Epoch 117/194\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 435ms/step - loss: 1.6043\\nEpoch 117: Calculating Validation WER/CER...\n",
      "  Example True: '9   ļ o t i   s ē ņ o'\n",
      "  Example Pred: '9   ļ o t i   s ē ņ o'\n",
      "  Successfully calculated WER: 0.2133 using 64 pairs.\n",
      "  Validation WER (0.2133) did not improve. Best: 0.2067 at epoch 104\n",
      "\n",
      "Epoch 117: val_wer_phase3 did not improve from 0.20667\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 499ms/step - loss: 1.6056 - val_loss: 4.9093 - val_wer_phase3: 0.2133 - learning_rate: 3.0000e-07\n",
      "Epoch 118/194\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 493ms/step - loss: 2.0845\\nEpoch 118: Calculating Validation WER/CER...\n",
      "  Example True: '9   ļ o t i   s ē ņ o'\n",
      "  Example Pred: '9   ļ o t i   s ē ņ o'\n",
      "  Successfully calculated WER: 0.2133 using 64 pairs.\n",
      "  Validation WER (0.2133) did not improve. Best: 0.2067 at epoch 104\n",
      "\n",
      "Epoch 118: val_wer_phase3 did not improve from 0.20667\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 540ms/step - loss: 2.0843 - val_wer_phase3: 0.2133 - learning_rate: 3.0000e-07\n",
      "Epoch 119/194\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455ms/step - loss: 1.7306\\nEpoch 119: Calculating Validation WER/CER...\n",
      "  Example True: '9   ļ o t i   s ē ņ o'\n",
      "  Example Pred: '9   ļ o t i   s ē ņ o'\n",
      "  Successfully calculated WER: 0.2133 using 64 pairs.\n",
      "  Validation WER (0.2133) did not improve. Best: 0.2067 at epoch 104\n",
      "\n",
      "Epoch 119: val_wer_phase3 did not improve from 0.20667\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 517ms/step - loss: 1.7347 - val_loss: 4.8756 - val_wer_phase3: 0.2133 - learning_rate: 3.0000e-07\n",
      "Epoch 120/194\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 417ms/step - loss: 2.3401\\nEpoch 120: Calculating Validation WER/CER...\n",
      "  Example True: '9   ļ o t i   s ē ņ o'\n",
      "  Example Pred: '9   ļ o t i   s ē ņ o'\n",
      "  Successfully calculated WER: 0.2167 using 64 pairs.\n",
      "  Validation WER (0.2167) did not improve. Best: 0.2067 at epoch 104\n",
      "\n",
      "Epoch 120: val_wer_phase3 did not improve from 0.20667\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 463ms/step - loss: 2.3347 - val_wer_phase3: 0.2167 - learning_rate: 3.0000e-07\n",
      "Epoch 121/194\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 513ms/step - loss: 1.5628\\nEpoch 121: Calculating Validation WER/CER...\n",
      "  Example True: '9   ļ o t i   s ē ņ o'\n",
      "  Example Pred: '9   ļ o t i   s ē ņ o'\n",
      "  Successfully calculated WER: 0.2133 using 64 pairs.\n",
      "  Validation WER (0.2133) did not improve. Best: 0.2067 at epoch 104\n",
      "\n",
      "Epoch 121: val_wer_phase3 did not improve from 0.20667\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 580ms/step - loss: 1.5693 - val_loss: 4.8846 - val_wer_phase3: 0.2133 - learning_rate: 3.0000e-07\n",
      "Epoch 122/194\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 484ms/step - loss: 1.9966\\nEpoch 122: Calculating Validation WER/CER...\n",
      "  Example True: '9   ļ o t i   s ē ņ o'\n",
      "  Example Pred: '9   ļ o t i   s ē ņ o'\n",
      "  Successfully calculated WER: 0.2167 using 64 pairs.\n",
      "  Validation WER (0.2167) did not improve. Best: 0.2067 at epoch 104\n",
      "\n",
      "Epoch 122: val_wer_phase3 did not improve from 0.20667\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 536ms/step - loss: 1.9961 - val_wer_phase3: 0.2167 - learning_rate: 3.0000e-07\n",
      "Epoch 123/194\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 439ms/step - loss: 1.9486\\nEpoch 123: Calculating Validation WER/CER...\n",
      "  Example True: '9   ļ o t i   s ē ņ o'\n",
      "  Example Pred: '9   ļ o t i   s ē ņ o'\n",
      "  Successfully calculated WER: 0.2100 using 64 pairs.\n",
      "  Validation WER (0.2100) did not improve. Best: 0.2067 at epoch 104\n",
      "\n",
      "Epoch 123: val_wer_phase3 did not improve from 0.20667\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 504ms/step - loss: 1.9489 - val_loss: 4.9077 - val_wer_phase3: 0.2100 - learning_rate: 3.0000e-07\n",
      "Epoch 124/194\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454ms/step - loss: 1.9423\\nEpoch 124: Calculating Validation WER/CER...\n",
      "  Example True: '9   ļ o t i   s ē ņ o'\n",
      "  Example Pred: '9   ļ o t i   s ē ņ o'\n",
      "  Successfully calculated WER: 0.2167 using 64 pairs.\n",
      "  Validation WER (0.2167) did not improve. Best: 0.2067 at epoch 104\n",
      "\n",
      "Epoch 124: val_wer_phase3 did not improve from 0.20667\n",
      "\n",
      "Epoch 124: ReduceLROnPlateau reducing learning rate to 9.000000318337698e-08.\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 502ms/step - loss: 1.9433 - val_wer_phase3: 0.2167 - learning_rate: 3.0000e-07\n",
      "Epoch 124: early stopping\n",
      "Restoring model weights from the end of the best epoch: 104.\n",
      "Loading best weights from Phase 3 checkpoint: c:\\Users\\liene\\Documents\\GitHub\\LZV-CSLR\\models\\lzv\\1\\lzv_model_phase3_best_exp1.keras\n",
      "\n",
      "--- Post-Phased Fine-tuning: Saving LZV Results ---\n",
      "Final LZV prediction model saved to: c:\\Users\\liene\\Documents\\GitHub\\LZV-CSLR\\models\\lzv\\1\\lzv_prediction_model_final_exp1.keras\n",
      "Overall best val_wer: 0.2067 at cumulative epoch 70\n",
      "\n",
      "Generating and saving LZV plot to: c:\\Users\\liene\\Documents\\GitHub\\LZV-CSLR\\models\\lzv\\1\\lzv_plot_exp1.png\n",
      "LZV Plot saved successfully to c:\\Users\\liene\\Documents\\GitHub\\LZV-CSLR\\models\\lzv\\1\\lzv_plot_exp1.png.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x700 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving LZV experiment data to: c:\\Users\\liene\\Documents\\GitHub\\LZV-CSLR\\models\\lzv\\1\\lzv_exp_data_1.json\n",
      "\n",
      "Generating LZV prediction examples for JSON (Phase 1)...\n",
      "Generated 64 LZV prediction examples for Phase 1.\n",
      "  Content of target_list_in_run_data for Phase 1 after generation: [{'ground_truth': '9   ļ o t i   s ē ņ o', 'prediction': '9   ļ o t i   s ē ņ o'}, {'ground_truth': 'č u k   č u k', 'prediction': 'č u k   č u'}, {'ground_truth': '10   t a g a d', 'prediction': '10   t a g a d'}, {'ground_truth': 'v a i   t ā p ā t', 'prediction': 'v a i   t ā p ā a t  '}, {'ground_truth': '1', 'prediction': '<empty_pred>'}, {'ground_truth': 'c', 'prediction': 'c'}, {'ground_truth': 'l a b i   g a n   t ā', 'prediction': 'l a b i g a n t'}, {'ground_truth': 'm', 'prediction': 'm'}, {'ground_truth': '9', 'prediction': '9'}, {'ground_truth': 'd i v i', 'prediction': 'd i v i'}, {'ground_truth': 's p ē l ē   ģ i t ā r u', 'prediction': 's p ē l ē   ģ i t ā r u'}, {'ground_truth': '9 8 7', 'prediction': '8'}, {'ground_truth': 'k ā   t e v i   s a u c', 'prediction': 'k a   r t e h v i s a u c'}, {'ground_truth': 'l a b i', 'prediction': 'l a b i'}, {'ground_truth': 'o', 'prediction': '0'}, {'ground_truth': 'a ā b c č d e ē f g ģ', 'prediction': 'a d'}, {'ground_truth': 'm', 'prediction': 'n'}, {'ground_truth': 'g a r d i', 'prediction': 'g a r a i'}, {'ground_truth': 'ū d e n s', 'prediction': 'ū d n s'}, {'ground_truth': 's p i e ž', 'prediction': 's p i ž'}, {'ground_truth': 'n', 'prediction': 'ņ'}, {'ground_truth': 'l i e n e', 'prediction': 'l i n e'}, {'ground_truth': 'm o h i t o', 'prediction': 'm o h i t o'}, {'ground_truth': 'd', 'prediction': 'd'}, {'ground_truth': '5', 'prediction': '5'}, {'ground_truth': 'e', 'prediction': 'e'}, {'ground_truth': 'ļ o d z ī t', 'prediction': 'ļ o d z ī t'}, {'ground_truth': '3', 'prediction': '2'}, {'ground_truth': 'd i e n a', 'prediction': 'n i n a'}, {'ground_truth': 'l u ņ ķ i s', 'prediction': 'l u ņ ķ i s'}, {'ground_truth': 'f 7 f 7 f 7', 'prediction': 'f 8 f 8'}, {'ground_truth': '0 4 0 4', 'prediction': '0 0 4'}, {'ground_truth': 'k ā d ē ļ   s l i k t i', 'prediction': 'k ā d ē l   s l i k t i'}, {'ground_truth': 't a v ā   ē d i e n ā', 'prediction': 't a v ā     ē d i e n ā'}, {'ground_truth': 'ļ o t i   m ī ļ i', 'prediction': 'ļ o t i   m ī l i'}, {'ground_truth': 'a', 'prediction': 'a'}, {'ground_truth': 'l a b i   g a n   k a   t ā', 'prediction': 'l a b i g a n k a   t ā'}, {'ground_truth': 'm a n s', 'prediction': 'm a n s'}, {'ground_truth': 'h', 'prediction': 'h'}, {'ground_truth': 'k ā d ē ļ   s l i k t i', 'prediction': 'k ā d ē l   s l i k t i'}, {'ground_truth': '1', 'prediction': '1 1'}, {'ground_truth': 'i z b r ī n a', 'prediction': 'i z b r i n a  '}, {'ground_truth': 'ģ h i ī j k ķ l ļ', 'prediction': 'h i j k ķ ļ'}, {'ground_truth': 'ē', 'prediction': 'e'}, {'ground_truth': '5 6 5 6', 'prediction': '5 5'}, {'ground_truth': '0 1 0 1 2 3 4 5 0', 'prediction': '0 1 0 1 2 3 4 0'}, {'ground_truth': 'i', 'prediction': 'j'}, {'ground_truth': 'ē', 'prediction': 'e'}, {'ground_truth': 'p', 'prediction': '<empty_pred>'}, {'ground_truth': 'a n a', 'prediction': 'a n a'}, {'ground_truth': '7 8 7 6 7 8', 'prediction': '8 6   8'}, {'ground_truth': 's', 'prediction': '<empty_pred>'}, {'ground_truth': 'k ā d ā s   v i e t ā s', 'prediction': 'k ā d ā s   v i e t ā s'}, {'ground_truth': '5 4 3 2 1', 'prediction': '4 1'}, {'ground_truth': '10', 'prediction': '10'}, {'ground_truth': 'l u ņ ķ i s', 'prediction': 'l u ņ ķ i s'}, {'ground_truth': 'c', 'prediction': 'c'}, {'ground_truth': '8', 'prediction': '8'}, {'ground_truth': '10   t a g a d', 'prediction': '10 t a g a'}, {'ground_truth': 'o p r s š t u ū v z ž', 'prediction': 'o p r s š t ū'}, {'ground_truth': 'o', 'prediction': '<empty_pred>'}, {'ground_truth': 'd a u d z', 'prediction': 'd a u z'}, {'ground_truth': 'b r ī n a', 'prediction': 'b r ī n a'}, {'ground_truth': 'f', 'prediction': 'f'}]\n",
      "\n",
      "Generating LZV prediction examples for JSON (Phase 2)...\n",
      "Generated 64 LZV prediction examples for Phase 2.\n",
      "  Content of target_list_in_run_data for Phase 2 after generation: [{'ground_truth': '9   ļ o t i   s ē ņ o', 'prediction': '9   ļ o t i   s ē ņ o'}, {'ground_truth': 'č u k   č u k', 'prediction': 'č u k   č u'}, {'ground_truth': '10   t a g a d', 'prediction': '10   t a g a d'}, {'ground_truth': 'v a i   t ā p ā t', 'prediction': 'v a i   t ā p ā a t  '}, {'ground_truth': '1', 'prediction': '<empty_pred>'}, {'ground_truth': 'c', 'prediction': 'c'}, {'ground_truth': 'l a b i   g a n   t ā', 'prediction': 'l a b i g a n t'}, {'ground_truth': 'm', 'prediction': 'm'}, {'ground_truth': '9', 'prediction': '9'}, {'ground_truth': 'd i v i', 'prediction': 'd i v i'}, {'ground_truth': 's p ē l ē   ģ i t ā r u', 'prediction': 's p ē l ē   ģ i t ā r u'}, {'ground_truth': '9 8 7', 'prediction': '8'}, {'ground_truth': 'k ā   t e v i   s a u c', 'prediction': 'k a   r t e h v i s a u c'}, {'ground_truth': 'l a b i', 'prediction': 'l a b i'}, {'ground_truth': 'o', 'prediction': '0'}, {'ground_truth': 'a ā b c č d e ē f g ģ', 'prediction': 'a d'}, {'ground_truth': 'm', 'prediction': 'n'}, {'ground_truth': 'g a r d i', 'prediction': 'g a r a i'}, {'ground_truth': 'ū d e n s', 'prediction': 'ū d n s'}, {'ground_truth': 's p i e ž', 'prediction': 's p i ž'}, {'ground_truth': 'n', 'prediction': 'ņ'}, {'ground_truth': 'l i e n e', 'prediction': 'l i n e'}, {'ground_truth': 'm o h i t o', 'prediction': 'm o h i t o'}, {'ground_truth': 'd', 'prediction': 'd'}, {'ground_truth': '5', 'prediction': '5'}, {'ground_truth': 'e', 'prediction': 'e'}, {'ground_truth': 'ļ o d z ī t', 'prediction': 'ļ o d z ī t'}, {'ground_truth': '3', 'prediction': '2'}, {'ground_truth': 'd i e n a', 'prediction': 'n i n a'}, {'ground_truth': 'l u ņ ķ i s', 'prediction': 'l u ņ ķ i s'}, {'ground_truth': 'f 7 f 7 f 7', 'prediction': 'f 8 f 8'}, {'ground_truth': '0 4 0 4', 'prediction': '0 0 4'}, {'ground_truth': 'k ā d ē ļ   s l i k t i', 'prediction': 'k ā d ē l   s l i k t i'}, {'ground_truth': 't a v ā   ē d i e n ā', 'prediction': 't a v ā     ē d i e n ā'}, {'ground_truth': 'ļ o t i   m ī ļ i', 'prediction': 'ļ o t i   m ī l i'}, {'ground_truth': 'a', 'prediction': 'a'}, {'ground_truth': 'l a b i   g a n   k a   t ā', 'prediction': 'l a b i g a n k a   t ā'}, {'ground_truth': 'm a n s', 'prediction': 'm a n s'}, {'ground_truth': 'h', 'prediction': 'h'}, {'ground_truth': 'k ā d ē ļ   s l i k t i', 'prediction': 'k ā d ē l   s l i k t i'}, {'ground_truth': '1', 'prediction': '1 1'}, {'ground_truth': 'i z b r ī n a', 'prediction': 'i z b r i n a  '}, {'ground_truth': 'ģ h i ī j k ķ l ļ', 'prediction': 'h i j k ķ ļ'}, {'ground_truth': 'ē', 'prediction': 'e'}, {'ground_truth': '5 6 5 6', 'prediction': '5 5'}, {'ground_truth': '0 1 0 1 2 3 4 5 0', 'prediction': '0 1 0 1 2 3 4 0'}, {'ground_truth': 'i', 'prediction': 'j'}, {'ground_truth': 'ē', 'prediction': 'e'}, {'ground_truth': 'p', 'prediction': '<empty_pred>'}, {'ground_truth': 'a n a', 'prediction': 'a n a'}, {'ground_truth': '7 8 7 6 7 8', 'prediction': '8 6   8'}, {'ground_truth': 's', 'prediction': '<empty_pred>'}, {'ground_truth': 'k ā d ā s   v i e t ā s', 'prediction': 'k ā d ā s   v i e t ā s'}, {'ground_truth': '5 4 3 2 1', 'prediction': '4 1'}, {'ground_truth': '10', 'prediction': '10'}, {'ground_truth': 'l u ņ ķ i s', 'prediction': 'l u ņ ķ i s'}, {'ground_truth': 'c', 'prediction': 'c'}, {'ground_truth': '8', 'prediction': '8'}, {'ground_truth': '10   t a g a d', 'prediction': '10 t a g a'}, {'ground_truth': 'o p r s š t u ū v z ž', 'prediction': 'o p r s š t ū'}, {'ground_truth': 'o', 'prediction': '<empty_pred>'}, {'ground_truth': 'd a u d z', 'prediction': 'd a u z'}, {'ground_truth': 'b r ī n a', 'prediction': 'b r ī n a'}, {'ground_truth': 'f', 'prediction': 'f'}]\n",
      "\n",
      "Generating LZV prediction examples for JSON (Phase 3)...\n",
      "Generated 64 LZV prediction examples for Phase 3.\n",
      "  Content of target_list_in_run_data for Phase 3 after generation: [{'ground_truth': '9   ļ o t i   s ē ņ o', 'prediction': '9   ļ o t i   s ē ņ o'}, {'ground_truth': 'č u k   č u k', 'prediction': 'č u k   č u'}, {'ground_truth': '10   t a g a d', 'prediction': '10   t a g a d'}, {'ground_truth': 'v a i   t ā p ā t', 'prediction': 'v a i   t ā p ā a t  '}, {'ground_truth': '1', 'prediction': '<empty_pred>'}, {'ground_truth': 'c', 'prediction': 'c'}, {'ground_truth': 'l a b i   g a n   t ā', 'prediction': 'l a b i g a n t'}, {'ground_truth': 'm', 'prediction': 'm'}, {'ground_truth': '9', 'prediction': '9'}, {'ground_truth': 'd i v i', 'prediction': 'd i v i'}, {'ground_truth': 's p ē l ē   ģ i t ā r u', 'prediction': 's p ē l ē   ģ i t ā r u'}, {'ground_truth': '9 8 7', 'prediction': '8'}, {'ground_truth': 'k ā   t e v i   s a u c', 'prediction': 'k a   r t e h v i s a u c'}, {'ground_truth': 'l a b i', 'prediction': 'l a b i'}, {'ground_truth': 'o', 'prediction': '0'}, {'ground_truth': 'a ā b c č d e ē f g ģ', 'prediction': 'a d'}, {'ground_truth': 'm', 'prediction': 'n'}, {'ground_truth': 'g a r d i', 'prediction': 'g a r a i'}, {'ground_truth': 'ū d e n s', 'prediction': 'ū d n s'}, {'ground_truth': 's p i e ž', 'prediction': 's p i ž'}, {'ground_truth': 'n', 'prediction': 'ņ'}, {'ground_truth': 'l i e n e', 'prediction': 'l i n e'}, {'ground_truth': 'm o h i t o', 'prediction': 'm o h i t o'}, {'ground_truth': 'd', 'prediction': 'd'}, {'ground_truth': '5', 'prediction': '5'}, {'ground_truth': 'e', 'prediction': 'e'}, {'ground_truth': 'ļ o d z ī t', 'prediction': 'ļ o d z ī t'}, {'ground_truth': '3', 'prediction': '2'}, {'ground_truth': 'd i e n a', 'prediction': 'n i n a'}, {'ground_truth': 'l u ņ ķ i s', 'prediction': 'l u ņ ķ i s'}, {'ground_truth': 'f 7 f 7 f 7', 'prediction': 'f 8 f 8'}, {'ground_truth': '0 4 0 4', 'prediction': '0 0 4'}, {'ground_truth': 'k ā d ē ļ   s l i k t i', 'prediction': 'k ā d ē l   s l i k t i'}, {'ground_truth': 't a v ā   ē d i e n ā', 'prediction': 't a v ā     ē d i e n ā'}, {'ground_truth': 'ļ o t i   m ī ļ i', 'prediction': 'ļ o t i   m ī l i'}, {'ground_truth': 'a', 'prediction': 'a'}, {'ground_truth': 'l a b i   g a n   k a   t ā', 'prediction': 'l a b i g a n k a   t ā'}, {'ground_truth': 'm a n s', 'prediction': 'm a n s'}, {'ground_truth': 'h', 'prediction': 'h'}, {'ground_truth': 'k ā d ē ļ   s l i k t i', 'prediction': 'k ā d ē l   s l i k t i'}, {'ground_truth': '1', 'prediction': '1 1'}, {'ground_truth': 'i z b r ī n a', 'prediction': 'i z b r i n a  '}, {'ground_truth': 'ģ h i ī j k ķ l ļ', 'prediction': 'h i j k ķ ļ'}, {'ground_truth': 'ē', 'prediction': 'e'}, {'ground_truth': '5 6 5 6', 'prediction': '5 5'}, {'ground_truth': '0 1 0 1 2 3 4 5 0', 'prediction': '0 1 0 1 2 3 4 0'}, {'ground_truth': 'i', 'prediction': 'j'}, {'ground_truth': 'ē', 'prediction': 'e'}, {'ground_truth': 'p', 'prediction': '<empty_pred>'}, {'ground_truth': 'a n a', 'prediction': 'a n a'}, {'ground_truth': '7 8 7 6 7 8', 'prediction': '8 6   8'}, {'ground_truth': 's', 'prediction': '<empty_pred>'}, {'ground_truth': 'k ā d ā s   v i e t ā s', 'prediction': 'k ā d ā s   v i e t ā s'}, {'ground_truth': '5 4 3 2 1', 'prediction': '4 1'}, {'ground_truth': '10', 'prediction': '10'}, {'ground_truth': 'l u ņ ķ i s', 'prediction': 'l u ņ ķ i s'}, {'ground_truth': 'c', 'prediction': 'c'}, {'ground_truth': '8', 'prediction': '8'}, {'ground_truth': '10   t a g a d', 'prediction': '10 t a g a'}, {'ground_truth': 'o p r s š t u ū v z ž', 'prediction': 'o p r s š t ū'}, {'ground_truth': 'o', 'prediction': '<empty_pred>'}, {'ground_truth': 'd a u d z', 'prediction': 'd a u z'}, {'ground_truth': 'b r ī n a', 'prediction': 'b r ī n a'}, {'ground_truth': 'f', 'prediction': 'f'}]\n",
      "\n",
      "--- Content of run_data before saving to JSON ---\n",
      "{\n",
      "    \"experiment_type\": \"Fine-tuning LZV\",\n",
      "    \"base_asl_model_path\": \"c:\\\\Users\\\\liene\\\\Documents\\\\GitHub\\\\LZV-CSLR\\\\models\\\\asl\\\\42\\\\cslr_model_best_42.keras\",\n",
      "    \"experiment_index\": 1,\n",
      "    \"timestamp_completed_utc\": \"2025-05-30T15:31:16+00:00\",\n",
      "    \"dataset_info\": {\n",
      "        \"name\": \"LZV\",\n",
      "        \"training_samples_final_filtered\": 254,\n",
      "        \"validation_samples_final_filtered\": 64,\n",
      "        \"total_classes_lzv_excl_blank\": 45,\n",
      "        \"total_classes_lzv_incl_blank\": 46,\n",
      "        \"char_map_file\": \"data\\\\processed_landmarks\\\\char_map.json\",\n",
      "        \"train_tfrecord\": \"training.tfrecord\",\n",
      "        \"val_tfrecord\": \"validation.tfrecord\"\n",
      "    },\n",
      "    \"landmark_info\": {\n",
      "        \"source\": \"MediaPipe Holistic\",\n",
      "        \"original_total_landmarks\": 543,\n",
      "        \"used_landmarks_count\": 42,\n",
      "        \"dimensions\": 3\n",
      "    },\n",
      "    \"preprocessing\": {\n",
      "        \"normalization_source\": \"calculated_on_the_spot\",\n",
      "        \"ctc_length_filter_applied\": true\n",
      "    },\n",
      "    \"augmentation_details\": {\n",
      "        \"enabled\": true,\n",
      "        \"spatial_affine\": true,\n",
      "        \"horizontal_flip\": false,\n",
      "        \"temporal_resample\": true,\n",
      "        \"temporal_mask\": true\n",
      "    },\n",
      "    \"model_architecture_fine_tuned\": {\n",
      "        \"config\": {\n",
      "            \"name\": \"cslr_lzv_fine_tune_training_model\",\n",
      "            \"trainable\": true,\n",
      "            \"layers\": [\n",
      "                {\n",
      "                    \"module\": \"keras.layers\",\n",
      "                    \"class_name\": \"InputLayer\",\n",
      "                    \"config\": {\n",
      "                        \"batch_shape\": [\n",
      "                            null,\n",
      "                            null,\n",
      "                            42,\n",
      "                            3\n",
      "                        ],\n",
      "                        \"dtype\": \"float32\",\n",
      "                        \"sparse\": false,\n",
      "                        \"name\": \"input_landmarks\"\n",
      "                    },\n",
      "                    \"registered_name\": null,\n",
      "                    \"name\": \"input_landmarks\",\n",
      "                    \"inbound_nodes\": []\n",
      "                },\n",
      "                {\n",
      "                    \"module\": \"keras.layers\",\n",
      "                    \"class_name\": \"Reshape\",\n",
      "                    \"config\": {\n",
      "                        \"name\": \"reshape_input\",\n",
      "                        \"trainable\": false,\n",
      "                        \"dtype\": {\n",
      "                            \"module\": \"keras\",\n",
      "                            \"class_name\": \"DTypePolicy\",\n",
      "                            \"config\": {\n",
      "                                \"name\": \"float32\"\n",
      "                            },\n",
      "                            \"registered_name\": null\n",
      "                        },\n",
      "                        \"target_shape\": [\n",
      "                            -1,\n",
      "                            126\n",
      "                        ]\n",
      "                    },\n",
      "                    \"registered_name\": null,\n",
      "                    \"build_config\": {\n",
      "                        \"input_shape\": [\n",
      "                            null,\n",
      "                            null,\n",
      "                            42,\n",
      "                            3\n",
      "                        ]\n",
      "                    },\n",
      "                    \"name\": \"reshape_input\",\n",
      "                    \"inbound_nodes\": [\n",
      "                        {\n",
      "                            \"args\": [\n",
      "                                {\n",
      "                                    \"class_name\": \"__keras_tensor__\",\n",
      "                                    \"config\": {\n",
      "                                        \"shape\": [\n",
      "                                            null,\n",
      "                                            null,\n",
      "                                            42,\n",
      "                                            3\n",
      "                                        ],\n",
      "                                        \"dtype\": \"float32\",\n",
      "                                        \"keras_history\": [\n",
      "                                            \"input_landmarks\",\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ]\n",
      "                                    }\n",
      "                                }\n",
      "                            ],\n",
      "                            \"kwargs\": {}\n",
      "                        }\n",
      "                    ]\n",
      "                },\n",
      "                {\n",
      "                    \"module\": \"keras.layers\",\n",
      "                    \"class_name\": \"Conv1D\",\n",
      "                    \"config\": {\n",
      "                        \"name\": \"conv1d_layer\",\n",
      "                        \"trainable\": true,\n",
      "                        \"dtype\": {\n",
      "                            \"module\": \"keras\",\n",
      "                            \"class_name\": \"DTypePolicy\",\n",
      "                            \"config\": {\n",
      "                                \"name\": \"float32\"\n",
      "                            },\n",
      "                            \"registered_name\": null\n",
      "                        },\n",
      "                        \"filters\": 128,\n",
      "                        \"kernel_size\": [\n",
      "                            5\n",
      "                        ],\n",
      "                        \"strides\": [\n",
      "                            1\n",
      "                        ],\n",
      "                        \"padding\": \"same\",\n",
      "                        \"data_format\": \"channels_last\",\n",
      "                        \"dilation_rate\": [\n",
      "                            1\n",
      "                        ],\n",
      "                        \"groups\": 1,\n",
      "                        \"activation\": \"relu\",\n",
      "                        \"use_bias\": true,\n",
      "                        \"kernel_initializer\": {\n",
      "                            \"module\": \"keras.initializers\",\n",
      "                            \"class_name\": \"GlorotUniform\",\n",
      "                            \"config\": {\n",
      "                                \"seed\": null\n",
      "                            },\n",
      "                            \"registered_name\": null\n",
      "                        },\n",
      "                        \"bias_initializer\": {\n",
      "                            \"module\": \"keras.initializers\",\n",
      "                            \"class_name\": \"Zeros\",\n",
      "                            \"config\": {},\n",
      "                            \"registered_name\": null\n",
      "                        },\n",
      "                        \"kernel_regularizer\": null,\n",
      "                        \"bias_regularizer\": null,\n",
      "                        \"activity_regularizer\": null,\n",
      "                        \"kernel_constraint\": null,\n",
      "                        \"bias_constraint\": null\n",
      "                    },\n",
      "                    \"registered_name\": null,\n",
      "                    \"build_config\": {\n",
      "                        \"input_shape\": [\n",
      "                            null,\n",
      "                            null,\n",
      "                            126\n",
      "                        ]\n",
      "                    },\n",
      "                    \"name\": \"conv1d_layer\",\n",
      "                    \"inbound_nodes\": [\n",
      "                        {\n",
      "                            \"args\": [\n",
      "                                {\n",
      "                                    \"class_name\": \"__keras_tensor__\",\n",
      "                                    \"config\": {\n",
      "                                        \"shape\": [\n",
      "                                            null,\n",
      "                                            null,\n",
      "                                            126\n",
      "                                        ],\n",
      "                                        \"dtype\": \"float32\",\n",
      "                                        \"keras_history\": [\n",
      "                                            \"reshape_input\",\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ]\n",
      "                                    }\n",
      "                                }\n",
      "                            ],\n",
      "                            \"kwargs\": {}\n",
      "                        }\n",
      "                    ]\n",
      "                },\n",
      "                {\n",
      "                    \"module\": \"keras.layers\",\n",
      "                    \"class_name\": \"BatchNormalization\",\n",
      "                    \"config\": {\n",
      "                        \"name\": \"batchnorm_conv\",\n",
      "                        \"trainable\": true,\n",
      "                        \"dtype\": {\n",
      "                            \"module\": \"keras\",\n",
      "                            \"class_name\": \"DTypePolicy\",\n",
      "                            \"config\": {\n",
      "                                \"name\": \"float32\"\n",
      "                            },\n",
      "                            \"registered_name\": null\n",
      "                        },\n",
      "                        \"axis\": -1,\n",
      "                        \"momentum\": 0.99,\n",
      "                        \"epsilon\": 0.001,\n",
      "                        \"center\": true,\n",
      "                        \"scale\": true,\n",
      "                        \"beta_initializer\": {\n",
      "                            \"module\": \"keras.initializers\",\n",
      "                            \"class_name\": \"Zeros\",\n",
      "                            \"config\": {},\n",
      "                            \"registered_name\": null\n",
      "                        },\n",
      "                        \"gamma_initializer\": {\n",
      "                            \"module\": \"keras.initializers\",\n",
      "                            \"class_name\": \"Ones\",\n",
      "                            \"config\": {},\n",
      "                            \"registered_name\": null\n",
      "                        },\n",
      "                        \"moving_mean_initializer\": {\n",
      "                            \"module\": \"keras.initializers\",\n",
      "                            \"class_name\": \"Zeros\",\n",
      "                            \"config\": {},\n",
      "                            \"registered_name\": null\n",
      "                        },\n",
      "                        \"moving_variance_initializer\": {\n",
      "                            \"module\": \"keras.initializers\",\n",
      "                            \"class_name\": \"Ones\",\n",
      "                            \"config\": {},\n",
      "                            \"registered_name\": null\n",
      "                        },\n",
      "                        \"beta_regularizer\": null,\n",
      "                        \"gamma_regularizer\": null,\n",
      "                        \"beta_constraint\": null,\n",
      "                        \"gamma_constraint\": null,\n",
      "                        \"synchronized\": false\n",
      "                    },\n",
      "                    \"registered_name\": null,\n",
      "                    \"build_config\": {\n",
      "                        \"input_shape\": [\n",
      "                            null,\n",
      "                            null,\n",
      "                            128\n",
      "                        ]\n",
      "                    },\n",
      "                    \"name\": \"batchnorm_conv\",\n",
      "                    \"inbound_nodes\": [\n",
      "                        {\n",
      "                            \"args\": [\n",
      "                                {\n",
      "                                    \"class_name\": \"__keras_tensor__\",\n",
      "                                    \"config\": {\n",
      "                                        \"shape\": [\n",
      "                                            null,\n",
      "                                            null,\n",
      "                                            128\n",
      "                                        ],\n",
      "                                        \"dtype\": \"float32\",\n",
      "                                        \"keras_history\": [\n",
      "                                            \"conv1d_layer\",\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ]\n",
      "                                    }\n",
      "                                }\n",
      "                            ],\n",
      "                            \"kwargs\": {\n",
      "                                \"mask\": null\n",
      "                            }\n",
      "                        }\n",
      "                    ]\n",
      "                },\n",
      "                {\n",
      "                    \"module\": \"keras.layers\",\n",
      "                    \"class_name\": \"Bidirectional\",\n",
      "                    \"config\": {\n",
      "                        \"name\": \"bilstm_1\",\n",
      "                        \"trainable\": true,\n",
      "                        \"dtype\": {\n",
      "                            \"module\": \"keras\",\n",
      "                            \"class_name\": \"DTypePolicy\",\n",
      "                            \"config\": {\n",
      "                                \"name\": \"float32\"\n",
      "                            },\n",
      "                            \"registered_name\": null\n",
      "                        },\n",
      "                        \"merge_mode\": \"concat\",\n",
      "                        \"layer\": {\n",
      "                            \"module\": \"keras.layers\",\n",
      "                            \"class_name\": \"LSTM\",\n",
      "                            \"config\": {\n",
      "                                \"name\": \"forward_lstm\",\n",
      "                                \"trainable\": true,\n",
      "                                \"dtype\": {\n",
      "                                    \"module\": \"keras\",\n",
      "                                    \"class_name\": \"DTypePolicy\",\n",
      "                                    \"config\": {\n",
      "                                        \"name\": \"float32\"\n",
      "                                    },\n",
      "                                    \"registered_name\": null\n",
      "                                },\n",
      "                                \"return_sequences\": true,\n",
      "                                \"return_state\": false,\n",
      "                                \"go_backwards\": false,\n",
      "                                \"stateful\": false,\n",
      "                                \"unroll\": false,\n",
      "                                \"zero_output_for_mask\": true,\n",
      "                                \"units\": 64,\n",
      "                                \"activation\": \"tanh\",\n",
      "                                \"recurrent_activation\": \"sigmoid\",\n",
      "                                \"use_bias\": true,\n",
      "                                \"kernel_initializer\": {\n",
      "                                    \"module\": \"keras.initializers\",\n",
      "                                    \"class_name\": \"GlorotUniform\",\n",
      "                                    \"config\": {\n",
      "                                        \"seed\": null\n",
      "                                    },\n",
      "                                    \"registered_name\": null\n",
      "                                },\n",
      "                                \"recurrent_initializer\": {\n",
      "                                    \"module\": \"keras.initializers\",\n",
      "                                    \"class_name\": \"OrthogonalInitializer\",\n",
      "                                    \"config\": {\n",
      "                                        \"seed\": null,\n",
      "                                        \"gain\": 1.0\n",
      "                                    },\n",
      "                                    \"registered_name\": null\n",
      "                                },\n",
      "                                \"bias_initializer\": {\n",
      "                                    \"module\": \"keras.initializers\",\n",
      "                                    \"class_name\": \"Zeros\",\n",
      "                                    \"config\": {},\n",
      "                                    \"registered_name\": null\n",
      "                                },\n",
      "                                \"unit_forget_bias\": true,\n",
      "                                \"kernel_regularizer\": null,\n",
      "                                \"recurrent_regularizer\": null,\n",
      "                                \"bias_regularizer\": null,\n",
      "                                \"activity_regularizer\": null,\n",
      "                                \"kernel_constraint\": null,\n",
      "                                \"recurrent_constraint\": null,\n",
      "                                \"bias_constraint\": null,\n",
      "                                \"dropout\": 0.0,\n",
      "                                \"recurrent_dropout\": 0.0,\n",
      "                                \"seed\": null\n",
      "                            },\n",
      "                            \"registered_name\": null,\n",
      "                            \"build_config\": {\n",
      "                                \"input_shape\": [\n",
      "                                    null,\n",
      "                                    null,\n",
      "                                    128\n",
      "                                ]\n",
      "                            }\n",
      "                        },\n",
      "                        \"backward_layer\": {\n",
      "                            \"module\": \"keras.layers\",\n",
      "                            \"class_name\": \"LSTM\",\n",
      "                            \"config\": {\n",
      "                                \"name\": \"backward_lstm\",\n",
      "                                \"trainable\": true,\n",
      "                                \"dtype\": {\n",
      "                                    \"module\": \"keras\",\n",
      "                                    \"class_name\": \"DTypePolicy\",\n",
      "                                    \"config\": {\n",
      "                                        \"name\": \"float32\"\n",
      "                                    },\n",
      "                                    \"registered_name\": null\n",
      "                                },\n",
      "                                \"return_sequences\": true,\n",
      "                                \"return_state\": false,\n",
      "                                \"go_backwards\": true,\n",
      "                                \"stateful\": false,\n",
      "                                \"unroll\": false,\n",
      "                                \"zero_output_for_mask\": true,\n",
      "                                \"units\": 64,\n",
      "                                \"activation\": \"tanh\",\n",
      "                                \"recurrent_activation\": \"sigmoid\",\n",
      "                                \"use_bias\": true,\n",
      "                                \"kernel_initializer\": {\n",
      "                                    \"module\": \"keras.initializers\",\n",
      "                                    \"class_name\": \"GlorotUniform\",\n",
      "                                    \"config\": {\n",
      "                                        \"seed\": null\n",
      "                                    },\n",
      "                                    \"registered_name\": null\n",
      "                                },\n",
      "                                \"recurrent_initializer\": {\n",
      "                                    \"module\": \"keras.initializers\",\n",
      "                                    \"class_name\": \"OrthogonalInitializer\",\n",
      "                                    \"config\": {\n",
      "                                        \"seed\": null,\n",
      "                                        \"gain\": 1.0\n",
      "                                    },\n",
      "                                    \"registered_name\": null\n",
      "                                },\n",
      "                                \"bias_initializer\": {\n",
      "                                    \"module\": \"keras.initializers\",\n",
      "                                    \"class_name\": \"Zeros\",\n",
      "                                    \"config\": {},\n",
      "                                    \"registered_name\": null\n",
      "                                },\n",
      "                                \"unit_forget_bias\": true,\n",
      "                                \"kernel_regularizer\": null,\n",
      "                                \"recurrent_regularizer\": null,\n",
      "                                \"bias_regularizer\": null,\n",
      "                                \"activity_regularizer\": null,\n",
      "                                \"kernel_constraint\": null,\n",
      "                                \"recurrent_constraint\": null,\n",
      "                                \"bias_constraint\": null,\n",
      "                                \"dropout\": 0.0,\n",
      "                                \"recurrent_dropout\": 0.0,\n",
      "                                \"seed\": null\n",
      "                            },\n",
      "                            \"registered_name\": null,\n",
      "                            \"build_config\": {\n",
      "                                \"input_shape\": [\n",
      "                                    null,\n",
      "                                    null,\n",
      "                                    128\n",
      "                                ]\n",
      "                            }\n",
      "                        }\n",
      "                    },\n",
      "                    \"registered_name\": null,\n",
      "                    \"build_config\": {\n",
      "                        \"input_shape\": [\n",
      "                            null,\n",
      "                            null,\n",
      "                            128\n",
      "                        ]\n",
      "                    },\n",
      "                    \"name\": \"bilstm_1\",\n",
      "                    \"inbound_nodes\": [\n",
      "                        {\n",
      "                            \"args\": [\n",
      "                                {\n",
      "                                    \"class_name\": \"__keras_tensor__\",\n",
      "                                    \"config\": {\n",
      "                                        \"shape\": [\n",
      "                                            null,\n",
      "                                            null,\n",
      "                                            128\n",
      "                                        ],\n",
      "                                        \"dtype\": \"float32\",\n",
      "                                        \"keras_history\": [\n",
      "                                            \"batchnorm_conv\",\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ]\n",
      "                                    }\n",
      "                                }\n",
      "                            ],\n",
      "                            \"kwargs\": {\n",
      "                                \"mask\": null\n",
      "                            }\n",
      "                        }\n",
      "                    ]\n",
      "                },\n",
      "                {\n",
      "                    \"module\": \"keras.layers\",\n",
      "                    \"class_name\": \"BatchNormalization\",\n",
      "                    \"config\": {\n",
      "                        \"name\": \"batchnorm_lstm1\",\n",
      "                        \"trainable\": true,\n",
      "                        \"dtype\": {\n",
      "                            \"module\": \"keras\",\n",
      "                            \"class_name\": \"DTypePolicy\",\n",
      "                            \"config\": {\n",
      "                                \"name\": \"float32\"\n",
      "                            },\n",
      "                            \"registered_name\": null\n",
      "                        },\n",
      "                        \"axis\": -1,\n",
      "                        \"momentum\": 0.99,\n",
      "                        \"epsilon\": 0.001,\n",
      "                        \"center\": true,\n",
      "                        \"scale\": true,\n",
      "                        \"beta_initializer\": {\n",
      "                            \"module\": \"keras.initializers\",\n",
      "                            \"class_name\": \"Zeros\",\n",
      "                            \"config\": {},\n",
      "                            \"registered_name\": null\n",
      "                        },\n",
      "                        \"gamma_initializer\": {\n",
      "                            \"module\": \"keras.initializers\",\n",
      "                            \"class_name\": \"Ones\",\n",
      "                            \"config\": {},\n",
      "                            \"registered_name\": null\n",
      "                        },\n",
      "                        \"moving_mean_initializer\": {\n",
      "                            \"module\": \"keras.initializers\",\n",
      "                            \"class_name\": \"Zeros\",\n",
      "                            \"config\": {},\n",
      "                            \"registered_name\": null\n",
      "                        },\n",
      "                        \"moving_variance_initializer\": {\n",
      "                            \"module\": \"keras.initializers\",\n",
      "                            \"class_name\": \"Ones\",\n",
      "                            \"config\": {},\n",
      "                            \"registered_name\": null\n",
      "                        },\n",
      "                        \"beta_regularizer\": null,\n",
      "                        \"gamma_regularizer\": null,\n",
      "                        \"beta_constraint\": null,\n",
      "                        \"gamma_constraint\": null,\n",
      "                        \"synchronized\": false\n",
      "                    },\n",
      "                    \"registered_name\": null,\n",
      "                    \"build_config\": {\n",
      "                        \"input_shape\": [\n",
      "                            null,\n",
      "                            null,\n",
      "                            128\n",
      "                        ]\n",
      "                    },\n",
      "                    \"name\": \"batchnorm_lstm1\",\n",
      "                    \"inbound_nodes\": [\n",
      "                        {\n",
      "                            \"args\": [\n",
      "                                {\n",
      "                                    \"class_name\": \"__keras_tensor__\",\n",
      "                                    \"config\": {\n",
      "                                        \"shape\": [\n",
      "                                            null,\n",
      "                                            null,\n",
      "                                            128\n",
      "                                        ],\n",
      "                                        \"dtype\": \"float32\",\n",
      "                                        \"keras_history\": [\n",
      "                                            \"bilstm_1\",\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ]\n",
      "                                    }\n",
      "                                }\n",
      "                            ],\n",
      "                            \"kwargs\": {\n",
      "                                \"mask\": null\n",
      "                            }\n",
      "                        }\n",
      "                    ]\n",
      "                },\n",
      "                {\n",
      "                    \"module\": \"keras.layers\",\n",
      "                    \"class_name\": \"InputLayer\",\n",
      "                    \"config\": {\n",
      "                        \"batch_shape\": [\n",
      "                            null,\n",
      "                            1\n",
      "                        ],\n",
      "                        \"dtype\": \"int64\",\n",
      "                        \"sparse\": false,\n",
      "                        \"name\": \"input_landmark_length_lzv\"\n",
      "                    },\n",
      "                    \"registered_name\": null,\n",
      "                    \"name\": \"input_landmark_length_lzv\",\n",
      "                    \"inbound_nodes\": []\n",
      "                },\n",
      "                {\n",
      "                    \"module\": \"keras.layers\",\n",
      "                    \"class_name\": \"InputLayer\",\n",
      "                    \"config\": {\n",
      "                        \"batch_shape\": [\n",
      "                            null,\n",
      "                            1\n",
      "                        ],\n",
      "                        \"dtype\": \"int64\",\n",
      "                        \"sparse\": false,\n",
      "                        \"name\": \"input_label_length_lzv\"\n",
      "                    },\n",
      "                    \"registered_name\": null,\n",
      "                    \"name\": \"input_label_length_lzv\",\n",
      "                    \"inbound_nodes\": []\n",
      "                },\n",
      "                {\n",
      "                    \"module\": \"keras.layers\",\n",
      "                    \"class_name\": \"InputLayer\",\n",
      "                    \"config\": {\n",
      "                        \"batch_shape\": [\n",
      "                            null,\n",
      "                            null\n",
      "                        ],\n",
      "                        \"dtype\": \"int64\",\n",
      "                        \"sparse\": false,\n",
      "                        \"name\": \"input_labels_lzv\"\n",
      "                    },\n",
      "                    \"registered_name\": null,\n",
      "                    \"name\": \"input_labels_lzv\",\n",
      "                    \"inbound_nodes\": []\n",
      "                },\n",
      "                {\n",
      "                    \"module\": \"keras.layers\",\n",
      "                    \"class_name\": \"TimeDistributed\",\n",
      "                    \"config\": {\n",
      "                        \"name\": \"output_dense_softmax_lzv\",\n",
      "                        \"trainable\": true,\n",
      "                        \"dtype\": {\n",
      "                            \"module\": \"keras\",\n",
      "                            \"class_name\": \"DTypePolicy\",\n",
      "                            \"config\": {\n",
      "                                \"name\": \"float32\"\n",
      "                            },\n",
      "                            \"registered_name\": null\n",
      "                        },\n",
      "                        \"layer\": {\n",
      "                            \"module\": \"keras.layers\",\n",
      "                            \"class_name\": \"Dense\",\n",
      "                            \"config\": {\n",
      "                                \"name\": \"dense_1\",\n",
      "                                \"trainable\": true,\n",
      "                                \"dtype\": {\n",
      "                                    \"module\": \"keras\",\n",
      "                                    \"class_name\": \"DTypePolicy\",\n",
      "                                    \"config\": {\n",
      "                                        \"name\": \"float32\"\n",
      "                                    },\n",
      "                                    \"registered_name\": null\n",
      "                                },\n",
      "                                \"units\": 46,\n",
      "                                \"activation\": \"softmax\",\n",
      "                                \"use_bias\": true,\n",
      "                                \"kernel_initializer\": {\n",
      "                                    \"module\": \"keras.initializers\",\n",
      "                                    \"class_name\": \"GlorotUniform\",\n",
      "                                    \"config\": {\n",
      "                                        \"seed\": null\n",
      "                                    },\n",
      "                                    \"registered_name\": null\n",
      "                                },\n",
      "                                \"bias_initializer\": {\n",
      "                                    \"module\": \"keras.initializers\",\n",
      "                                    \"class_name\": \"Zeros\",\n",
      "                                    \"config\": {},\n",
      "                                    \"registered_name\": null\n",
      "                                },\n",
      "                                \"kernel_regularizer\": null,\n",
      "                                \"bias_regularizer\": null,\n",
      "                                \"kernel_constraint\": null,\n",
      "                                \"bias_constraint\": null\n",
      "                            },\n",
      "                            \"registered_name\": null,\n",
      "                            \"build_config\": {\n",
      "                                \"input_shape\": [\n",
      "                                    null,\n",
      "                                    128\n",
      "                                ]\n",
      "                            }\n",
      "                        }\n",
      "                    },\n",
      "                    \"registered_name\": null,\n",
      "                    \"build_config\": {\n",
      "                        \"input_shape\": [\n",
      "                            null,\n",
      "                            null,\n",
      "                            128\n",
      "                        ]\n",
      "                    },\n",
      "                    \"name\": \"output_dense_softmax_lzv\",\n",
      "                    \"inbound_nodes\": [\n",
      "                        {\n",
      "                            \"args\": [\n",
      "                                {\n",
      "                                    \"class_name\": \"__keras_tensor__\",\n",
      "                                    \"config\": {\n",
      "                                        \"shape\": [\n",
      "                                            null,\n",
      "                                            null,\n",
      "                                            128\n",
      "                                        ],\n",
      "                                        \"dtype\": \"float32\",\n",
      "                                        \"keras_history\": [\n",
      "                                            \"batchnorm_lstm1\",\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ]\n",
      "                                    }\n",
      "                                }\n",
      "                            ],\n",
      "                            \"kwargs\": {\n",
      "                                \"mask\": null\n",
      "                            }\n",
      "                        }\n",
      "                    ]\n",
      "                },\n",
      "                {\n",
      "                    \"module\": \"keras.layers\",\n",
      "                    \"class_name\": \"Lambda\",\n",
      "                    \"config\": {\n",
      "                        \"name\": \"squeeze_lm_len_lzv\",\n",
      "                        \"trainable\": true,\n",
      "                        \"dtype\": {\n",
      "                            \"module\": \"keras\",\n",
      "                            \"class_name\": \"DTypePolicy\",\n",
      "                            \"config\": {\n",
      "                                \"name\": \"float32\"\n",
      "                            },\n",
      "                            \"registered_name\": null\n",
      "                        },\n",
      "                        \"function\": {\n",
      "                            \"class_name\": \"__lambda__\",\n",
      "                            \"config\": {\n",
      "                                \"code\": \"4wEAAAAAAAAAAAAAAAQAAAATAAAA8zoAAACXAHQAAAAAAAAAAAAAAKABAAAAAAAAAAAAAAAAAAAA\\nAAAAAAB8AGQBrAKmAgAAqwIAAAAAAAAAAFMAqQNO6f////+pAdoEYXhpc6kC2gJ0ZtoHc3F1ZWV6\\nZakB2gF0cwEAAAAg+j9DOi9Vc2Vycy9saWVuZS9BcHBEYXRhL0xvY2FsL1RlbXAvaXB5a2VybmVs\\nXzIzODEyLzE4MjQ4MzMwNzkucHn6CDxsYW1iZGE++ixidWlsZF9jc2xyX2ZpbmVfdHVuZV9tb2Rl\\nbC48bG9jYWxzPi48bGFtYmRhPmsAAABzFgAAAIAAvTK/Oro6wGHIYrg60TtR1DtRgADzAAAAAA==\\n\",\n",
      "                                \"defaults\": null,\n",
      "                                \"closure\": null\n",
      "                            }\n",
      "                        },\n",
      "                        \"arguments\": {}\n",
      "                    },\n",
      "                    \"registered_name\": null,\n",
      "                    \"build_config\": {\n",
      "                        \"input_shape\": [\n",
      "                            null,\n",
      "                            1\n",
      "                        ]\n",
      "                    },\n",
      "                    \"name\": \"squeeze_lm_len_lzv\",\n",
      "                    \"inbound_nodes\": [\n",
      "                        {\n",
      "                            \"args\": [\n",
      "                                {\n",
      "                                    \"class_name\": \"__keras_tensor__\",\n",
      "                                    \"config\": {\n",
      "                                        \"shape\": [\n",
      "                                            null,\n",
      "                                            1\n",
      "                                        ],\n",
      "                                        \"dtype\": \"int64\",\n",
      "                                        \"keras_history\": [\n",
      "                                            \"input_landmark_length_lzv\",\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ]\n",
      "                                    }\n",
      "                                }\n",
      "                            ],\n",
      "                            \"kwargs\": {\n",
      "                                \"mask\": null\n",
      "                            }\n",
      "                        }\n",
      "                    ]\n",
      "                },\n",
      "                {\n",
      "                    \"module\": \"keras.layers\",\n",
      "                    \"class_name\": \"Lambda\",\n",
      "                    \"config\": {\n",
      "                        \"name\": \"squeeze_ph_len_lzv\",\n",
      "                        \"trainable\": true,\n",
      "                        \"dtype\": {\n",
      "                            \"module\": \"keras\",\n",
      "                            \"class_name\": \"DTypePolicy\",\n",
      "                            \"config\": {\n",
      "                                \"name\": \"float32\"\n",
      "                            },\n",
      "                            \"registered_name\": null\n",
      "                        },\n",
      "                        \"function\": {\n",
      "                            \"class_name\": \"__lambda__\",\n",
      "                            \"config\": {\n",
      "                                \"code\": \"4wEAAAAAAAAAAAAAAAQAAAATAAAA8zoAAACXAHQAAAAAAAAAAAAAAKABAAAAAAAAAAAAAAAAAAAA\\nAAAAAAB8AGQBrAKmAgAAqwIAAAAAAAAAAFMAqQNO6f////+pAdoEYXhpc6kC2gJ0ZtoHc3F1ZWV6\\nZakB2gF0cwEAAAAg+j9DOi9Vc2Vycy9saWVuZS9BcHBEYXRhL0xvY2FsL1RlbXAvaXB5a2VybmVs\\nXzIzODEyLzE4MjQ4MzMwNzkucHn6CDxsYW1iZGE++ixidWlsZF9jc2xyX2ZpbmVfdHVuZV9tb2Rl\\nbC48bG9jYWxzPi48bGFtYmRhPmwAAABzFgAAAIAAvQK/CroKwDHIMrgK0ThO1DhOgADzAAAAAA==\\n\",\n",
      "                                \"defaults\": null,\n",
      "                                \"closure\": null\n",
      "                            }\n",
      "                        },\n",
      "                        \"arguments\": {}\n",
      "                    },\n",
      "                    \"registered_name\": null,\n",
      "                    \"build_config\": {\n",
      "                        \"input_shape\": [\n",
      "                            null,\n",
      "                            1\n",
      "                        ]\n",
      "                    },\n",
      "                    \"name\": \"squeeze_ph_len_lzv\",\n",
      "                    \"inbound_nodes\": [\n",
      "                        {\n",
      "                            \"args\": [\n",
      "                                {\n",
      "                                    \"class_name\": \"__keras_tensor__\",\n",
      "                                    \"config\": {\n",
      "                                        \"shape\": [\n",
      "                                            null,\n",
      "                                            1\n",
      "                                        ],\n",
      "                                        \"dtype\": \"int64\",\n",
      "                                        \"keras_history\": [\n",
      "                                            \"input_label_length_lzv\",\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ]\n",
      "                                    }\n",
      "                                }\n",
      "                            ],\n",
      "                            \"kwargs\": {\n",
      "                                \"mask\": null\n",
      "                            }\n",
      "                        }\n",
      "                    ]\n",
      "                },\n",
      "                {\n",
      "                    \"module\": \"keras.layers\",\n",
      "                    \"class_name\": \"Lambda\",\n",
      "                    \"config\": {\n",
      "                        \"name\": \"ctc_loss_lzv\",\n",
      "                        \"trainable\": true,\n",
      "                        \"dtype\": {\n",
      "                            \"module\": \"keras\",\n",
      "                            \"class_name\": \"DTypePolicy\",\n",
      "                            \"config\": {\n",
      "                                \"name\": \"float32\"\n",
      "                            },\n",
      "                            \"registered_name\": null\n",
      "                        },\n",
      "                        \"function\": {\n",
      "                            \"class_name\": \"__lambda__\",\n",
      "                            \"config\": {\n",
      "                                \"code\": \"4wEAAAAAAAAAAAAAAAkAAAATAAAA8+oAAACXAHQAAAAAAAAAAAAAAGoBAAAAAAAAAABqAgAAAAAA\\nAAAAoAMAAAAAAAAAAAAAAAAAAAAAAAAAAHwAZAEZAAAAAAAAAAAAfABkAhkAAAAAAAAAAAB0AAAA\\nAAAAAAAAAACgBAAAAAAAAAAAAAAAAAAAAAAAAAAAfABkAxkAAAAAAAAAAABkBKwFpgIAAKsCAAAA\\nAAAAAAB0AAAAAAAAAAAAAACgBAAAAAAAAAAAAAAAAAAAAAAAAAAAfABkBhkAAAAAAAAAAABkBKwF\\npgIAAKsCAAAAAAAAAACsB6YEAACrBAAAAAAAAAAAUwApCE7pAAAAAOkBAAAA6QIAAADp/////6kB\\n2gRheGlz6QMAAAApBNoGeV90cnVl2gZ5X3ByZWTaDGlucHV0X2xlbmd0aNoMbGFiZWxfbGVuZ3Ro\\nKQXaAnRm2gVrZXJhc9oHYmFja2VuZNoOY3RjX2JhdGNoX2Nvc3TaC2V4cGFuZF9kaW1zKQHaBGFy\\nZ3NzAQAAACD6P0M6L1VzZXJzL2xpZW5lL0FwcERhdGEvTG9jYWwvVGVtcC9pcHlrZXJuZWxfMjM4\\nMTIvMTgyNDgzMzA3OS5wefoIPGxhbWJkYT76LGJ1aWxkX2NzbHJfZmluZV90dW5lX21vZGVsLjxs\\nb2NhbHM+LjxsYW1iZGE+bwAAAHNeAAAAgACVUpRY1BUl1xU00hU02BMXmAGUN6A0qAGkN90ZG58e\\nmh6oBKhRrAewYpge0Rk51Bk5zQLPDsoO0Fdb0C9d1Fde0GVnyA7RSGjUSGjwBQAWNfEAAxYK9AAD\\nFgqAAPMAAAAA\\n\",\n",
      "                                \"defaults\": null,\n",
      "                                \"closure\": null\n",
      "                            }\n",
      "                        },\n",
      "                        \"arguments\": {}\n",
      "                    },\n",
      "                    \"registered_name\": null,\n",
      "                    \"build_config\": {\n",
      "                        \"input_shape\": [\n",
      "                            [\n",
      "                                null,\n",
      "                                null\n",
      "                            ],\n",
      "                            [\n",
      "                                null,\n",
      "                                null,\n",
      "                                46\n",
      "                            ],\n",
      "                            [\n",
      "                                null\n",
      "                            ],\n",
      "                            [\n",
      "                                null\n",
      "                            ]\n",
      "                        ]\n",
      "                    },\n",
      "                    \"name\": \"ctc_loss_lzv\",\n",
      "                    \"inbound_nodes\": [\n",
      "                        {\n",
      "                            \"args\": [\n",
      "                                [\n",
      "                                    {\n",
      "                                        \"class_name\": \"__keras_tensor__\",\n",
      "                                        \"config\": {\n",
      "                                            \"shape\": [\n",
      "                                                null,\n",
      "                                                null\n",
      "                                            ],\n",
      "                                            \"dtype\": \"int64\",\n",
      "                                            \"keras_history\": [\n",
      "                                                \"input_labels_lzv\",\n",
      "                                                0,\n",
      "                                                0\n",
      "                                            ]\n",
      "                                        }\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"class_name\": \"__keras_tensor__\",\n",
      "                                        \"config\": {\n",
      "                                            \"shape\": [\n",
      "                                                null,\n",
      "                                                null,\n",
      "                                                46\n",
      "                                            ],\n",
      "                                            \"dtype\": \"float32\",\n",
      "                                            \"keras_history\": [\n",
      "                                                \"output_dense_softmax_lzv\",\n",
      "                                                0,\n",
      "                                                0\n",
      "                                            ]\n",
      "                                        }\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"class_name\": \"__keras_tensor__\",\n",
      "                                        \"config\": {\n",
      "                                            \"shape\": [\n",
      "                                                null\n",
      "                                            ],\n",
      "                                            \"dtype\": \"float32\",\n",
      "                                            \"keras_history\": [\n",
      "                                                \"squeeze_lm_len_lzv\",\n",
      "                                                0,\n",
      "                                                0\n",
      "                                            ]\n",
      "                                        }\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"class_name\": \"__keras_tensor__\",\n",
      "                                        \"config\": {\n",
      "                                            \"shape\": [\n",
      "                                                null\n",
      "                                            ],\n",
      "                                            \"dtype\": \"float32\",\n",
      "                                            \"keras_history\": [\n",
      "                                                \"squeeze_ph_len_lzv\",\n",
      "                                                0,\n",
      "                                                0\n",
      "                                            ]\n",
      "                                        }\n",
      "                                    }\n",
      "                                ]\n",
      "                            ],\n",
      "                            \"kwargs\": {\n",
      "                                \"mask\": [\n",
      "                                    null,\n",
      "                                    null,\n",
      "                                    null,\n",
      "                                    null\n",
      "                                ]\n",
      "                            }\n",
      "                        }\n",
      "                    ]\n",
      "                }\n",
      "            ],\n",
      "            \"input_layers\": {\n",
      "                \"input_landmarks\": [\n",
      "                    \"input_landmarks\",\n",
      "                    0,\n",
      "                    0\n",
      "                ],\n",
      "                \"input_labels\": [\n",
      "                    \"input_labels_lzv\",\n",
      "                    0,\n",
      "                    0\n",
      "                ],\n",
      "                \"input_landmark_length\": [\n",
      "                    \"input_landmark_length_lzv\",\n",
      "                    0,\n",
      "                    0\n",
      "                ],\n",
      "                \"input_label_length\": [\n",
      "                    \"input_label_length_lzv\",\n",
      "                    0,\n",
      "                    0\n",
      "                ]\n",
      "            },\n",
      "            \"output_layers\": [\n",
      "                [\n",
      "                    \"ctc_loss_lzv\",\n",
      "                    0,\n",
      "                    0\n",
      "                ]\n",
      "            ]\n",
      "        },\n",
      "        \"params_total\": 186542,\n",
      "        \"params_trainable\": 186030\n",
      "    },\n",
      "    \"results\": {\n",
      "        \"best_val_wer_overall\": 0.20666666666666667,\n",
      "        \"best_val_wer_epoch_overall\": 70,\n",
      "        \"final_train_loss\": 2.004436731338501,\n",
      "        \"final_val_wer\": 0.21666666666666667,\n",
      "        \"epoch_metrics\": [\n",
      "            {\n",
      "                \"epoch\": 1,\n",
      "                \"loss\": 206.20648193359375,\n",
      "                \"val_loss\": 26.54610824584961,\n",
      "                \"val_wer\": 1.52,\n",
      "                \"lr\": 0.0010000000474974513\n",
      "            },\n",
      "            {\n",
      "                \"epoch\": 2,\n",
      "                \"loss\": 34.10596466064453,\n",
      "                \"val_loss\": 15.602439880371094,\n",
      "                \"val_wer\": 1.3566666666666667,\n",
      "                \"lr\": 0.0010000000474974513\n",
      "            },\n",
      "            {\n",
      "                \"epoch\": 3,\n",
      "                \"loss\": 24.33619499206543,\n",
      "                \"val_loss\": 10.465883255004883,\n",
      "                \"val_wer\": 2.3733333333333335,\n",
      "                \"lr\": 0.0010000000474974513\n",
      "            },\n",
      "            {\n",
      "                \"epoch\": 4,\n",
      "                \"loss\": 19.343950271606445,\n",
      "                \"val_loss\": 8.105584144592285,\n",
      "                \"val_wer\": 2.1433333333333335,\n",
      "                \"lr\": 0.0010000000474974513\n",
      "            },\n",
      "            {\n",
      "                \"epoch\": 5,\n",
      "                \"loss\": 13.173686027526855,\n",
      "                \"val_loss\": 7.240564346313477,\n",
      "                \"val_wer\": 1.8233333333333333,\n",
      "                \"lr\": 0.0010000000474974513\n",
      "            },\n",
      "            {\n",
      "                \"epoch\": 6,\n",
      "                \"loss\": 11.042464256286621,\n",
      "                \"val_loss\": 6.450219631195068,\n",
      "                \"val_wer\": 1.02,\n",
      "                \"lr\": 0.0010000000474974513\n",
      "            },\n",
      "            {\n",
      "                \"epoch\": 7,\n",
      "                \"loss\": 9.674126625061035,\n",
      "                \"val_loss\": 5.698976516723633,\n",
      "                \"val_wer\": 0.8633333333333333,\n",
      "                \"lr\": 0.0010000000474974513\n",
      "            },\n",
      "            {\n",
      "                \"epoch\": 8,\n",
      "                \"loss\": 8.771221160888672,\n",
      "                \"val_loss\": 5.446804046630859,\n",
      "                \"val_wer\": 0.8233333333333334,\n",
      "                \"lr\": 0.0010000000474974513\n",
      "            },\n",
      "            {\n",
      "                \"epoch\": 9,\n",
      "                \"loss\": 7.1685662269592285,\n",
      "                \"val_loss\": 5.654796600341797,\n",
      "                \"val_wer\": 0.8633333333333333,\n",
      "                \"lr\": 0.0010000000474974513\n",
      "            },\n",
      "            {\n",
      "                \"epoch\": 10,\n",
      "                \"loss\": 6.703371047973633,\n",
      "                \"val_loss\": 5.305193901062012,\n",
      "                \"val_wer\": 0.6266666666666667,\n",
      "                \"lr\": 0.0010000000474974513\n",
      "            },\n",
      "            {\n",
      "                \"epoch\": 11,\n",
      "                \"loss\": 6.120894908905029,\n",
      "                \"val_loss\": 5.412588119506836,\n",
      "                \"val_wer\": 0.54,\n",
      "                \"lr\": 0.0010000000474974513\n",
      "            },\n",
      "            {\n",
      "                \"epoch\": 12,\n",
      "                \"loss\": 5.942758083343506,\n",
      "                \"val_loss\": 5.174802303314209,\n",
      "                \"val_wer\": 0.4666666666666667,\n",
      "                \"lr\": 0.0010000000474974513\n",
      "            },\n",
      "            {\n",
      "                \"epoch\": 13,\n",
      "                \"loss\": 5.186604976654053,\n",
      "                \"val_loss\": 5.481748104095459,\n",
      "                \"val_wer\": 0.41,\n",
      "                \"lr\": 0.0010000000474974513\n",
      "            },\n",
      "            {\n",
      "                \"epoch\": 14,\n",
      "                \"loss\": 4.853175640106201,\n",
      "                \"val_loss\": 5.052728652954102,\n",
      "                \"val_wer\": 0.5,\n",
      "                \"lr\": 0.0010000000474974513\n",
      "            },\n",
      "            {\n",
      "                \"epoch\": 15,\n",
      "                \"loss\": 4.819790363311768,\n",
      "                \"val_loss\": 5.6814775466918945,\n",
      "                \"val_wer\": 0.37666666666666665,\n",
      "                \"lr\": 0.0010000000474974513\n",
      "            },\n",
      "            {\n",
      "                \"epoch\": 16,\n",
      "                \"loss\": 4.3741679191589355,\n",
      "                \"val_loss\": 4.822079658508301,\n",
      "                \"val_wer\": 0.58,\n",
      "                \"lr\": 0.0010000000474974513\n",
      "            },\n",
      "            {\n",
      "                \"epoch\": 17,\n",
      "                \"loss\": 4.304736137390137,\n",
      "                \"val_loss\": 5.341893196105957,\n",
      "                \"val_wer\": 0.35,\n",
      "                \"lr\": 0.0010000000474974513\n",
      "            },\n",
      "            {\n",
      "                \"epoch\": 18,\n",
      "                \"loss\": 4.056751251220703,\n",
      "                \"val_loss\": 5.502028942108154,\n",
      "                \"val_wer\": 0.4633333333333333,\n",
      "                \"lr\": 0.0010000000474974513\n",
      "            },\n",
      "            {\n",
      "                \"epoch\": 19,\n",
      "                \"loss\": 4.121574878692627,\n",
      "                \"val_loss\": 5.735354900360107,\n",
      "                \"val_wer\": 0.2966666666666667,\n",
      "                \"lr\": 0.0010000000474974513\n",
      "            },\n",
      "            {\n",
      "                \"epoch\": 20,\n",
      "                \"loss\": 3.7452774047851562,\n",
      "                \"val_loss\": 5.343857765197754,\n",
      "                \"val_wer\": 2.92,\n",
      "                \"lr\": 0.0010000000474974513\n",
      "            },\n",
      "            {\n",
      "                \"epoch\": 21,\n",
      "                \"loss\": 3.3568735122680664,\n",
      "                \"val_loss\": 4.8929877281188965,\n",
      "                \"val_wer\": 0.29,\n",
      "                \"lr\": 0.0010000000474974513\n",
      "            },\n",
      "            {\n",
      "                \"epoch\": 22,\n",
      "                \"loss\": 3.181058406829834,\n",
      "                \"val_loss\": 5.046799659729004,\n",
      "                \"val_wer\": 0.2866666666666667,\n",
      "                \"lr\": 0.0010000000474974513\n",
      "            },\n",
      "            {\n",
      "                \"epoch\": 23,\n",
      "                \"loss\": 3.0942695140838623,\n",
      "                \"val_loss\": 5.149197101593018,\n",
      "                \"val_wer\": 0.2866666666666667,\n",
      "                \"lr\": 0.0010000000474974513\n",
      "            },\n",
      "            {\n",
      "                \"epoch\": 24,\n",
      "                \"loss\": 2.976198196411133,\n",
      "                \"val_loss\": 5.064435958862305,\n",
      "                \"val_wer\": 0.25333333333333335,\n",
      "                \"lr\": 0.0010000000474974513\n",
      "            },\n",
      "            {\n",
      "                \"epoch\": 25,\n",
      "                \"loss\": 2.7827887535095215,\n",
      "                \"val_loss\": 5.003209590911865,\n",
      "                \"val_wer\": 0.26,\n",
      "                \"lr\": 0.0010000000474974513\n",
      "            },\n",
      "            {\n",
      "                \"epoch\": 26,\n",
      "                \"loss\": 2.7701001167297363,\n",
      "                \"val_loss\": 4.9690842628479,\n",
      "                \"val_wer\": 0.25666666666666665,\n",
      "                \"lr\": 0.0010000000474974513\n",
      "            },\n",
      "            {\n",
      "                \"epoch\": 27,\n",
      "                \"loss\": 2.894383668899536,\n",
      "                \"val_loss\": 4.9692816734313965,\n",
      "                \"val_wer\": 0.25333333333333335,\n",
      "                \"lr\": 0.0010000000474974513\n",
      "            },\n",
      "            {\n",
      "                \"epoch\": 28,\n",
      "                \"loss\": 2.648350477218628,\n",
      "                \"val_loss\": 4.969820499420166,\n",
      "                \"val_wer\": 0.24333333333333335,\n",
      "                \"lr\": 0.0010000000474974513\n",
      "            },\n",
      "            {\n",
      "                \"epoch\": 29,\n",
      "                \"loss\": 2.5926449298858643,\n",
      "                \"val_loss\": 4.929688453674316,\n",
      "                \"val_wer\": 0.25333333333333335,\n",
      "                \"lr\": 0.0010000000474974513\n",
      "            },\n",
      "            {\n",
      "                \"epoch\": 30,\n",
      "                \"loss\": 2.8468525409698486,\n",
      "                \"val_loss\": 4.97042989730835,\n",
      "                \"val_wer\": 0.27,\n",
      "                \"lr\": 0.0010000000474974513\n",
      "            },\n",
      "            {\n",
      "                \"epoch\": 31,\n",
      "                \"loss\": 2.6271915435791016,\n",
      "                \"val_loss\": 4.9832563400268555,\n",
      "                \"val_wer\": 0.25333333333333335,\n",
      "                \"lr\": 0.0010000000474974513\n",
      "            },\n",
      "            {\n",
      "                \"epoch\": 32,\n",
      "                \"loss\": 2.452608823776245,\n",
      "                \"val_loss\": 4.9857635498046875,\n",
      "                \"val_wer\": 0.22,\n",
      "                \"lr\": 0.0010000000474974513\n",
      "            },\n",
      "            {\n",
      "                \"epoch\": 33,\n",
      "                \"loss\": 2.3159427642822266,\n",
      "                \"val_loss\": 4.941298007965088,\n",
      "                \"val_wer\": 0.24333333333333335,\n",
      "                \"lr\": 0.0010000000474974513\n",
      "            },\n",
      "            {\n",
      "                \"epoch\": 34,\n",
      "                \"loss\": 2.387188673019409,\n",
      "                \"val_loss\": 4.935210704803467,\n",
      "                \"val_wer\": 0.25,\n",
      "                \"lr\": 0.0010000000474974513\n",
      "            },\n",
      "            {\n",
      "                \"epoch\": 35,\n",
      "                \"loss\": 2.489093065261841,\n",
      "                \"val_loss\": 4.945798397064209,\n",
      "                \"val_wer\": 0.24333333333333335,\n",
      "                \"lr\": 0.0010000000474974513\n",
      "            },\n",
      "            {\n",
      "                \"epoch\": 36,\n",
      "                \"loss\": 1.970621943473816,\n",
      "                \"val_loss\": 4.965644836425781,\n",
      "                \"val_wer\": 0.23666666666666666,\n",
      "                \"lr\": 0.0010000000474974513\n",
      "            },\n",
      "            {\n",
      "                \"epoch\": 37,\n",
      "                \"loss\": 2.0265345573425293,\n",
      "                \"val_loss\": 4.924252986907959,\n",
      "                \"val_wer\": 0.24333333333333335,\n",
      "                \"lr\": 0.0010000000474974513\n",
      "            },\n",
      "            {\n",
      "                \"epoch\": 38,\n",
      "                \"loss\": 1.9878968000411987,\n",
      "                \"val_loss\": 4.934693336486816,\n",
      "                \"val_wer\": 0.24,\n",
      "                \"lr\": 0.0010000000474974513\n",
      "            },\n",
      "            {\n",
      "                \"epoch\": 39,\n",
      "                \"loss\": 2.2693676948547363,\n",
      "                \"val_loss\": 4.94143009185791,\n",
      "                \"val_wer\": 0.22666666666666666,\n",
      "                \"lr\": 0.0010000000474974513\n",
      "            },\n",
      "            {\n",
      "                \"epoch\": 40,\n",
      "                \"loss\": 1.8009779453277588,\n",
      "                \"val_loss\": 4.960853099822998,\n",
      "                \"val_wer\": 0.23666666666666666,\n",
      "                \"lr\": 0.0003000000142492354\n",
      "            },\n",
      "            {\n",
      "                \"epoch\": 41,\n",
      "                \"loss\": 1.9474061727523804,\n",
      "                \"val_loss\": 4.954375267028809,\n",
      "                \"val_wer\": 0.22666666666666666,\n",
      "                \"lr\": 0.0003000000142492354\n",
      "            },\n",
      "            {\n",
      "                \"epoch\": 42,\n",
      "                \"loss\": 2.1159114837646484,\n",
      "                \"val_loss\": 4.9426589012146,\n",
      "                \"val_wer\": 0.24666666666666667,\n",
      "                \"lr\": 0.0003000000142492354\n",
      "            },\n",
      "            {\n",
      "                \"epoch\": 43,\n",
      "                \"loss\": 1.8123546838760376,\n",
      "                \"val_loss\": 4.954473495483398,\n",
      "                \"val_wer\": 0.24,\n",
      "                \"lr\": 0.0003000000142492354\n",
      "            },\n",
      "            {\n",
      "                \"epoch\": 44,\n",
      "                \"loss\": 1.7502700090408325,\n",
      "                \"val_loss\": 4.91982364654541,\n",
      "                \"val_wer\": 0.23666666666666666,\n",
      "                \"lr\": 0.0003000000142492354\n",
      "            },\n",
      "            {\n",
      "                \"epoch\": 45,\n",
      "                \"loss\": 1.8233662843704224,\n",
      "                \"val_loss\": 4.930367469787598,\n",
      "                \"val_wer\": 0.24,\n",
      "                \"lr\": 0.0003000000142492354\n",
      "            },\n",
      "            {\n",
      "                \"epoch\": 46,\n",
      "                \"loss\": 1.7463399171829224,\n",
      "                \"val_loss\": 4.964728355407715,\n",
      "                \"val_wer\": 0.23,\n",
      "                \"lr\": 0.0003000000142492354\n",
      "            },\n",
      "            {\n",
      "                \"epoch\": 47,\n",
      "                \"loss\": 2.0971505641937256,\n",
      "                \"val_loss\": 4.943946361541748,\n",
      "                \"val_wer\": 0.22666666666666666,\n",
      "                \"lr\": 9.000000136438757e-05\n",
      "            },\n",
      "            {\n",
      "                \"epoch\": 48,\n",
      "                \"loss\": 2.010704517364502,\n",
      "                \"val_loss\": 4.93200159072876,\n",
      "                \"val_wer\": 0.21666666666666667,\n",
      "                \"lr\": 4.999999873689376e-05\n",
      "            },\n",
      "            {\n",
      "                \"epoch\": 49,\n",
      "                \"loss\": 2.408869743347168,\n",
      "                \"val_loss\": 4.8996758460998535,\n",
      "                \"val_wer\": 0.21333333333333335,\n",
      "                \"lr\": 4.999999873689376e-05\n",
      "            },\n",
      "            {\n",
      "                \"epoch\": 50,\n",
      "                \"loss\": 2.14277982711792,\n",
      "                \"val_loss\": 4.886695861816406,\n",
      "                \"val_wer\": 0.21666666666666667,\n",
      "                \"lr\": 4.999999873689376e-05\n",
      "            },\n",
      "            {\n",
      "                \"epoch\": 51,\n",
      "                \"loss\": 2.224501132965088,\n",
      "                \"val_loss\": 4.962104797363281,\n",
      "                \"val_wer\": 0.22,\n",
      "                \"lr\": 4.999999873689376e-05\n",
      "            },\n",
      "            {\n",
      "                \"epoch\": 52,\n",
      "                \"loss\": 1.9518166780471802,\n",
      "                \"val_loss\": 4.914669036865234,\n",
      "                \"val_wer\": 0.21666666666666667,\n",
      "                \"lr\": 4.999999873689376e-05\n",
      "            },\n",
      "            {\n",
      "                \"epoch\": 53,\n",
      "                \"loss\": 1.8818767070770264,\n",
      "                \"val_loss\": 4.888377666473389,\n",
      "                \"val_wer\": 0.21333333333333335,\n",
      "                \"lr\": 4.999999873689376e-05\n",
      "            },\n",
      "            {\n",
      "                \"epoch\": 54,\n",
      "                \"loss\": 1.720983624458313,\n",
      "                \"val_loss\": 4.903701305389404,\n",
      "                \"val_wer\": 0.21333333333333335,\n",
      "                \"lr\": 4.999999873689376e-05\n",
      "            },\n",
      "            {\n",
      "                \"epoch\": 55,\n",
      "                \"loss\": 2.0088260173797607,\n",
      "                \"val_loss\": 4.880401134490967,\n",
      "                \"val_wer\": 0.22,\n",
      "                \"lr\": 4.999999873689376e-05\n",
      "            },\n",
      "            {\n",
      "                \"epoch\": 56,\n",
      "                \"loss\": 2.3358471393585205,\n",
      "                \"val_loss\": 4.904203414916992,\n",
      "                \"val_wer\": 0.21,\n",
      "                \"lr\": 4.999999873689376e-05\n",
      "            },\n",
      "            {\n",
      "                \"epoch\": 57,\n",
      "                \"loss\": 2.2459399700164795,\n",
      "                \"val_loss\": 4.8764729499816895,\n",
      "                \"val_wer\": 0.21666666666666667,\n",
      "                \"lr\": 4.999999873689376e-05\n",
      "            },\n",
      "            {\n",
      "                \"epoch\": 58,\n",
      "                \"loss\": 1.8947744369506836,\n",
      "                \"val_loss\": 4.92652702331543,\n",
      "                \"val_wer\": 0.21333333333333335,\n",
      "                \"lr\": 4.999999873689376e-05\n",
      "            },\n",
      "            {\n",
      "                \"epoch\": 59,\n",
      "                \"loss\": 1.9542148113250732,\n",
      "                \"val_loss\": 4.914553165435791,\n",
      "                \"val_wer\": 0.21333333333333335,\n",
      "                \"lr\": 4.999999873689376e-05\n",
      "            },\n",
      "            {\n",
      "                \"epoch\": 60,\n",
      "                \"loss\": 1.6892844438552856,\n",
      "                \"val_loss\": 4.909337997436523,\n",
      "                \"val_wer\": 0.21666666666666667,\n",
      "                \"lr\": 4.999999873689376e-05\n",
      "            },\n",
      "            {\n",
      "                \"epoch\": 61,\n",
      "                \"loss\": 1.886260986328125,\n",
      "                \"val_loss\": 4.875606536865234,\n",
      "                \"val_wer\": 0.21,\n",
      "                \"lr\": 4.999999873689376e-05\n",
      "            },\n",
      "            {\n",
      "                \"epoch\": 62,\n",
      "                \"loss\": 1.6726866960525513,\n",
      "                \"val_loss\": 4.884582996368408,\n",
      "                \"val_wer\": 0.21,\n",
      "                \"lr\": 4.999999873689376e-05\n",
      "            },\n",
      "            {\n",
      "                \"epoch\": 63,\n",
      "                \"loss\": 1.831255555152893,\n",
      "                \"val_loss\": 4.9076972007751465,\n",
      "                \"val_wer\": 0.21666666666666667,\n",
      "                \"lr\": 4.999999873689376e-05\n",
      "            },\n",
      "            {\n",
      "                \"epoch\": 64,\n",
      "                \"loss\": 1.9563323259353638,\n",
      "                \"val_loss\": null,\n",
      "                \"val_wer\": 0.22,\n",
      "                \"lr\": 4.999999873689376e-05\n",
      "            },\n",
      "            {\n",
      "                \"epoch\": 65,\n",
      "                \"loss\": 1.819286584854126,\n",
      "                \"val_loss\": null,\n",
      "                \"val_wer\": 0.21333333333333335,\n",
      "                \"lr\": 4.999999873689376e-05\n",
      "            },\n",
      "            {\n",
      "                \"epoch\": 66,\n",
      "                \"loss\": 1.5868775844573975,\n",
      "                \"val_loss\": null,\n",
      "                \"val_wer\": 0.21666666666666667,\n",
      "                \"lr\": 4.999999873689376e-05\n",
      "            },\n",
      "            {\n",
      "                \"epoch\": 67,\n",
      "                \"loss\": 1.8303248882293701,\n",
      "                \"val_loss\": null,\n",
      "                \"val_wer\": 0.22,\n",
      "                \"lr\": 1.4999999621068127e-05\n",
      "            },\n",
      "            {\n",
      "                \"epoch\": 68,\n",
      "                \"loss\": 1.7039809226989746,\n",
      "                \"val_loss\": null,\n",
      "                \"val_wer\": 0.21333333333333335,\n",
      "                \"lr\": 1.4999999621068127e-05\n",
      "            },\n",
      "            {\n",
      "                \"epoch\": 69,\n",
      "                \"loss\": 1.493611454963684,\n",
      "                \"val_loss\": null,\n",
      "                \"val_wer\": 0.21333333333333335,\n",
      "                \"lr\": 1.4999999621068127e-05\n",
      "            },\n",
      "            {\n",
      "                \"epoch\": 70,\n",
      "                \"loss\": 1.7470701932907104,\n",
      "                \"val_loss\": null,\n",
      "                \"val_wer\": 0.20666666666666667,\n",
      "                \"lr\": 1.4999999621068127e-05\n",
      "            },\n",
      "            {\n",
      "                \"epoch\": 71,\n",
      "                \"loss\": 1.6974461078643799,\n",
      "                \"val_loss\": null,\n",
      "                \"val_wer\": 0.21,\n",
      "                \"lr\": 1.4999999621068127e-05\n",
      "            },\n",
      "            {\n",
      "                \"epoch\": 72,\n",
      "                \"loss\": 1.9918668270111084,\n",
      "                \"val_loss\": null,\n",
      "                \"val_wer\": 0.21666666666666667,\n",
      "                \"lr\": 1.4999999621068127e-05\n",
      "            },\n",
      "            {\n",
      "                \"epoch\": 73,\n",
      "                \"loss\": 1.8692277669906616,\n",
      "                \"val_loss\": null,\n",
      "                \"val_wer\": 0.21333333333333335,\n",
      "                \"lr\": 1.4999999621068127e-05\n",
      "            },\n",
      "            {\n",
      "                \"epoch\": 74,\n",
      "                \"loss\": 1.5330407619476318,\n",
      "                \"val_loss\": null,\n",
      "                \"val_wer\": 0.21333333333333335,\n",
      "                \"lr\": 1.4999999621068127e-05\n",
      "            },\n",
      "            {\n",
      "                \"epoch\": 75,\n",
      "                \"loss\": 1.6593152284622192,\n",
      "                \"val_loss\": null,\n",
      "                \"val_wer\": 0.21333333333333335,\n",
      "                \"lr\": 1.4999999621068127e-05\n",
      "            },\n",
      "            {\n",
      "                \"epoch\": 76,\n",
      "                \"loss\": 1.4409912824630737,\n",
      "                \"val_loss\": null,\n",
      "                \"val_wer\": 0.21666666666666667,\n",
      "                \"lr\": 1.4999999621068127e-05\n",
      "            },\n",
      "            {\n",
      "                \"epoch\": 77,\n",
      "                \"loss\": 1.950264573097229,\n",
      "                \"val_loss\": null,\n",
      "                \"val_wer\": 0.21,\n",
      "                \"lr\": 1.4999999621068127e-05\n",
      "            },\n",
      "            {\n",
      "                \"epoch\": 78,\n",
      "                \"loss\": 1.4825527667999268,\n",
      "                \"val_loss\": null,\n",
      "                \"val_wer\": 0.21333333333333335,\n",
      "                \"lr\": 1.4999999621068127e-05\n",
      "            },\n",
      "            {\n",
      "                \"epoch\": 79,\n",
      "                \"loss\": 1.7822487354278564,\n",
      "                \"val_loss\": null,\n",
      "                \"val_wer\": 0.21333333333333335,\n",
      "                \"lr\": 1.4999999621068127e-05\n",
      "            },\n",
      "            {\n",
      "                \"epoch\": 80,\n",
      "                \"loss\": 1.644487977027893,\n",
      "                \"val_loss\": null,\n",
      "                \"val_wer\": 0.21,\n",
      "                \"lr\": 1.4999999621068127e-05\n",
      "            },\n",
      "            {\n",
      "                \"epoch\": 81,\n",
      "                \"loss\": 1.5737788677215576,\n",
      "                \"val_loss\": null,\n",
      "                \"val_wer\": 0.21333333333333335,\n",
      "                \"lr\": 4.499999704421498e-06\n",
      "            },\n",
      "            {\n",
      "                \"epoch\": 82,\n",
      "                \"loss\": 1.7735272645950317,\n",
      "                \"val_loss\": null,\n",
      "                \"val_wer\": 0.21333333333333335,\n",
      "                \"lr\": 4.499999704421498e-06\n",
      "            },\n",
      "            {\n",
      "                \"epoch\": 83,\n",
      "                \"loss\": 1.717195987701416,\n",
      "                \"val_loss\": null,\n",
      "                \"val_wer\": 0.21333333333333335,\n",
      "                \"lr\": 4.499999704421498e-06\n",
      "            },\n",
      "            {\n",
      "                \"epoch\": 84,\n",
      "                \"loss\": 1.529819369316101,\n",
      "                \"val_loss\": null,\n",
      "                \"val_wer\": 0.21333333333333335,\n",
      "                \"lr\": 4.499999704421498e-06\n",
      "            },\n",
      "            {\n",
      "                \"epoch\": 85,\n",
      "                \"loss\": 1.749667763710022,\n",
      "                \"val_loss\": null,\n",
      "                \"val_wer\": 0.21666666666666667,\n",
      "                \"lr\": 4.499999704421498e-06\n",
      "            },\n",
      "            {\n",
      "                \"epoch\": 86,\n",
      "                \"loss\": 1.6034654378890991,\n",
      "                \"val_loss\": null,\n",
      "                \"val_wer\": 0.22,\n",
      "                \"lr\": 4.499999704421498e-06\n",
      "            },\n",
      "            {\n",
      "                \"epoch\": 87,\n",
      "                \"loss\": 1.7392528057098389,\n",
      "                \"val_loss\": null,\n",
      "                \"val_wer\": 0.21333333333333335,\n",
      "                \"lr\": 4.499999704421498e-06\n",
      "            },\n",
      "            {\n",
      "                \"epoch\": 88,\n",
      "                \"loss\": 1.798583984375,\n",
      "                \"val_loss\": null,\n",
      "                \"val_wer\": 0.21666666666666667,\n",
      "                \"lr\": 4.499999704421498e-06\n",
      "            },\n",
      "            {\n",
      "                \"epoch\": 89,\n",
      "                \"loss\": 1.6197352409362793,\n",
      "                \"val_loss\": null,\n",
      "                \"val_wer\": 0.21666666666666667,\n",
      "                \"lr\": 4.499999704421498e-06\n",
      "            },\n",
      "            {\n",
      "                \"epoch\": 90,\n",
      "                \"loss\": 1.6391394138336182,\n",
      "                \"val_loss\": null,\n",
      "                \"val_wer\": 0.21666666666666667,\n",
      "                \"lr\": 4.499999704421498e-06\n",
      "            },\n",
      "            {\n",
      "                \"epoch\": 91,\n",
      "                \"loss\": 1.5916919708251953,\n",
      "                \"val_loss\": null,\n",
      "                \"val_wer\": 0.21666666666666667,\n",
      "                \"lr\": 1.349999934063817e-06\n",
      "            },\n",
      "            {\n",
      "                \"epoch\": 92,\n",
      "                \"loss\": 1.9348058700561523,\n",
      "                \"val_loss\": null,\n",
      "                \"val_wer\": 0.21333333333333335,\n",
      "                \"lr\": 1.349999934063817e-06\n",
      "            },\n",
      "            {\n",
      "                \"epoch\": 93,\n",
      "                \"loss\": 1.7642844915390015,\n",
      "                \"val_loss\": null,\n",
      "                \"val_wer\": 0.21333333333333335,\n",
      "                \"lr\": 1.349999934063817e-06\n",
      "            },\n",
      "            {\n",
      "                \"epoch\": 94,\n",
      "                \"loss\": 1.551417350769043,\n",
      "                \"val_loss\": null,\n",
      "                \"val_wer\": 0.22,\n",
      "                \"lr\": 1.349999934063817e-06\n",
      "            },\n",
      "            {\n",
      "                \"epoch\": 95,\n",
      "                \"loss\": 1.8008408546447754,\n",
      "                \"val_loss\": null,\n",
      "                \"val_wer\": 0.21666666666666667,\n",
      "                \"lr\": 1.349999934063817e-06\n",
      "            },\n",
      "            {\n",
      "                \"epoch\": 96,\n",
      "                \"loss\": 1.7973657846450806,\n",
      "                \"val_loss\": null,\n",
      "                \"val_wer\": 0.21333333333333335,\n",
      "                \"lr\": 9.999999974752427e-07\n",
      "            },\n",
      "            {\n",
      "                \"epoch\": 97,\n",
      "                \"loss\": 2.0968592166900635,\n",
      "                \"val_loss\": null,\n",
      "                \"val_wer\": 0.21333333333333335,\n",
      "                \"lr\": 9.999999974752427e-07\n",
      "            },\n",
      "            {\n",
      "                \"epoch\": 98,\n",
      "                \"loss\": 2.079890012741089,\n",
      "                \"val_loss\": null,\n",
      "                \"val_wer\": 0.21666666666666667,\n",
      "                \"lr\": 9.999999974752427e-07\n",
      "            },\n",
      "            {\n",
      "                \"epoch\": 99,\n",
      "                \"loss\": 2.0081663131713867,\n",
      "                \"val_loss\": null,\n",
      "                \"val_wer\": 0.22,\n",
      "                \"lr\": 9.999999974752427e-07\n",
      "            },\n",
      "            {\n",
      "                \"epoch\": 100,\n",
      "                \"loss\": 1.7035870552062988,\n",
      "                \"val_loss\": null,\n",
      "                \"val_wer\": 0.21333333333333335,\n",
      "                \"lr\": 9.999999974752427e-07\n",
      "            },\n",
      "            {\n",
      "                \"epoch\": 101,\n",
      "                \"loss\": 1.881250262260437,\n",
      "                \"val_loss\": null,\n",
      "                \"val_wer\": 0.21666666666666667,\n",
      "                \"lr\": 9.999999974752427e-07\n",
      "            },\n",
      "            {\n",
      "                \"epoch\": 102,\n",
      "                \"loss\": 1.8560891151428223,\n",
      "                \"val_loss\": null,\n",
      "                \"val_wer\": 0.21333333333333335,\n",
      "                \"lr\": 9.999999974752427e-07\n",
      "            },\n",
      "            {\n",
      "                \"epoch\": 103,\n",
      "                \"loss\": 1.8866636753082275,\n",
      "                \"val_loss\": null,\n",
      "                \"val_wer\": 0.21,\n",
      "                \"lr\": 9.999999974752427e-07\n",
      "            },\n",
      "            {\n",
      "                \"epoch\": 104,\n",
      "                \"loss\": 1.8086490631103516,\n",
      "                \"val_loss\": null,\n",
      "                \"val_wer\": 0.21333333333333335,\n",
      "                \"lr\": 9.999999974752427e-07\n",
      "            },\n",
      "            {\n",
      "                \"epoch\": 105,\n",
      "                \"loss\": 2.1092171669006348,\n",
      "                \"val_loss\": null,\n",
      "                \"val_wer\": 0.20666666666666667,\n",
      "                \"lr\": 9.999999974752427e-07\n",
      "            },\n",
      "            {\n",
      "                \"epoch\": 106,\n",
      "                \"loss\": 2.055722236633301,\n",
      "                \"val_loss\": null,\n",
      "                \"val_wer\": 0.22,\n",
      "                \"lr\": 9.999999974752427e-07\n",
      "            },\n",
      "            {\n",
      "                \"epoch\": 107,\n",
      "                \"loss\": 2.00193190574646,\n",
      "                \"val_loss\": null,\n",
      "                \"val_wer\": 0.21666666666666667,\n",
      "                \"lr\": 9.999999974752427e-07\n",
      "            },\n",
      "            {\n",
      "                \"epoch\": 108,\n",
      "                \"loss\": 1.729475975036621,\n",
      "                \"val_loss\": null,\n",
      "                \"val_wer\": 0.21333333333333335,\n",
      "                \"lr\": 9.999999974752427e-07\n",
      "            },\n",
      "            {\n",
      "                \"epoch\": 109,\n",
      "                \"loss\": 2.4290201663970947,\n",
      "                \"val_loss\": null,\n",
      "                \"val_wer\": 0.21333333333333335,\n",
      "                \"lr\": 9.999999974752427e-07\n",
      "            },\n",
      "            {\n",
      "                \"epoch\": 110,\n",
      "                \"loss\": 1.8988804817199707,\n",
      "                \"val_loss\": null,\n",
      "                \"val_wer\": 0.21333333333333335,\n",
      "                \"lr\": 9.999999974752427e-07\n",
      "            },\n",
      "            {\n",
      "                \"epoch\": 111,\n",
      "                \"loss\": 1.713120698928833,\n",
      "                \"val_loss\": null,\n",
      "                \"val_wer\": 0.22333333333333333,\n",
      "                \"lr\": 9.999999974752427e-07\n",
      "            },\n",
      "            {\n",
      "                \"epoch\": 112,\n",
      "                \"loss\": 2.0294675827026367,\n",
      "                \"val_loss\": null,\n",
      "                \"val_wer\": 0.21666666666666667,\n",
      "                \"lr\": 9.999999974752427e-07\n",
      "            },\n",
      "            {\n",
      "                \"epoch\": 113,\n",
      "                \"loss\": 1.7247991561889648,\n",
      "                \"val_loss\": null,\n",
      "                \"val_wer\": 0.21333333333333335,\n",
      "                \"lr\": 9.999999974752427e-07\n",
      "            },\n",
      "            {\n",
      "                \"epoch\": 114,\n",
      "                \"loss\": 2.0385637283325195,\n",
      "                \"val_loss\": null,\n",
      "                \"val_wer\": 0.21,\n",
      "                \"lr\": 9.999999974752427e-07\n",
      "            },\n",
      "            {\n",
      "                \"epoch\": 115,\n",
      "                \"loss\": 2.1938178539276123,\n",
      "                \"val_loss\": null,\n",
      "                \"val_wer\": 0.21,\n",
      "                \"lr\": 9.999999974752427e-07\n",
      "            },\n",
      "            {\n",
      "                \"epoch\": 116,\n",
      "                \"loss\": 2.1042816638946533,\n",
      "                \"val_loss\": null,\n",
      "                \"val_wer\": 0.21333333333333335,\n",
      "                \"lr\": 3.000000106112566e-07\n",
      "            },\n",
      "            {\n",
      "                \"epoch\": 117,\n",
      "                \"loss\": 1.9276080131530762,\n",
      "                \"val_loss\": null,\n",
      "                \"val_wer\": 0.21333333333333335,\n",
      "                \"lr\": 3.000000106112566e-07\n",
      "            },\n",
      "            {\n",
      "                \"epoch\": 118,\n",
      "                \"loss\": 1.6922991275787354,\n",
      "                \"val_loss\": null,\n",
      "                \"val_wer\": 0.21333333333333335,\n",
      "                \"lr\": 3.000000106112566e-07\n",
      "            },\n",
      "            {\n",
      "                \"epoch\": 119,\n",
      "                \"loss\": 2.0754613876342773,\n",
      "                \"val_loss\": null,\n",
      "                \"val_wer\": 0.21333333333333335,\n",
      "                \"lr\": 3.000000106112566e-07\n",
      "            },\n",
      "            {\n",
      "                \"epoch\": 120,\n",
      "                \"loss\": 1.996691346168518,\n",
      "                \"val_loss\": null,\n",
      "                \"val_wer\": 0.21333333333333335,\n",
      "                \"lr\": 3.000000106112566e-07\n",
      "            },\n",
      "            {\n",
      "                \"epoch\": 121,\n",
      "                \"loss\": 1.9903812408447266,\n",
      "                \"val_loss\": null,\n",
      "                \"val_wer\": 0.21666666666666667,\n",
      "                \"lr\": 3.000000106112566e-07\n",
      "            },\n",
      "            {\n",
      "                \"epoch\": 122,\n",
      "                \"loss\": 1.9844050407409668,\n",
      "                \"val_loss\": null,\n",
      "                \"val_wer\": 0.21333333333333335,\n",
      "                \"lr\": 3.000000106112566e-07\n",
      "            },\n",
      "            {\n",
      "                \"epoch\": 123,\n",
      "                \"loss\": 1.965273141860962,\n",
      "                \"val_loss\": null,\n",
      "                \"val_wer\": 0.21666666666666667,\n",
      "                \"lr\": 3.000000106112566e-07\n",
      "            },\n",
      "            {\n",
      "                \"epoch\": 124,\n",
      "                \"loss\": 1.9686954021453857,\n",
      "                \"val_loss\": null,\n",
      "                \"val_wer\": 0.21,\n",
      "                \"lr\": 3.000000106112566e-07\n",
      "            }\n",
      "        ]\n",
      "    },\n",
      "    \"prediction_examples_lzv_phase1\": [\n",
      "        {\n",
      "            \"ground_truth\": \"9   ļ o t i   s ē ņ o\",\n",
      "            \"prediction\": \"9   ļ o t i   s ē ņ o\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"č u k   č u k\",\n",
      "            \"prediction\": \"č u k   č u\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"10   t a g a d\",\n",
      "            \"prediction\": \"10   t a g a d\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"v a i   t ā p ā t\",\n",
      "            \"prediction\": \"v a i   t ā p ā a t  \"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"1\",\n",
      "            \"prediction\": \"<empty_pred>\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"c\",\n",
      "            \"prediction\": \"c\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"l a b i   g a n   t ā\",\n",
      "            \"prediction\": \"l a b i g a n t\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"m\",\n",
      "            \"prediction\": \"m\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"9\",\n",
      "            \"prediction\": \"9\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"d i v i\",\n",
      "            \"prediction\": \"d i v i\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"s p ē l ē   ģ i t ā r u\",\n",
      "            \"prediction\": \"s p ē l ē   ģ i t ā r u\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"9 8 7\",\n",
      "            \"prediction\": \"8\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"k ā   t e v i   s a u c\",\n",
      "            \"prediction\": \"k a   r t e h v i s a u c\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"l a b i\",\n",
      "            \"prediction\": \"l a b i\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"o\",\n",
      "            \"prediction\": \"0\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"a ā b c č d e ē f g ģ\",\n",
      "            \"prediction\": \"a d\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"m\",\n",
      "            \"prediction\": \"n\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"g a r d i\",\n",
      "            \"prediction\": \"g a r a i\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"ū d e n s\",\n",
      "            \"prediction\": \"ū d n s\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"s p i e ž\",\n",
      "            \"prediction\": \"s p i ž\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"n\",\n",
      "            \"prediction\": \"ņ\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"l i e n e\",\n",
      "            \"prediction\": \"l i n e\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"m o h i t o\",\n",
      "            \"prediction\": \"m o h i t o\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"d\",\n",
      "            \"prediction\": \"d\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"5\",\n",
      "            \"prediction\": \"5\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"e\",\n",
      "            \"prediction\": \"e\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"ļ o d z ī t\",\n",
      "            \"prediction\": \"ļ o d z ī t\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"3\",\n",
      "            \"prediction\": \"2\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"d i e n a\",\n",
      "            \"prediction\": \"n i n a\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"l u ņ ķ i s\",\n",
      "            \"prediction\": \"l u ņ ķ i s\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"f 7 f 7 f 7\",\n",
      "            \"prediction\": \"f 8 f 8\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"0 4 0 4\",\n",
      "            \"prediction\": \"0 0 4\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"k ā d ē ļ   s l i k t i\",\n",
      "            \"prediction\": \"k ā d ē l   s l i k t i\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"t a v ā   ē d i e n ā\",\n",
      "            \"prediction\": \"t a v ā     ē d i e n ā\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"ļ o t i   m ī ļ i\",\n",
      "            \"prediction\": \"ļ o t i   m ī l i\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"a\",\n",
      "            \"prediction\": \"a\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"l a b i   g a n   k a   t ā\",\n",
      "            \"prediction\": \"l a b i g a n k a   t ā\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"m a n s\",\n",
      "            \"prediction\": \"m a n s\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"h\",\n",
      "            \"prediction\": \"h\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"k ā d ē ļ   s l i k t i\",\n",
      "            \"prediction\": \"k ā d ē l   s l i k t i\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"1\",\n",
      "            \"prediction\": \"1 1\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"i z b r ī n a\",\n",
      "            \"prediction\": \"i z b r i n a  \"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"ģ h i ī j k ķ l ļ\",\n",
      "            \"prediction\": \"h i j k ķ ļ\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"ē\",\n",
      "            \"prediction\": \"e\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"5 6 5 6\",\n",
      "            \"prediction\": \"5 5\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"0 1 0 1 2 3 4 5 0\",\n",
      "            \"prediction\": \"0 1 0 1 2 3 4 0\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"i\",\n",
      "            \"prediction\": \"j\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"ē\",\n",
      "            \"prediction\": \"e\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"p\",\n",
      "            \"prediction\": \"<empty_pred>\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"a n a\",\n",
      "            \"prediction\": \"a n a\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"7 8 7 6 7 8\",\n",
      "            \"prediction\": \"8 6   8\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"s\",\n",
      "            \"prediction\": \"<empty_pred>\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"k ā d ā s   v i e t ā s\",\n",
      "            \"prediction\": \"k ā d ā s   v i e t ā s\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"5 4 3 2 1\",\n",
      "            \"prediction\": \"4 1\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"10\",\n",
      "            \"prediction\": \"10\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"l u ņ ķ i s\",\n",
      "            \"prediction\": \"l u ņ ķ i s\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"c\",\n",
      "            \"prediction\": \"c\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"8\",\n",
      "            \"prediction\": \"8\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"10   t a g a d\",\n",
      "            \"prediction\": \"10 t a g a\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"o p r s š t u ū v z ž\",\n",
      "            \"prediction\": \"o p r s š t ū\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"o\",\n",
      "            \"prediction\": \"<empty_pred>\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"d a u d z\",\n",
      "            \"prediction\": \"d a u z\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"b r ī n a\",\n",
      "            \"prediction\": \"b r ī n a\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"f\",\n",
      "            \"prediction\": \"f\"\n",
      "        }\n",
      "    ],\n",
      "    \"prediction_examples_lzv_phase2\": [\n",
      "        {\n",
      "            \"ground_truth\": \"9   ļ o t i   s ē ņ o\",\n",
      "            \"prediction\": \"9   ļ o t i   s ē ņ o\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"č u k   č u k\",\n",
      "            \"prediction\": \"č u k   č u\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"10   t a g a d\",\n",
      "            \"prediction\": \"10   t a g a d\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"v a i   t ā p ā t\",\n",
      "            \"prediction\": \"v a i   t ā p ā a t  \"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"1\",\n",
      "            \"prediction\": \"<empty_pred>\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"c\",\n",
      "            \"prediction\": \"c\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"l a b i   g a n   t ā\",\n",
      "            \"prediction\": \"l a b i g a n t\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"m\",\n",
      "            \"prediction\": \"m\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"9\",\n",
      "            \"prediction\": \"9\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"d i v i\",\n",
      "            \"prediction\": \"d i v i\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"s p ē l ē   ģ i t ā r u\",\n",
      "            \"prediction\": \"s p ē l ē   ģ i t ā r u\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"9 8 7\",\n",
      "            \"prediction\": \"8\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"k ā   t e v i   s a u c\",\n",
      "            \"prediction\": \"k a   r t e h v i s a u c\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"l a b i\",\n",
      "            \"prediction\": \"l a b i\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"o\",\n",
      "            \"prediction\": \"0\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"a ā b c č d e ē f g ģ\",\n",
      "            \"prediction\": \"a d\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"m\",\n",
      "            \"prediction\": \"n\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"g a r d i\",\n",
      "            \"prediction\": \"g a r a i\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"ū d e n s\",\n",
      "            \"prediction\": \"ū d n s\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"s p i e ž\",\n",
      "            \"prediction\": \"s p i ž\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"n\",\n",
      "            \"prediction\": \"ņ\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"l i e n e\",\n",
      "            \"prediction\": \"l i n e\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"m o h i t o\",\n",
      "            \"prediction\": \"m o h i t o\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"d\",\n",
      "            \"prediction\": \"d\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"5\",\n",
      "            \"prediction\": \"5\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"e\",\n",
      "            \"prediction\": \"e\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"ļ o d z ī t\",\n",
      "            \"prediction\": \"ļ o d z ī t\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"3\",\n",
      "            \"prediction\": \"2\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"d i e n a\",\n",
      "            \"prediction\": \"n i n a\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"l u ņ ķ i s\",\n",
      "            \"prediction\": \"l u ņ ķ i s\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"f 7 f 7 f 7\",\n",
      "            \"prediction\": \"f 8 f 8\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"0 4 0 4\",\n",
      "            \"prediction\": \"0 0 4\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"k ā d ē ļ   s l i k t i\",\n",
      "            \"prediction\": \"k ā d ē l   s l i k t i\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"t a v ā   ē d i e n ā\",\n",
      "            \"prediction\": \"t a v ā     ē d i e n ā\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"ļ o t i   m ī ļ i\",\n",
      "            \"prediction\": \"ļ o t i   m ī l i\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"a\",\n",
      "            \"prediction\": \"a\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"l a b i   g a n   k a   t ā\",\n",
      "            \"prediction\": \"l a b i g a n k a   t ā\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"m a n s\",\n",
      "            \"prediction\": \"m a n s\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"h\",\n",
      "            \"prediction\": \"h\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"k ā d ē ļ   s l i k t i\",\n",
      "            \"prediction\": \"k ā d ē l   s l i k t i\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"1\",\n",
      "            \"prediction\": \"1 1\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"i z b r ī n a\",\n",
      "            \"prediction\": \"i z b r i n a  \"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"ģ h i ī j k ķ l ļ\",\n",
      "            \"prediction\": \"h i j k ķ ļ\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"ē\",\n",
      "            \"prediction\": \"e\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"5 6 5 6\",\n",
      "            \"prediction\": \"5 5\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"0 1 0 1 2 3 4 5 0\",\n",
      "            \"prediction\": \"0 1 0 1 2 3 4 0\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"i\",\n",
      "            \"prediction\": \"j\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"ē\",\n",
      "            \"prediction\": \"e\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"p\",\n",
      "            \"prediction\": \"<empty_pred>\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"a n a\",\n",
      "            \"prediction\": \"a n a\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"7 8 7 6 7 8\",\n",
      "            \"prediction\": \"8 6   8\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"s\",\n",
      "            \"prediction\": \"<empty_pred>\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"k ā d ā s   v i e t ā s\",\n",
      "            \"prediction\": \"k ā d ā s   v i e t ā s\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"5 4 3 2 1\",\n",
      "            \"prediction\": \"4 1\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"10\",\n",
      "            \"prediction\": \"10\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"l u ņ ķ i s\",\n",
      "            \"prediction\": \"l u ņ ķ i s\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"c\",\n",
      "            \"prediction\": \"c\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"8\",\n",
      "            \"prediction\": \"8\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"10   t a g a d\",\n",
      "            \"prediction\": \"10 t a g a\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"o p r s š t u ū v z ž\",\n",
      "            \"prediction\": \"o p r s š t ū\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"o\",\n",
      "            \"prediction\": \"<empty_pred>\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"d a u d z\",\n",
      "            \"prediction\": \"d a u z\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"b r ī n a\",\n",
      "            \"prediction\": \"b r ī n a\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"f\",\n",
      "            \"prediction\": \"f\"\n",
      "        }\n",
      "    ],\n",
      "    \"prediction_examples_lzv_phase3\": [\n",
      "        {\n",
      "            \"ground_truth\": \"9   ļ o t i   s ē ņ o\",\n",
      "            \"prediction\": \"9   ļ o t i   s ē ņ o\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"č u k   č u k\",\n",
      "            \"prediction\": \"č u k   č u\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"10   t a g a d\",\n",
      "            \"prediction\": \"10   t a g a d\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"v a i   t ā p ā t\",\n",
      "            \"prediction\": \"v a i   t ā p ā a t  \"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"1\",\n",
      "            \"prediction\": \"<empty_pred>\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"c\",\n",
      "            \"prediction\": \"c\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"l a b i   g a n   t ā\",\n",
      "            \"prediction\": \"l a b i g a n t\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"m\",\n",
      "            \"prediction\": \"m\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"9\",\n",
      "            \"prediction\": \"9\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"d i v i\",\n",
      "            \"prediction\": \"d i v i\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"s p ē l ē   ģ i t ā r u\",\n",
      "            \"prediction\": \"s p ē l ē   ģ i t ā r u\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"9 8 7\",\n",
      "            \"prediction\": \"8\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"k ā   t e v i   s a u c\",\n",
      "            \"prediction\": \"k a   r t e h v i s a u c\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"l a b i\",\n",
      "            \"prediction\": \"l a b i\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"o\",\n",
      "            \"prediction\": \"0\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"a ā b c č d e ē f g ģ\",\n",
      "            \"prediction\": \"a d\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"m\",\n",
      "            \"prediction\": \"n\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"g a r d i\",\n",
      "            \"prediction\": \"g a r a i\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"ū d e n s\",\n",
      "            \"prediction\": \"ū d n s\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"s p i e ž\",\n",
      "            \"prediction\": \"s p i ž\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"n\",\n",
      "            \"prediction\": \"ņ\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"l i e n e\",\n",
      "            \"prediction\": \"l i n e\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"m o h i t o\",\n",
      "            \"prediction\": \"m o h i t o\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"d\",\n",
      "            \"prediction\": \"d\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"5\",\n",
      "            \"prediction\": \"5\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"e\",\n",
      "            \"prediction\": \"e\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"ļ o d z ī t\",\n",
      "            \"prediction\": \"ļ o d z ī t\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"3\",\n",
      "            \"prediction\": \"2\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"d i e n a\",\n",
      "            \"prediction\": \"n i n a\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"l u ņ ķ i s\",\n",
      "            \"prediction\": \"l u ņ ķ i s\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"f 7 f 7 f 7\",\n",
      "            \"prediction\": \"f 8 f 8\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"0 4 0 4\",\n",
      "            \"prediction\": \"0 0 4\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"k ā d ē ļ   s l i k t i\",\n",
      "            \"prediction\": \"k ā d ē l   s l i k t i\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"t a v ā   ē d i e n ā\",\n",
      "            \"prediction\": \"t a v ā     ē d i e n ā\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"ļ o t i   m ī ļ i\",\n",
      "            \"prediction\": \"ļ o t i   m ī l i\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"a\",\n",
      "            \"prediction\": \"a\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"l a b i   g a n   k a   t ā\",\n",
      "            \"prediction\": \"l a b i g a n k a   t ā\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"m a n s\",\n",
      "            \"prediction\": \"m a n s\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"h\",\n",
      "            \"prediction\": \"h\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"k ā d ē ļ   s l i k t i\",\n",
      "            \"prediction\": \"k ā d ē l   s l i k t i\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"1\",\n",
      "            \"prediction\": \"1 1\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"i z b r ī n a\",\n",
      "            \"prediction\": \"i z b r i n a  \"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"ģ h i ī j k ķ l ļ\",\n",
      "            \"prediction\": \"h i j k ķ ļ\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"ē\",\n",
      "            \"prediction\": \"e\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"5 6 5 6\",\n",
      "            \"prediction\": \"5 5\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"0 1 0 1 2 3 4 5 0\",\n",
      "            \"prediction\": \"0 1 0 1 2 3 4 0\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"i\",\n",
      "            \"prediction\": \"j\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"ē\",\n",
      "            \"prediction\": \"e\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"p\",\n",
      "            \"prediction\": \"<empty_pred>\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"a n a\",\n",
      "            \"prediction\": \"a n a\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"7 8 7 6 7 8\",\n",
      "            \"prediction\": \"8 6   8\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"s\",\n",
      "            \"prediction\": \"<empty_pred>\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"k ā d ā s   v i e t ā s\",\n",
      "            \"prediction\": \"k ā d ā s   v i e t ā s\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"5 4 3 2 1\",\n",
      "            \"prediction\": \"4 1\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"10\",\n",
      "            \"prediction\": \"10\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"l u ņ ķ i s\",\n",
      "            \"prediction\": \"l u ņ ķ i s\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"c\",\n",
      "            \"prediction\": \"c\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"8\",\n",
      "            \"prediction\": \"8\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"10   t a g a d\",\n",
      "            \"prediction\": \"10 t a g a\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"o p r s š t u ū v z ž\",\n",
      "            \"prediction\": \"o p r s š t ū\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"o\",\n",
      "            \"prediction\": \"<empty_pred>\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"d a u d z\",\n",
      "            \"prediction\": \"d a u z\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"b r ī n a\",\n",
      "            \"prediction\": \"b r ī n a\"\n",
      "        },\n",
      "        {\n",
      "            \"ground_truth\": \"f\",\n",
      "            \"prediction\": \"f\"\n",
      "        }\n",
      "    ],\n",
      "    \"saved_files\": {\n",
      "        \"best_fine_tuned_training_checkpoint\": \"lzv_finetuned_model_best_exp1.keras\",\n",
      "        \"final_lzv_prediction_model\": \"lzv_prediction_model_final_exp1.keras\",\n",
      "        \"plot\": \"lzv_plot_exp1.png\",\n",
      "        \"experiment_data_json\": \"lzv_exp_data_1.json\"\n",
      "    }\n",
      "}\n",
      "LZV Experiment data JSON saved successfully.\n"
     ]
    }
   ],
   "source": [
    "# Cik daudz reizes trenēt modeli, 1=1 reizi\n",
    "for _ in range(1):\n",
    "        \n",
    "    print(\"\\n--- Preparing for training ---\")\n",
    "\n",
    "    try:\n",
    "        if BATCH_SIZE <= 0:\n",
    "            raise ValueError(\"BATCH_SIZE must be positive.\")\n",
    "\n",
    "        steps_per_epoch = math.ceil(NUM_TRAIN_SAMPLES_AFTER_FILTER / BATCH_SIZE)\n",
    "        validation_steps_for_keras = math.ceil(NUM_VAL_SAMPLES_AFTER_FILTER / BATCH_SIZE)\n",
    "        validation_steps_for_callback = validation_steps_for_keras\n",
    "\n",
    "        print(f\"LZV Training Samples (post-filter): {NUM_TRAIN_SAMPLES_AFTER_FILTER}\")\n",
    "        print(f\"LZV Validation Samples (post-filter): {NUM_VAL_SAMPLES_AFTER_FILTER}\")\n",
    "        print(f\"Batch Size: {BATCH_SIZE}\")\n",
    "        print(f\"Learning Rate for fine-tuning: {LEARNING_RATE}\")\n",
    "        print(f\"Calculated steps_per_epoch: {steps_per_epoch}\")\n",
    "        print(f\"Calculated validation_steps (for Keras & WER Callback): {validation_steps_for_keras}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    # Pārbaude\n",
    "    try:\n",
    "        current_experiment_index = find_next_experiment_index(OUTPUT_DIR)\n",
    "        experiment_dir = os.path.join(OUTPUT_DIR, str(current_experiment_index))\n",
    "        os.makedirs(experiment_dir, exist_ok=True)\n",
    "        print(f\"\\nLZV experiment results will be saved in: {experiment_dir}\")\n",
    "\n",
    "        checkpoint_filename = f\"lzv_finetuned_model_best_exp{current_experiment_index}.keras\"\n",
    "        checkpoint_filepath = os.path.join(experiment_dir, checkpoint_filename)\n",
    "        \n",
    "        prediction_model_filename = f\"lzv_prediction_model_final_exp{current_experiment_index}.keras\"\n",
    "        prediction_model_save_path = os.path.join(experiment_dir, prediction_model_filename)\n",
    "        \n",
    "        json_filename = f\"lzv_exp_data_{current_experiment_index}.json\"\n",
    "        json_save_path = os.path.join(experiment_dir, json_filename)\n",
    "        \n",
    "        plot_filename = f\"lzv_plot_exp{current_experiment_index}.png\"\n",
    "        plot_path = os.path.join(experiment_dir, plot_filename)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error setting up LZV experiment directory or paths: {e}. Exiting.\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    combined_history_data = {'loss': [], 'val_loss': [], 'val_wer': [], 'lr': []}\n",
    "\n",
    "    training_start_time = time.monotonic()\n",
    "    print(f\"\\nStarted at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')})...\")\n",
    "\n",
    "\n",
    "    # --- 1. Fāze ---\n",
    "    print(\"\\n--- PHASE 1 ---\")\n",
    "    asl_training_model_base_loaded.trainable = False\n",
    "    print(f\"Base model '{asl_training_model_base_loaded.name}' trainable: {asl_training_model_base_loaded.trainable}\")\n",
    "    training_model.get_layer('output_dense_softmax_lzv').trainable = True\n",
    "\n",
    "    print(\"Trainable params for Phase 1:\")\n",
    "    training_model.summary(line_length=100)\n",
    "\n",
    "    optimizer_phase1 = keras.optimizers.Adam(learning_rate=LR_PHASE_1, clipnorm=1.0)\n",
    "    training_model.compile(optimizer=optimizer_phase1, loss=lambda y_true, y_pred: y_pred, metrics=[])\n",
    "    print(f\"Model compiled for Phase 1 with LR: {LR_PHASE_1}\")\n",
    "\n",
    "    phase1_log_prefix = 'val_wer_phase1'\n",
    "    checkpoint_filepath_phase1 = os.path.join(experiment_dir, f\"lzv_model_phase1_best_exp{current_experiment_index}.keras\")\n",
    "    model_checkpoint_phase1 = ModelCheckpoint(filepath=checkpoint_filepath_phase1, monitor=phase1_log_prefix, save_best_only=True, mode='min', verbose=1)\n",
    "    early_stopping_phase1 = EarlyStopping(monitor=phase1_log_prefix, patience=15, verbose=1, mode='min', restore_best_weights=True)\n",
    "    reduce_lr_phase1 = keras.callbacks.ReduceLROnPlateau(monitor=phase1_log_prefix, factor=0.3, patience=7, min_lr=1e-5, verbose=1)\n",
    "    wer_callback_phase1 = WERCallback(prediction_model, validation_dataset_batched, validation_steps_for_callback, inverse_char_map, log_prefix=phase1_log_prefix)\n",
    "\n",
    "    print(f\"Starting Phase 1 training for {EPOCHS_PHASE_1} epochs...\")\n",
    "    history_phase1 = training_model.fit(\n",
    "        train_dataset_prepared,\n",
    "        epochs=EPOCHS_PHASE_1,\n",
    "        steps_per_epoch=steps_per_epoch,\n",
    "        callbacks=[wer_callback_phase1, early_stopping_phase1, model_checkpoint_phase1, reduce_lr_phase1],\n",
    "        validation_data=validation_dataset_prepared,\n",
    "        validation_steps=validation_steps_for_keras,\n",
    "        verbose=1\n",
    "    )\n",
    "    if os.path.exists(checkpoint_filepath_phase1) and early_stopping_phase1.stopped_epoch > 0:\n",
    "        print(f\"Loading best weights from Phase 1 checkpoint: {checkpoint_filepath_phase1}\")\n",
    "        training_model.load_weights(checkpoint_filepath_phase1)\n",
    "\n",
    "    current_input_tensor = training_model.get_layer('input_landmarks').input\n",
    "    current_logits_output_tensor = training_model.get_layer('output_dense_softmax_lzv').output\n",
    "\n",
    "    # Saglabā datus 1. fāzei\n",
    "    epochs_completed_phase1 = len(history_phase1.history['loss'])\n",
    "    combined_history_data['loss'].extend(history_phase1.history['loss'])\n",
    "    combined_history_data['val_loss'].extend(history_phase1.history.get('val_loss', [None]*epochs_completed_phase1))\n",
    "    combined_history_data['val_wer'].extend(history_phase1.history[phase1_log_prefix])\n",
    "    combined_history_data['lr'].extend(history_phase1.history['learning_rate'])\n",
    "\n",
    "\n",
    "    # --- 2. Fāze ---\n",
    "    print(\"\\n--- PHASE 2: Fine-tuning Top Layers of the Base Model ---\")\n",
    "    asl_training_model_base_loaded.trainable = True\n",
    "    unfrozen_in_phase2 = []\n",
    "    for layer in asl_training_model_base_loaded.layers:\n",
    "        if layer.name in ['bilstm_1', 'batchnorm_lstm1']:\n",
    "            if not layer.trainable: layer.trainable = True; unfrozen_in_phase2.append(layer.name)\n",
    "        elif layer.name != 'input_landmarks':\n",
    "            if layer.trainable: layer.trainable = False\n",
    "    print(f\"  Unfrozen in Phase 2: {unfrozen_in_phase2 if unfrozen_in_phase2 else 'None (already trainable or not found)'}\")\n",
    "    print(f\"  Base model '{asl_training_model_base_loaded.name}' trainable: {asl_training_model_base_loaded.trainable}\")\n",
    "    training_model.get_layer('output_dense_softmax_lzv').trainable = True \n",
    "    print(\"Trainable params for Phase 2:\")\n",
    "    training_model.summary(line_length=100)\n",
    "\n",
    "    optimizer_phase2 = keras.optimizers.Adam(learning_rate=LR_PHASE_2, clipnorm=1.0)\n",
    "    training_model.compile(optimizer=optimizer_phase2, loss=lambda y_true, y_pred: y_pred, metrics=[])\n",
    "    print(f\"Model re-compiled for Phase 2 with LR: {LR_PHASE_2}\")\n",
    "\n",
    "    phase2_log_prefix = 'val_wer_phase2'\n",
    "    checkpoint_filepath_phase2 = os.path.join(experiment_dir, f\"lzv_model_phase2_best_exp{current_experiment_index}.keras\")\n",
    "    model_checkpoint_phase2 = ModelCheckpoint(filepath=checkpoint_filepath_phase2, monitor=phase2_log_prefix, save_best_only=True, mode='min', verbose=1)\n",
    "    early_stopping_phase2 = EarlyStopping(monitor=phase2_log_prefix, patience=25, verbose=1, mode='min', restore_best_weights=True)\n",
    "    reduce_lr_phase2 = keras.callbacks.ReduceLROnPlateau(monitor=phase2_log_prefix, factor=0.3, patience=10, min_lr=1e-6, verbose=1)\n",
    "    wer_callback_phase2 = WERCallback(prediction_model, validation_dataset_batched, validation_steps_for_callback, inverse_char_map, log_prefix=phase2_log_prefix)\n",
    "\n",
    "    print(f\"Starting Phase 2 training for {EPOCHS_PHASE_2} epochs, continuing from epoch {epochs_completed_phase1}...\")\n",
    "    history_phase2 = training_model.fit(\n",
    "        train_dataset_prepared,\n",
    "        epochs=epochs_completed_phase1 + EPOCHS_PHASE_2,\n",
    "        initial_epoch=epochs_completed_phase1,\n",
    "        steps_per_epoch=steps_per_epoch,\n",
    "        callbacks=[wer_callback_phase2, early_stopping_phase2, model_checkpoint_phase2, reduce_lr_phase2],\n",
    "        validation_data=validation_dataset_prepared,\n",
    "        validation_steps=validation_steps_for_keras,\n",
    "        verbose=1\n",
    "    )\n",
    "    if os.path.exists(checkpoint_filepath_phase2) and early_stopping_phase2.stopped_epoch > 0:\n",
    "        print(f\"Loading best weights from Phase 2 checkpoint: {checkpoint_filepath_phase2}\")\n",
    "        training_model.load_weights(checkpoint_filepath_phase2)\n",
    "\n",
    "    # Saglabā datus 2. fāzei\n",
    "    epochs_in_phase2 = len(history_phase2.history['loss'])\n",
    "    combined_history_data['loss'].extend(history_phase2.history['loss'])\n",
    "    combined_history_data['val_loss'].extend(history_phase2.history.get('val_loss', [None]*epochs_in_phase2))\n",
    "    combined_history_data['val_wer'].extend(history_phase2.history[phase2_log_prefix])\n",
    "    combined_history_data['lr'].extend(history_phase2.history['learning_rate'])\n",
    "    epochs_completed_phase2 = epochs_completed_phase1 + epochs_in_phase2\n",
    "    if hasattr(early_stopping_phase2, 'stopped_epoch') and early_stopping_phase2.stopped_epoch > 0:\n",
    "        epochs_completed_phase2 = early_stopping_phase2.stopped_epoch\n",
    "\n",
    "\n",
    "    # --- 3. Fāze ---\n",
    "    print(\"\\n--- PHASE 3: Fine-tuning More Base Layers (including Conv1D) ---\")\n",
    "    print(\"Setting trainable status for Phase 3:\")\n",
    "    unfrozen_in_phase3 = []\n",
    "    for layer in asl_training_model_base_loaded.layers:\n",
    "        if layer.name in ['conv1d_layer', 'batchnorm_conv', 'bilstm_1', 'batchnorm_lstm1']:\n",
    "            if not layer.trainable: layer.trainable = True; unfrozen_in_phase3.append(layer.name)\n",
    "        elif layer.name != 'input_landmarks':\n",
    "            if layer.trainable: layer.trainable = False\n",
    "    print(f\"  Unfrozen in Phase 3 (or confirmed): {unfrozen_in_phase3 if unfrozen_in_phase3 else 'None (already trainable or not found)'}\")\n",
    "    training_model.get_layer('output_dense_softmax_lzv').trainable = True\n",
    "    print(\"Trainable params for Phase 3:\")\n",
    "    training_model.summary(line_length=100)\n",
    "\n",
    "    optimizer_phase3 = keras.optimizers.Adam(learning_rate=LR_PHASE_3, clipnorm=1.0) # Start with LR_PHASE_3\n",
    "    training_model.compile(optimizer=optimizer_phase3, loss=lambda y_true, y_pred: y_pred, metrics=[])\n",
    "    print(f\"Model re-compiled for Phase 3 with LR: {LR_PHASE_3}\")\n",
    "\n",
    "    phase3_log_prefix = 'val_wer_phase3'\n",
    "    checkpoint_filepath_phase3 = os.path.join(experiment_dir, f\"lzv_model_phase3_best_exp{current_experiment_index}.keras\")\n",
    "    model_checkpoint_phase3 = ModelCheckpoint(filepath=checkpoint_filepath_phase3, monitor=phase3_log_prefix, save_best_only=True, mode='min', verbose=1)\n",
    "    early_stopping_phase3 = EarlyStopping(monitor=phase3_log_prefix, patience=20, verbose=1, mode='min', restore_best_weights=True) # Longer patience\n",
    "    reduce_lr_phase3 = keras.callbacks.ReduceLROnPlateau(monitor=phase3_log_prefix, factor=0.3, patience=10, min_lr=5e-8, verbose=1)\n",
    "    wer_callback_phase3 = WERCallback(prediction_model, validation_dataset_batched, validation_steps_for_callback, inverse_char_map, log_prefix=phase3_log_prefix)\n",
    "\n",
    "    print(f\"Starting Phase 3 training for {EPOCHS_PHASE_3} epochs, continuing from epoch {epochs_completed_phase2}...\")\n",
    "    history_phase3 = training_model.fit(\n",
    "        train_dataset_prepared,\n",
    "        epochs=epochs_completed_phase2 + EPOCHS_PHASE_3,\n",
    "        initial_epoch=epochs_completed_phase2,\n",
    "        steps_per_epoch=steps_per_epoch,\n",
    "        callbacks=[wer_callback_phase3, early_stopping_phase3, model_checkpoint_phase3, reduce_lr_phase3],\n",
    "        validation_data=validation_dataset_prepared,\n",
    "        validation_steps=validation_steps_for_keras,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    if os.path.exists(checkpoint_filepath_phase3) and early_stopping_phase3.stopped_epoch > 0:\n",
    "        print(f\"Loading best weights from Phase 3 checkpoint: {checkpoint_filepath_phase3}\")\n",
    "        training_model.load_weights(checkpoint_filepath_phase3)\n",
    "\n",
    "    # Saglabā datus 3. fāzei\n",
    "    epochs_in_phase3 = len(history_phase3.history['loss'])\n",
    "    combined_history_data['loss'].extend(history_phase3.history['loss'])\n",
    "    combined_history_data['val_loss'].extend(history_phase3.history.get('val_loss', [None]*epochs_in_phase3))\n",
    "    combined_history_data['val_wer'].extend(history_phase3.history[phase3_log_prefix])\n",
    "    combined_history_data['lr'].extend(history_phase3.history['learning_rate'])\n",
    "    epochs_actually_run_total = epochs_completed_phase2 + epochs_in_phase3\n",
    "\n",
    "\n",
    "    # --- Saglabāšana ---\n",
    "    print(\"\\n--- Post-Phased Fine-tuning: Saving LZV Results ---\")\n",
    "    elapsed_training_seconds = time.monotonic() - training_start_time\n",
    "    training_successful = True\n",
    "\n",
    "    if training_successful:\n",
    "        if prediction_model is not None:\n",
    "            prediction_model.save(prediction_model_save_path)\n",
    "            print(f\"Final LZV prediction model saved to: {prediction_model_save_path}\")\n",
    "        \n",
    "        overall_best_wer = min(combined_history_data['val_wer'])\n",
    "        overall_best_epoch = combined_history_data['val_wer'].index(overall_best_wer) + 1\n",
    "\n",
    "        print(f\"Overall best val_wer: {overall_best_wer:.4f} at cumulative epoch {overall_best_epoch}\")\n",
    "\n",
    "        # Grafs trenēšanas kļūdām un WER\n",
    "        if combined_history_data['loss']:\n",
    "            print(f\"\\nGenerating and saving LZV plot to: {plot_path}\")\n",
    "            fig, ax1 = plt.subplots(figsize=(14, 7))\n",
    "            color = 'tab:red'\n",
    "            ax1.set_xlabel('Epohs')\n",
    "            ax1.set_ylabel('Kļūdas', color=color)\n",
    "            ax1.plot(combined_history_data['loss'], color=color, label='Trenēšanas kļūdas')\n",
    "            if combined_history_data['val_loss'] and any(vl is not None for vl in combined_history_data['val_loss']):\n",
    "                ax1.plot(combined_history_data['val_loss'], color='orange', linestyle='--', label='Validācijas kļūdas')\n",
    "            ax1.tick_params(axis='y', labelcolor=color)\n",
    "            \n",
    "            epochs_p1_end = len(history_phase1.history['loss']) if history_phase1 else 0\n",
    "            epochs_p2_end = epochs_p1_end + (len(history_phase2.history['loss']) if history_phase2 else 0)\n",
    "\n",
    "            if epochs_p1_end > 0:\n",
    "                ax1.axvline(x=epochs_p1_end -1 , color='gray', linestyle='--', label=f'2. fāzes sākums')\n",
    "            if epochs_p2_end > epochs_p1_end:\n",
    "                ax1.axvline(x=epochs_p2_end -1, color='black', linestyle='--', label=f'3. fāzes sākums')\n",
    "            \n",
    "            ax1.legend(loc='upper left')\n",
    "            ax1.grid(True)\n",
    "\n",
    "            ax2 = ax1.twinx()\n",
    "            color = 'tab:blue'\n",
    "            ax2.set_ylabel('VAL_WER', color=color)\n",
    "            ax2.plot(combined_history_data['val_wer'], color=color, marker='o', linestyle='-', label='VAL_WER')\n",
    "            ax2.tick_params(axis='y', labelcolor=color)\n",
    "            ax2.legend(loc='upper right')\n",
    "            \n",
    "            fig.tight_layout()\n",
    "            plt.title(f'LZV modeļa apmācība')\n",
    "            plt.savefig(plot_path)\n",
    "            print(f\"LZV Plot saved successfully to {plot_path}.\")\n",
    "            plt.show()\n",
    "        else:\n",
    "            print(\"No history data to plot.\")\n",
    "\n",
    "        # --- Saglabā metadatus JSON ---\n",
    "        print(f\"\\nSaving LZV experiment data to: {json_save_path}\")\n",
    "        run_data = {}\n",
    "        try:\n",
    "            run_data[\"experiment_type\"] = \"Fine-tuning LZV\"\n",
    "            run_data[\"base_asl_model_path\"] = ASL_MODEL_PATH\n",
    "            run_data[\"experiment_index\"] = current_experiment_index\n",
    "            run_data[\"timestamp_completed_utc\"] = datetime.now(timezone.utc).isoformat(timespec='seconds')\n",
    "            \n",
    "            run_data[\"dataset_info\"] = {\n",
    "                \"name\": dataset_info.get(\"dataset_name\", \"LZV\"),\n",
    "                \"training_samples_final_filtered\": NUM_TRAIN_SAMPLES_AFTER_FILTER,\n",
    "                \"validation_samples_final_filtered\": NUM_VAL_SAMPLES_AFTER_FILTER,\n",
    "                \"total_classes_lzv_excl_blank\": NUM_CLASSES,\n",
    "                \"total_classes_lzv_incl_blank\": NUM_CLASSES_WITH_BLANK,\n",
    "                \"char_map_file\": os.path.relpath(CHAR_MAP_FILE, BASE_DIR) if 'BASE_DIR' in locals() and CHAR_MAP_FILE else CHAR_MAP_FILE,\n",
    "                \"train_tfrecord\": os.path.basename(TFRECORD_FILE),\n",
    "                \"val_tfrecord\": os.path.basename(TFRECORD_FILE_VAL)\n",
    "            }\n",
    "            run_data[\"landmark_info\"] = {\n",
    "                \"source\": \"MediaPipe Holistic\",\n",
    "                \"original_total_landmarks\": ORIGINAL_NUM_LANDMARKS,\n",
    "                \"used_landmarks_count\": NUM_LANDMARKS,\n",
    "                \"dimensions\": LANDMARK_DIMS,\n",
    "            }\n",
    "            run_data[\"preprocessing\"] = {\n",
    "                \"normalization_source\": \"calculated_on_the_spot\",\n",
    "                \"ctc_length_filter_applied\": True\n",
    "            }\n",
    "            run_data[\"augmentation_details\"] = {\n",
    "                \"enabled\": USE_AUGMENTATION,\n",
    "                \"spatial_affine\": True if USE_AUGMENTATION else False,\n",
    "                \"horizontal_flip\": True if USE_AUGMENTATION and USE_FLIP_AUGMENTATION else False,\n",
    "                \"temporal_resample\": True if USE_AUGMENTATION else False,\n",
    "                \"temporal_mask\": True if USE_AUGMENTATION else False,\n",
    "            }\n",
    "\n",
    "            model_config = {}\n",
    "            try:\n",
    "                if training_model: model_config = training_model.get_config()\n",
    "            except Exception as cfg_e: print(f\"Warning: Could not get full model config: {cfg_e}\")\n",
    "\n",
    "            run_data[\"model_architecture_fine_tuned\"] = {\n",
    "                \"config\": model_config,\n",
    "                \"params_total\": training_model.count_params() if training_model else None,\n",
    "                \"params_trainable\": sum([w.shape.num_elements() for w in training_model.trainable_weights]) if training_model else None,\n",
    "            }\n",
    "\n",
    "            if combined_history_data['val_wer']:\n",
    "                best_val_wer_overall = min(val for val in combined_history_data['val_wer'] if val is not None)\n",
    "                best_val_wer_epoch_overall = combined_history_data['val_wer'].index(best_val_wer_overall) + 1\n",
    "            else:\n",
    "                best_val_wer_overall = None\n",
    "                best_val_wer_epoch_overall = None\n",
    "\n",
    "            final_train_loss = combined_history_data['loss'][-1] if combined_history_data['loss'] else None\n",
    "            final_val_wer = combined_history_data['val_wer'][-1] if combined_history_data['val_wer'] else None\n",
    "            \n",
    "            run_data[\"results\"] = {\n",
    "                \"best_val_wer_overall\": best_val_wer_overall,\n",
    "                \"best_val_wer_epoch_overall\": best_val_wer_epoch_overall,\n",
    "                \"final_train_loss\": final_train_loss,\n",
    "                \"final_val_wer\": final_val_wer,\n",
    "                \"epoch_metrics\": [\n",
    "                    {\n",
    "                        \"epoch\": i + 1,\n",
    "                        \"loss\": combined_history_data['loss'][i] if i < len(combined_history_data['loss']) else None,\n",
    "                        \"val_loss\": combined_history_data['val_loss'][i] if i < len(combined_history_data['val_loss']) else None,\n",
    "                        \"val_wer\": combined_history_data['val_wer'][i] if i < len(combined_history_data['val_wer']) else None,\n",
    "                        \"lr\": combined_history_data['lr'][i] if i < len(combined_history_data['lr']) else None,\n",
    "                    }\n",
    "                    for i in range(epochs_actually_run_total)\n",
    "                ],\n",
    "            }\n",
    "\n",
    "\n",
    "            # Saglabā minējumus (neobligāti 1. un 2. fāzei)\n",
    "            run_data[\"prediction_examples_lzv_phase1\"] = []\n",
    "            generate_and_log_predictions(\"Phase 1\", prediction_model, validation_dataset_batched, wer_callback_phase1, 64, BATCH_SIZE, run_data[\"prediction_examples_lzv_phase1\"])\n",
    "\n",
    "            run_data[\"prediction_examples_lzv_phase2\"] = []\n",
    "            generate_and_log_predictions(\"Phase 2\", prediction_model, validation_dataset_batched, wer_callback_phase2, 64, BATCH_SIZE, run_data[\"prediction_examples_lzv_phase2\"])\n",
    "\n",
    "            run_data[\"prediction_examples_lzv_phase3\"] = []\n",
    "            generate_and_log_predictions(\"Phase 3\", prediction_model, validation_dataset_batched, wer_callback_phase3, 64, BATCH_SIZE, run_data[\"prediction_examples_lzv_phase3\"])\n",
    "            \n",
    "\n",
    "            best_checkpoint_path_overall = \"\"\n",
    "            if best_val_wer_epoch_overall <= epochs_completed_phase1:\n",
    "                best_checkpoint_path_overall = checkpoint_filepath_phase1\n",
    "            elif best_val_wer_epoch_overall <= epochs_completed_phase2:\n",
    "                best_checkpoint_path_overall = checkpoint_filepath_phase2\n",
    "            else:\n",
    "                best_checkpoint_path_overall = checkpoint_filepath_phase3\n",
    "\n",
    "\n",
    "            run_data[\"saved_files\"] = {\n",
    "                \"best_fine_tuned_training_checkpoint\": checkpoint_filename,\n",
    "                \"final_lzv_prediction_model\": prediction_model_filename,\n",
    "                \"plot\": plot_filename, \"experiment_data_json\": json_filename\n",
    "            }\n",
    "\n",
    "            print(\"\\n--- Content of run_data before saving to JSON ---\")\n",
    "            print(json.dumps(run_data, indent=4, default=str, ensure_ascii=False))\n",
    "            \n",
    "            with open(json_save_path, \"w\", encoding='utf-8') as f:\n",
    "                json.dump(run_data, f, indent=4, default=str, ensure_ascii=False)\n",
    "            print(\"LZV Experiment data JSON saved successfully.\")\n",
    "\n",
    "        except Exception as json_e:\n",
    "            print(f\"Error populating or saving LZV experiment data JSON: {json_e}\")\n",
    "\n",
    "    else:\n",
    "        print(\"Skipping LZV model phased fine-tuning due to missing components.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
